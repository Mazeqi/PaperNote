[TOC]

## 简介

### yolo与传统的检测算法的不同 

-  yolo把目标简介转化为一个回归问题，与传统的分类检测不同，yolo是one-stage的。每次预测中，用单独的神经网络预测全图的bounding box和分类的可能性。当检测的是一个单独的网络时，它可以直接对检测性能进行端到端的最优化
- 传统的检测方法是基于Region Proposal，如R-CNN系列，它们是two-stage的，需要先用启发式的方法（selective search）或者CNN网络(RPN)产生Region Proposal，然后再在Region Proposal上作分类和回归。

### 滑动窗口与CNN

- 采用滑动窗口的目标检测算法思路非常简单，它将检测问题转化为了图像分类问题。
- 其基本原理就是采用不同大小和比例（宽高比）的窗口在整张图片上以一定的步长进行滑动，然后对这些窗口对应的区域做图像分类，这样就可以实现对整张图片的检测了。如DPM就是采用这种思路。
- 缺点：
  -  不知道要检测的目标大小是什么规模，所以要设置不同大小和比例的窗口去滑动，而且还要选取合适的步长。
  - 滑动会产生很多的子区域，并且都要经过分类器去做预测，这需要很大的计算量，所以你的分类器不能太复杂，因为要保证速度。
  - 解决思路之一就是减少要分类的子区域，这就是R-CNN的一个改进策略，其采用了selective search方法来找到最有可能包含目标的子区域（Region Proposal），其实可以看成采用启发式方法过滤掉很多子区域，这会提升效率。

- **滑动窗口图片**

![](./img/slide_window.jpg)

- 全卷积网络（FCN）：全卷积网络通过转置卷积（transposed convolution）层将中间层特征图的高和宽变换回输入图像的尺寸，从而令预测结果与输入图像在空间维（高和宽）上一一对应：给定空间维上的位置，通道维的输出即该位置对应像素的类别预测。尽管可以减少滑动窗口的计算量，但是只是针对一个固定大小与步长的窗口，这是远远不够的。

## yolo设计理念

![](./img/yolo_process.jpg)

- 将图片分成$S \times S$ 的网格，如果目标对象的中心落在某个单元格，那么该单元格就要负责检测那个对象
- 每个单元格会预测数个bounding boxes 出来，并且为这些box各自附上一个confidence score，confidence scores反映了box包含了一个对象并且box的accuracy，把confidence定义为 $Pr(Object) * IOU^{truth}_{pred}$ ,confidece包含两个方面，一个是这个边界框含有目标的可能性大小，二是这个边界框的准确度。前者为$Pr(Object)$ ，当边界框是背景时（即不包含目标），此时$Pr(Object)=0$ ,而包含目标时则为1。边界框的准确度用IOU来检测。
- 每一个bounding box 右五个预测值组成：x，y，w，h，confidence。(x，y)坐标表示box的中心，(x，y)是相对于每个单元格左上角坐标点的偏移值。width和height是box的宽和长，但是值是相对于整个图片的宽与高的比例，这样子前4个元素的大小在$[0,1]$ 。confidence表示predicted box和any ground truth box 之间的IOU
- 分类问题：每个单元格预测 $ C$  个类别的概率值，$ Pr(Class_i|Object)$ 这些概率值取决于包含该对象的单元格。不管一个单元格预测多少个边界框，其只预测一组类别概率值，这是Yolo算法的一个缺点。
- 现在可以得到各个边界框的类别置信度（class-confidence scores）,这些socres同时编码了box类别的概率和box的accuracy
  - $Pr(Class_i|Object) * Pr(Object) * IOU^{truth}_{pred} = Pr(Class_i) * IOU^{truth}_{pred}  (1)$



![](./img/grid_cell.jpg)

- 图中的预测被编码为一个tensor,它的形状为
  - $S \times S \times(B*5+C)$

- 在PASCAL VOC上评估YOLO， 使用S = 7，B = 2。PASCAL VOC有20个被标记的classes ，所以C = 20。所以最后的预测是一个7 * 7 * 30的tensor



### 网络设计



![](./img/network_design.jpg).

- 网络的初始卷积层提取图片的的特征，全连接层预测输出的概率和坐标
- 网络用GoogLeNet模型来对图片分类，网络有24个卷积层，并且紧跟着两个全连接层，接着用1 * 1的卷积层，然后是3*3的卷积层。对于卷积层和全连接层，采用Leaky ReLU激活函数：$ max(x,0.1x)$。但是最后一层却采用线性激活函数。
- YOLO的快速版本只有9个卷积层
- 对于每一个单元格，输出$7 \times 7 \times 30$前20个元素是类别概率值，然后2个元素是边界框置信度，两者相乘可以得到类别置信度，最后8个元素是边界框的$(x,y,w,h)$ 。为了计算方便，对于边界框把置信度 $C$ 和 $(x,y,w,h)$ 都分开排列，而不是按照$(x,y,w,h,C)$ 这样排列。因为实际上这30个元素都是对应一个单元格，其排列是可以任意的。但是分离排布，可以方便地提取每一个部分。这里来解释一下，首先网络的预测值是一个二维张量 $P$ ，其shape为 $[barch,7 \times 7 \times 30]$。采用切片，那么 $P_{[:,7 *7*20]}$就是类别概率部分，而 $P_{[:,7*7*20:7*7*(20+2)]}$是置信度部分，最后剩余部分 $P_{[:,7*7*(20+2):]}$ 是边界框的预测结果。这样，提取每个部分是非常方便的，这会方面后面的训练及预测时的计算。



### Training

- 在ImageNet 1000-class competition dataset上预训练卷积层。为了预训练，使用前20个卷积层，然后接着一个average-poolig层和一个全连接层
- 预训练之后，加上四个卷积层和两个全连接层，它们带有随机初始化的值。检测通常需要细粒度化的视觉信息，所以把图片从224*224 增加到448 * 448
- 最后一层同时预测类别概率和box坐标。用图片的width和height对box的width和height进行正则化，所以它们的值在 $[0,1]$之间。将边界框x和y坐标参数化为网格单元位置的偏移量，因此它们也在0和1之间有界。
- 最后一层使用线性激活函数，其他层使用下面的泄漏整流线性激活函数

​															$$ \phi(x) = \begin{cases}x \text{,        if  x > 0} \\ 0.1x \text{,   otherwise}\end{cases} $$


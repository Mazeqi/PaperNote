{"cells":[{"metadata":{},"cell_type":"markdown","source":"Here, i did basic EDA https://www.kaggle.com/yaroslavmavliutov/riiid-answer-correctness-prediction-basic-eda"},{"metadata":{},"cell_type":"markdown","source":"## Import necessary libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"# model\nimport time\nimport itertools    \nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as Data\nfrom sklearn.metrics import *\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nfrom torch.nn.utils.rnn import PackedSequence\nfrom torch.optim import lr_scheduler\n\ntry:\n    from tensorflow.python.keras.callbacks import CallbackList\nexcept ImportError:\n    from tensorflow.python.keras._impl.keras.callbacks import CallbackList\n    \nfrom collections import OrderedDict, namedtuple, defaultdict\nfrom itertools import chain\n\n# -------------------------------------------------------------------------------------\n# activation\nclass Dice(nn.Module):\n    \"\"\"The Data Adaptive Activation Function in DIN,which can be viewed as a generalization of PReLu and can adaptively adjust the rectified point according to distribution of input data.\n\n    Input shape:\n        - 2 dims: [batch_size, embedding_size(features)]\n        - 3 dims: [batch_size, num_features, embedding_size(features)]\n\n    Output shape:\n        - Same shape as input.\n    \n    References\n        - [Zhou G, Zhu X, Song C, et al. Deep interest network for click-through rate prediction[C]//Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. ACM, 2018: 1059-1068.](https://arxiv.org/pdf/1706.06978.pdf)\n        - https://github.com/zhougr1993/DeepInterestNetwork, https://github.com/fanoping/DIN-pytorch\n    \"\"\"\n    def __init__(self, emb_size, dim=2, epsilon=1e-8, device='cpu'):\n        super(Dice, self).__init__()\n        assert dim == 2 or dim == 3\n\n        self.bn = nn.BatchNorm1d(emb_size, eps=epsilon)\n        self.sigmoid = nn.Sigmoid()\n        self.dim = dim\n\n        if self.dim == 2:\n            self.alpha = torch.zeros((emb_size,)).to(device)\n        else:\n            self.alpha = torch.zeros((emb_size, 1)).to(device)\n\n    def forward(self, x):\n        assert x.dim() == self.dim\n        if self.dim == 2:\n            x_p = self.sigmoid(self.bn(x))\n            out = self.alpha * (1 - x_p) * x + x_p * x\n        else:\n            x = torch.transpose(x, 1, 2)\n            x_p = self.sigmoid(self.bn(x))\n            out = self.alpha * (1 - x_p) * x + x_p * x\n            out = torch.transpose(out, 1, 2)\n        \n        return out\n\n\nclass Identity(nn.Module):\n\n\n    def __init__(self, **kwargs):\n        super(Identity, self).__init__()\n\n    def forward(self, X):\n        return X\n\n\ndef activation_layer(act_name, hidden_size=None, dice_dim=2):\n    \"\"\"Construct activation layers\n\n    Args:\n        act_name: str or nn.Module, name of activation function\n        hidden_size: int, used for Dice activation\n        dice_dim: int, used for Dice activation\n    Return:\n        act_layer: activation layer\n    \"\"\"\n    if isinstance(act_name, str):\n        if act_name.lower() == 'sigmoid':\n            act_layer = nn.Sigmoid()\n        elif act_name.lower() == 'linear':\n            act_layer = Identity()\n        elif act_name.lower() == 'relu':\n            act_layer = nn.ReLU(inplace=True)\n        elif act_name.lower() == 'dice':\n            assert dice_dim\n            act_layer = Dice(hidden_size, dice_dim)\n        elif act_name.lower() == 'prelu':\n            act_layer = nn.PReLU()\n    elif issubclass(act_name, nn.Module):\n        act_layer = act_name()\n    else:\n        raise NotImplementedError\n\n    return act_layer\n\n\nclass LocalActivationUnit(nn.Module):\n    \"\"\"The LocalActivationUnit used in DIN with which the representation of\n        user interests varies adaptively given different candidate items.\n\n    Input shape\n        - A list of two 3D tensor with shape:  ``(batch_size, 1, embedding_size)`` and ``(batch_size, T, embedding_size)``\n\n    Output shape\n        - 3D tensor with shape: ``(batch_size, T, 1)``.\n\n    Arguments\n        - **hidden_units**:list of positive integer, the attention net layer number and units in each layer.\n\n        - **activation**: Activation function to use in attention net.\n\n        - **l2_reg**: float between 0 and 1. L2 regularizer strength applied to the kernel weights matrix of attention net.\n\n        - **dropout_rate**: float in [0,1). Fraction of the units to dropout in attention net.\n\n        - **use_bn**: bool. Whether use BatchNormalization before activation or not in attention net.\n\n        - **seed**: A Python integer to use as random seed.\n\n    References\n        - [Zhou G, Zhu X, Song C, et al. Deep interest network for click-through rate prediction[C]//Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. ACM, 2018: 1059-1068.](https://arxiv.org/pdf/1706.06978.pdf)\n    \"\"\"\n\n    def __init__(self, hidden_units=(64, 32), embedding_dim=4, activation='sigmoid', dropout_rate=0, dice_dim=3,\n                 l2_reg=0, use_bn=False):\n        super(LocalActivationUnit, self).__init__()\n\n        self.dnn = DNN(inputs_dim=4 * embedding_dim,\n                       hidden_units=hidden_units,\n                       activation=activation,\n                       l2_reg=l2_reg,\n                       dropout_rate=dropout_rate,\n                       dice_dim=dice_dim,\n                       use_bn=use_bn)\n\n        self.dense = nn.Linear(hidden_units[-1], 1)\n\n    def forward(self, query, user_behavior):\n        # query ad            : size -> batch_size * 1 * embedding_size\n        # user behavior       : size -> batch_size * time_seq_len * embedding_size\n        user_behavior_len = user_behavior.size(1)\n\n        queries = query.expand(-1, user_behavior_len, -1)\n\n        attention_input = torch.cat([queries, user_behavior, queries - user_behavior, queries * user_behavior],\n                                    dim=-1)  # as the source code, subtraction simulates verctors' difference\n        attention_output = self.dnn(attention_input)\n\n        attention_score = self.dense(attention_output)  # [B, T, 1]\n\n        return attention_score\n\n\n#--------------------------------------------------------------------------------------------------------------\n# core\nclass DNN(nn.Module):\n    \"\"\"The Multi Layer Percetron\n\n      Input shape\n        - nD tensor with shape: ``(batch_size, ..., input_dim)``. The most common situation would be a 2D input with shape ``(batch_size, input_dim)``.\n\n      Output shape\n        - nD tensor with shape: ``(batch_size, ..., hidden_size[-1])``. For instance, for a 2D input with shape ``(batch_size, input_dim)``, the output would have shape ``(batch_size, hidden_size[-1])``.\n\n      Arguments\n        - **inputs_dim**: input feature dimension.\n\n        - **hidden_units**:list of positive integer, the layer number and units in each layer.\n\n        - **activation**: Activation function to use.\n\n        - **l2_reg**: float between 0 and 1. L2 regularizer strength applied to the kernel weights matrix.\n\n        - **dropout_rate**: float in [0,1). Fraction of the units to dropout.\n\n        - **use_bn**: bool. Whether use BatchNormalization before activation or not.\n\n        - **seed**: A Python integer to use as random seed.\n    \"\"\"\n\n    def __init__(self, inputs_dim, hidden_units, activation='relu', l2_reg=0, dropout_rate=0, use_bn=False,\n                 init_std=0.0001, dice_dim=3, seed=1024, device='cpu'):\n        super(DNN, self).__init__()\n        self.dropout_rate = dropout_rate\n        self.dropout = nn.Dropout(dropout_rate)\n        self.seed = seed\n        self.l2_reg = l2_reg\n        self.use_bn = use_bn\n        if len(hidden_units) == 0:\n            raise ValueError(\"hidden_units is empty!!\")\n        hidden_units = [inputs_dim] + list(hidden_units)\n\n        self.linears = nn.ModuleList(\n            [nn.Linear(hidden_units[i], hidden_units[i + 1]) for i in range(len(hidden_units) - 1)])\n\n        if self.use_bn:\n            self.bn = nn.ModuleList(\n                [nn.BatchNorm1d(hidden_units[i + 1]) for i in range(len(hidden_units) - 1)])\n\n        self.activation_layers = nn.ModuleList(\n            [activation_layer(activation, hidden_units[i + 1], dice_dim) for i in range(len(hidden_units) - 1)])\n\n        for name, tensor in self.linears.named_parameters():\n            if 'weight' in name:\n                nn.init.normal_(tensor, mean=0, std=init_std)\n\n        self.to(device)\n\n    def forward(self, inputs):\n        deep_input = inputs\n\n        for i in range(len(self.linears)):\n\n            fc = self.linears[i](deep_input)\n\n            if self.use_bn:\n                fc = self.bn[i](fc)\n\n            fc = self.activation_layers[i](fc)\n\n            fc = self.dropout(fc)\n            deep_input = fc\n        return deep_input\n\n\nclass PredictionLayer(nn.Module):\n    \"\"\"\n      Arguments\n         - **task**: str, ``\"binary\"`` for  binary logloss or  ``\"regression\"`` for regression loss\n         - **use_bias**: bool.Whether add bias term or not.\n    \"\"\"\n\n    def __init__(self, task='binary', use_bias=True, **kwargs):\n        if task not in [\"binary\", \"multiclass\", \"regression\"]:\n            raise ValueError(\"task must be binary,multiclass or regression\")\n\n        super(PredictionLayer, self).__init__()\n        self.use_bias = use_bias\n        self.task = task\n        if self.use_bias:\n            self.bias = nn.Parameter(torch.zeros((1,)))\n\n    def forward(self, X):\n        output = X\n        if self.use_bias:\n            output += self.bias\n        if self.task == \"binary\":\n            output = torch.sigmoid(output)\n        return output\n\n\nclass Conv2dSame(nn.Conv2d):\n    \"\"\" Tensorflow like 'SAME' convolution wrapper for 2D convolutions\n    \"\"\"\n\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n                 padding=0, dilation=1, groups=1, bias=True):\n        super(Conv2dSame, self).__init__(\n            in_channels, out_channels, kernel_size, stride, 0, dilation,\n            groups, bias)\n        nn.init.xavier_uniform_(self.weight)\n\n    def forward(self, x):\n        ih, iw = x.size()[-2:]\n        kh, kw = self.weight.size()[-2:]\n        oh = math.ceil(ih / self.stride[0])\n        ow = math.ceil(iw / self.stride[1])\n        pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)\n        pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)\n        if pad_h > 0 or pad_w > 0:\n            x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2])\n        out = F.conv2d(x, self.weight, self.bias, self.stride,\n                       self.padding, self.dilation, self.groups)\n        return out\n\n    \n\n#-------------------------------------------------------------------------\n# sequence\nclass SequencePoolingLayer(nn.Module):\n    \"\"\"The SequencePoolingLayer is used to apply pooling operation(sum,mean,max) on variable-length sequence feature/multi-value feature.\n\n      Input shape\n        - A list of two  tensor [seq_value,seq_len]\n\n        - seq_value is a 3D tensor with shape: ``(batch_size, T, embedding_size)``\n\n        - seq_len is a 2D tensor with shape : ``(batch_size, 1)``,indicate valid length of each sequence.\n\n      Output shape\n        - 3D tensor with shape: ``(batch_size, 1, embedding_size)``.\n\n      Arguments\n        - **mode**:str.Pooling operation to be used,can be sum,mean or max.\n\n    \"\"\"\n\n    def __init__(self, mode='mean', supports_masking=False, device='cpu'):\n\n        super(SequencePoolingLayer, self).__init__()\n        if mode not in ['sum', 'mean', 'max']:\n            raise ValueError('parameter mode should in [sum, mean, max]')\n        self.supports_masking = supports_masking\n        self.mode = mode\n        self.device = device\n        self.eps = torch.FloatTensor([1e-8]).to(device)\n        self.to(device)\n\n    def _sequence_mask(self, lengths, maxlen=None, dtype=torch.bool):\n        # Returns a mask tensor representing the first N positions of each cell.\n        if maxlen is None:\n            maxlen = lengths.max()\n        row_vector = torch.arange(0, maxlen, 1).to(self.device)\n        matrix = torch.unsqueeze(lengths, dim=-1)\n        mask = row_vector < matrix\n\n        mask.type(dtype)\n        return mask\n\n    def forward(self, seq_value_len_list):\n        if self.supports_masking:\n            uiseq_embed_list, mask = seq_value_len_list  # [B, T, E], [B, 1]\n            mask = mask.float()\n            user_behavior_length = torch.sum(mask, dim=-1, keepdim=True)\n            mask = mask.unsqueeze(2)\n        else:\n            uiseq_embed_list, user_behavior_length = seq_value_len_list  # [B, T, E], [B, 1]\n            mask = self._sequence_mask(user_behavior_length, maxlen=uiseq_embed_list.shape[1],\n                                       dtype=torch.float32)  # [B, 1, maxlen]\n            mask = torch.transpose(mask, 1, 2)  # [B, maxlen, 1]\n\n        embedding_size = uiseq_embed_list.shape[-1]\n\n        mask = torch.repeat_interleave(mask, embedding_size, dim=2)  # [B, maxlen, E]\n\n        if self.mode == 'max':\n            hist = uiseq_embed_list - (1 - mask) * 1e9\n            hist = torch.max(hist, dim=1, keepdim=True)[0]\n            return hist\n        hist = uiseq_embed_list * mask.float()\n        hist = torch.sum(hist, dim=1, keepdim=False)\n\n        if self.mode == 'mean':\n            hist = torch.div(hist, user_behavior_length.type(torch.float32) + self.eps)\n\n        hist = torch.unsqueeze(hist, dim=1)\n        return hist\n\n\nclass AttentionSequencePoolingLayer(nn.Module):\n    \"\"\"The Attentional sequence pooling operation used in DIN & DIEN.\n\n        Arguments\n          - **att_hidden_units**:list of positive integer, the attention net layer number and units in each layer.\n\n          - **att_activation**: Activation function to use in attention net.\n\n          - **weight_normalization**: bool.Whether normalize the attention score of local activation unit.\n\n          - **supports_masking**:If True,the input need to support masking.\n\n        References\n          - [Zhou G, Zhu X, Song C, et al. Deep interest network for click-through rate prediction[C]//Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. ACM, 2018: 1059-1068.](https://arxiv.org/pdf/1706.06978.pdf)\n      \"\"\"\n\n    def __init__(self, att_hidden_units=(80, 40), att_activation='sigmoid', weight_normalization=False,\n                 return_score=False, supports_masking=False, embedding_dim=4, **kwargs):\n        super(AttentionSequencePoolingLayer, self).__init__()\n        self.return_score = return_score\n        self.weight_normalization = weight_normalization\n        self.supports_masking = supports_masking\n        self.local_att = LocalActivationUnit(hidden_units=att_hidden_units, embedding_dim=embedding_dim,\n                                             activation=att_activation,\n                                             dropout_rate=0, use_bn=False)\n\n    def forward(self, query, keys, keys_length, mask=None):\n        \"\"\"\n        Input shape\n          - A list of three tensor: [query,keys,keys_length]\n\n          - query is a 3D tensor with shape:  ``(batch_size, 1, embedding_size)``\n\n          - keys is a 3D tensor with shape:   ``(batch_size, T, embedding_size)``\n\n          - keys_length is a 2D tensor with shape: ``(batch_size, 1)``\n\n        Output shape\n          - 3D tensor with shape: ``(batch_size, 1, embedding_size)``.\n        \"\"\"\n        batch_size, max_length, dim = keys.size()\n\n        # Mask\n        if self.supports_masking:\n            if mask is None:\n                raise ValueError(\"When supports_masking=True,input must support masking\")\n            keys_masks = mask.unsqueeze(1)\n        else:\n            keys_masks = torch.arange(max_length, device=keys_length.device, dtype=keys_length.dtype).repeat(batch_size,\n                                                                                                             1)  # [B, T]\n            keys_masks = keys_masks < keys_length.view(-1, 1)  # 0, 1 mask\n            keys_masks = keys_masks.unsqueeze(1)  # [B, 1, T]\n\n        attention_score = self.local_att(query, keys)  # [B, T, 1]\n\n        outputs = torch.transpose(attention_score, 1, 2)  # [B, 1, T]\n\n        if self.weight_normalization:\n            paddings = torch.ones_like(outputs) * (-2 ** 32 + 1)\n        else:\n            paddings = torch.zeros_like(outputs)\n\n        outputs = torch.where(keys_masks, outputs, paddings)  # [B, 1, T]\n\n        # Scale\n        # outputs = outputs / (keys.shape[-1] ** 0.05)\n\n        if self.weight_normalization:\n            outputs = F.softmax(outputs, dim=-1)  # [B, 1, T]\n\n        if not self.return_score:\n            # Weighted sum\n            outputs = torch.matmul(outputs, keys)  # [B, 1, E]\n\n        return outputs\n\n\nclass KMaxPooling(nn.Module):\n    \"\"\"K Max pooling that selects the k biggest value along the specific axis.\n\n      Input shape\n        -  nD tensor with shape: ``(batch_size, ..., input_dim)``.\n\n      Output shape\n        - nD tensor with shape: ``(batch_size, ..., output_dim)``.\n\n      Arguments\n        - **k**: positive integer, number of top elements to look for along the ``axis`` dimension.\n\n        - **axis**: positive integer, the dimension to look for elements.\n\n     \"\"\"\n\n    def __init__(self, k, axis, device='cpu'):\n        super(KMaxPooling, self).__init__()\n        self.k = k\n        self.axis = axis\n        self.to(device)\n\n    def forward(self, input):\n        if self.axis < 0 or self.axis >= len(input.shape):\n            raise ValueError(\"axis must be 0~%d,now is %d\" %\n                             (len(input.shape) - 1, self.axis))\n\n        if self.k < 1 or self.k > input.shape[self.axis]:\n            raise ValueError(\"k must be in 1 ~ %d,now k is %d\" %\n                             (input.shape[self.axis], self.k))\n\n        out = torch.topk(input, k=self.k, dim=self.axis, sorted=True)[0]\n        return out\n\n\nclass AGRUCell(nn.Module):\n    \"\"\" Attention based GRU (AGRU)\n\n        Reference:\n        -  Deep Interest Evolution Network for Click-Through Rate Prediction[J]. arXiv preprint arXiv:1809.03672, 2018.\n    \"\"\"\n\n    def __init__(self, input_size, hidden_size, bias=True):\n        super(AGRUCell, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.bias = bias\n        # (W_ir|W_iz|W_ih)\n        self.weight_ih = nn.Parameter(torch.Tensor(3 * hidden_size, input_size))\n        self.register_parameter('weight_ih', self.weight_ih)\n        # (W_hr|W_hz|W_hh)\n        self.weight_hh = nn.Parameter(torch.Tensor(3 * hidden_size, hidden_size))\n        self.register_parameter('weight_hh', self.weight_hh)\n        if bias:\n            # (b_ir|b_iz|b_ih)\n            self.bias_ih = nn.Parameter(torch.Tensor(3 * hidden_size))\n            self.register_parameter('bias_ih', self.bias_ih)\n            # (b_hr|b_hz|b_hh)\n            self.bias_hh = nn.Parameter(torch.Tensor(3 * hidden_size))\n            self.register_parameter('bias_hh', self.bias_hh)\n            for tensor in [self.bias_ih, self.bias_hh]:\n                nn.init.zeros_(tensor, )\n        else:\n            self.register_parameter('bias_ih', None)\n            self.register_parameter('bias_hh', None)\n\n    def forward(self, input, hx, att_score):\n        gi = F.linear(input, self.weight_ih, self.bias_ih)\n        gh = F.linear(hx, self.weight_hh, self.bias_hh)\n        i_r, i_z, i_n = gi.chunk(3, 1)\n        h_r, h_z, h_n = gh.chunk(3, 1)\n\n        reset_gate = torch.sigmoid(i_r + h_r)\n        # update_gate = torch.sigmoid(i_z + h_z)\n        new_state = torch.tanh(i_n + reset_gate * h_n)\n\n        att_score = att_score.view(-1, 1)\n        hy = (1. - att_score) * hx + att_score * new_state\n        return hy\n\n\nclass AUGRUCell(nn.Module):\n    \"\"\" Effect of GRU with attentional update gate (AUGRU)\n\n        Reference:\n        -  Deep Interest Evolution Network for Click-Through Rate Prediction[J]. arXiv preprint arXiv:1809.03672, 2018.\n    \"\"\"\n\n    def __init__(self, input_size, hidden_size, bias=True):\n        super(AUGRUCell, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.bias = bias\n        # (W_ir|W_iz|W_ih)\n        self.weight_ih = nn.Parameter(torch.Tensor(3 * hidden_size, input_size))\n        self.register_parameter('weight_ih', self.weight_ih)\n        # (W_hr|W_hz|W_hh)\n        self.weight_hh = nn.Parameter(torch.Tensor(3 * hidden_size, hidden_size))\n        self.register_parameter('weight_hh', self.weight_hh)\n        if bias:\n            # (b_ir|b_iz|b_ih)\n            self.bias_ih = nn.Parameter(torch.Tensor(3 * hidden_size))\n            self.register_parameter('bias_ih', self.bias_ih)\n            # (b_hr|b_hz|b_hh)\n            self.bias_hh = nn.Parameter(torch.Tensor(3 * hidden_size))\n            self.register_parameter('bias_ih', self.bias_hh)\n            for tensor in [self.bias_ih, self.bias_hh]:\n                nn.init.zeros_(tensor, )\n        else:\n            self.register_parameter('bias_ih', None)\n            self.register_parameter('bias_hh', None)\n\n    def forward(self, input, hx, att_score):\n        gi = F.linear(input, self.weight_ih, self.bias_ih)\n        gh = F.linear(hx, self.weight_hh, self.bias_hh)\n        i_r, i_z, i_n = gi.chunk(3, 1)\n        h_r, h_z, h_n = gh.chunk(3, 1)\n\n        reset_gate = torch.sigmoid(i_r + h_r)\n        update_gate = torch.sigmoid(i_z + h_z)\n        new_state = torch.tanh(i_n + reset_gate * h_n)\n\n        att_score = att_score.view(-1, 1)\n        update_gate = att_score * update_gate\n        hy = (1. - update_gate) * hx + update_gate * new_state\n        return hy\n\n\nclass DynamicGRU(nn.Module):\n    def __init__(self, input_size, hidden_size, bias=True, gru_type='AGRU'):\n        super(DynamicGRU, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n\n        if gru_type == 'AGRU':\n            self.rnn = AGRUCell(input_size, hidden_size, bias)\n        elif gru_type == 'AUGRU':\n            self.rnn = AUGRUCell(input_size, hidden_size, bias)\n\n    def forward(self, input, att_scores=None, hx=None):\n        if not isinstance(input, PackedSequence) or not isinstance(att_scores, PackedSequence):\n            raise NotImplementedError(\"DynamicGRU only supports packed input and att_scores\")\n\n        input, batch_sizes, sorted_indices, unsorted_indices = input\n        att_scores, _, _, _ = att_scores\n\n        max_batch_size = int(batch_sizes[0])\n        if hx is None:\n            hx = torch.zeros(max_batch_size, self.hidden_size,\n                             dtype=input.dtype, device=input.device)\n\n        outputs = torch.zeros(input.size(0), self.hidden_size,\n                              dtype=input.dtype, device=input.device)\n\n        begin = 0\n        for batch in batch_sizes:\n            new_hx = self.rnn(\n                input[begin:begin + batch],\n                hx[0:batch],\n                att_scores[begin:begin + batch])\n            outputs[begin:begin + batch] = new_hx\n            hx = new_hx\n            begin += batch\n        return PackedSequence(outputs, batch_sizes, sorted_indices, unsorted_indices)\n\n# utils\n#-------------------------------------------------------------------------------------\ndef concat_fun(inputs, axis=-1):\n    if len(inputs) == 1:\n        return inputs[0]\n    else:\n        return torch.cat(inputs, dim=axis)\n\n\ndef slice_arrays(arrays, start=None, stop=None):\n    \"\"\"Slice an array or list of arrays.\n\n    This takes an array-like, or a list of\n    array-likes, and outputs:\n        - arrays[start:stop] if `arrays` is an array-like\n        - [x[start:stop] for x in arrays] if `arrays` is a list\n\n    Can also work on list/array of indices: `slice_arrays(x, indices)`\n\n    Arguments:\n        arrays: Single array or list of arrays.\n        start: can be an integer index (start index)\n            or a list/array of indices\n        stop: integer (stop index); should be None if\n            `start` was a list.\n\n    Returns:\n        A slice of the array(s).\n\n    Raises:\n        ValueError: If the value of start is a list and stop is not None.\n    \"\"\"\n\n    if arrays is None:\n        return [None]\n\n    if isinstance(arrays, np.ndarray):\n        arrays = [arrays]\n\n    if isinstance(start, list) and stop is not None:\n        raise ValueError('The stop argument has to be None if the value of start '\n                         'is a list.')\n    elif isinstance(arrays, list):\n        if hasattr(start, '__len__'):\n            # hdf5 datasets only support list objects as indices\n            if hasattr(start, 'shape'):\n                start = start.tolist()\n            return [None if x is None else x[start] for x in arrays]\n        else:\n            if len(arrays) == 1:\n                return arrays[0][start:stop]\n            return [None if x is None else x[start:stop] for x in arrays]\n    else:\n        if hasattr(start, '__len__'):\n            if hasattr(start, 'shape'):\n                start = start.tolist()\n            return arrays[start]\n        elif hasattr(start, '__getitem__'):\n            return arrays[start:stop]\n        else:\n            return [None]\n\n#inputs\n#-------------------------------------------------------------------------------------\nDEFAULT_GROUP_NAME = \"default_group\"\n\n\nclass SparseFeat(namedtuple('SparseFeat',\n                            ['name', 'vocabulary_size', 'embedding_dim', 'use_hash', 'dtype', 'embedding_name',\n                             'group_name'])):\n    __slots__ = ()\n\n    def __new__(cls, name, vocabulary_size, embedding_dim=4, use_hash=False, dtype=\"int32\", embedding_name=None,\n                group_name=DEFAULT_GROUP_NAME):\n        if embedding_name is None:\n            embedding_name = name\n        if embedding_dim == \"auto\":\n            embedding_dim = 6 * int(pow(vocabulary_size, 0.25))\n        if use_hash:\n            print(\n                \"Notice! Feature Hashing on the fly currently is not supported in torch version,you can use tensorflow version!\")\n        return super(SparseFeat, cls).__new__(cls, name, vocabulary_size, embedding_dim, use_hash, dtype,\n                                              embedding_name, group_name)\n\n    def __hash__(self):\n        return self.name.__hash__()\n\n\nclass VarLenSparseFeat(namedtuple('VarLenSparseFeat',\n                                  ['sparsefeat', 'maxlen', 'combiner', 'length_name'])):\n    __slots__ = ()\n\n    def __new__(cls, sparsefeat, maxlen, combiner=\"mean\", length_name=None):\n        return super(VarLenSparseFeat, cls).__new__(cls, sparsefeat, maxlen, combiner, length_name)\n\n    @property\n    def name(self):\n        return self.sparsefeat.name\n\n    @property\n    def vocabulary_size(self):\n        return self.sparsefeat.vocabulary_size\n\n    @property\n    def embedding_dim(self):\n        return self.sparsefeat.embedding_dim\n\n    @property\n    def dtype(self):\n        return self.sparsefeat.dtype\n\n    @property\n    def embedding_name(self):\n        return self.sparsefeat.embedding_name\n\n    @property\n    def group_name(self):\n        return self.sparsefeat.group_name\n\n    def __hash__(self):\n        return self.name.__hash__()\n\n\nclass DenseFeat(namedtuple('DenseFeat', ['name', 'dimension', 'dtype'])):\n    __slots__ = ()\n\n    def __new__(cls, name, dimension=1, dtype=\"float32\"):\n        return super(DenseFeat, cls).__new__(cls, name, dimension, dtype)\n\n    def __hash__(self):\n        return self.name.__hash__()\n\n\ndef get_feature_names(feature_columns):\n    features = build_input_features(feature_columns)\n    return list(features.keys())\n\n\n# def get_inputs_list(inputs):\n#     return list(chain(*list(map(lambda x: x.values(), filter(lambda x: x is not None, inputs)))))\n\n\ndef build_input_features(feature_columns):\n    # Return OrderedDict: {feature_name:(start, start+dimension)}\n\n    features = OrderedDict()\n\n    start = 0\n    for feat in feature_columns:\n        feat_name = feat.name\n        if feat_name in features:\n            continue\n        if isinstance(feat, SparseFeat):\n            features[feat_name] = (start, start + 1)\n            start += 1\n        elif isinstance(feat, DenseFeat):\n            features[feat_name] = (start, start + feat.dimension)\n            start += feat.dimension\n        elif isinstance(feat, VarLenSparseFeat):\n            features[feat_name] = (start, start + feat.maxlen)\n            start += feat.maxlen\n            if feat.length_name is not None and feat.length_name not in features:\n                features[feat.length_name] = (start, start + 1)\n                start += 1\n        else:\n            raise TypeError(\"Invalid feature column type,got\", type(feat))\n    return features\n\n\ndef combined_dnn_input(sparse_embedding_list, dense_value_list):\n    if len(sparse_embedding_list) > 0 and len(dense_value_list) > 0:\n        sparse_dnn_input = torch.flatten(\n            torch.cat(sparse_embedding_list, dim=-1), start_dim=1)\n        dense_dnn_input = torch.flatten(\n            torch.cat(dense_value_list, dim=-1), start_dim=1)\n        return concat_fun([sparse_dnn_input, dense_dnn_input])\n    elif len(sparse_embedding_list) > 0:\n        return torch.flatten(torch.cat(sparse_embedding_list, dim=-1), start_dim=1)\n    elif len(dense_value_list) > 0:\n        return torch.flatten(torch.cat(dense_value_list, dim=-1), start_dim=1)\n    else:\n        raise NotImplementedError\n\n\ndef get_varlen_pooling_list(embedding_dict, features, feature_index, varlen_sparse_feature_columns, device):\n    varlen_sparse_embedding_list = []\n\n    for feat in varlen_sparse_feature_columns:\n        seq_emb = embedding_dict[feat.embedding_name](\n            features[:, feature_index[feat.name][0]:feature_index[feat.name][1]].long())\n        if feat.length_name is None:\n            seq_mask = features[:, feature_index[feat.name][0]:feature_index[feat.name][1]].long() != 0\n\n            emb = SequencePoolingLayer(mode=feat.combiner, supports_masking=True, device=device)(\n                [seq_emb, seq_mask])\n        else:\n            seq_length = features[:,\n                         feature_index[feat.length_name][0]:feature_index[feat.length_name][1]].long()\n            emb = SequencePoolingLayer(mode=feat.combiner, supports_masking=False, device=device)(\n                [seq_emb, seq_length])\n        varlen_sparse_embedding_list.append(emb)\n    return varlen_sparse_embedding_list\n\n\ndef create_embedding_matrix(feature_columns, init_std=0.0001, linear=False, sparse=False, device='cpu'):\n    # Return nn.ModuleDict: for sparse features, {embedding_name: nn.Embedding}\n    # for varlen sparse features, {embedding_name: nn.EmbeddingBag}\n    sparse_feature_columns = list(\n        filter(lambda x: isinstance(x, SparseFeat), feature_columns)) if len(feature_columns) else []\n\n    varlen_sparse_feature_columns = list(\n        filter(lambda x: isinstance(x, VarLenSparseFeat), feature_columns)) if len(feature_columns) else []\n\n    embedding_dict = nn.ModuleDict(\n        {feat.embedding_name: nn.Embedding(feat.vocabulary_size, feat.embedding_dim if not linear else 1, sparse=sparse)\n         for feat in\n         sparse_feature_columns + varlen_sparse_feature_columns}\n    )\n\n    # for feat in varlen_sparse_feature_columns:\n    #     embedding_dict[feat.embedding_name] = nn.EmbeddingBag(\n    #         feat.dimension, embedding_size, sparse=sparse, mode=feat.combiner)\n\n    for tensor in embedding_dict.values():\n        nn.init.normal_(tensor.weight, mean=0, std=init_std)\n\n    return embedding_dict.to(device)\n\n\ndef input_from_feature_columns(self, X, feature_columns, embedding_dict, support_dense=True):\n    sparse_feature_columns = list(\n        filter(lambda x: isinstance(x, SparseFeat), feature_columns)) if len(feature_columns) else []\n    dense_feature_columns = list(\n        filter(lambda x: isinstance(x, DenseFeat), feature_columns)) if len(feature_columns) else []\n\n    varlen_sparse_feature_columns = list(\n        filter(lambda x: isinstance(x, VarLenSparseFeat), feature_columns)) if feature_columns else []\n\n    if not support_dense and len(dense_feature_columns) > 0:\n        raise ValueError(\n            \"DenseFeat is not supported in dnn_feature_columns\")\n\n    sparse_embedding_list = [embedding_dict[feat.embedding_name](\n        X[:, self.feature_index[feat.name][0]:self.feature_index[feat.name][1]].long()) for\n        feat in sparse_feature_columns]\n\n    varlen_sparse_embedding_list = get_varlen_pooling_list(self.embedding_dict, X, self.feature_index,\n                                                           varlen_sparse_feature_columns, self.device)\n\n    dense_value_list = [X[:, self.feature_index[feat.name][0]:self.feature_index[feat.name][1]] for feat in\n                        dense_feature_columns]\n\n    return sparse_embedding_list + varlen_sparse_embedding_list, dense_value_list\n\n\n\ndef embedding_lookup(X, sparse_embedding_dict, sparse_input_dict, sparse_feature_columns, return_feat_list=(),\n                     mask_feat_list=(), to_list=False):\n    \"\"\"\n        Args:\n            X: input Tensor [batch_size x hidden_dim]\n            sparse_embedding_dict: nn.ModuleDict, {embedding_name: nn.Embedding}\n            sparse_input_dict: OrderedDict, {feature_name:(start, start+dimension)}\n            sparse_feature_columns: list, sparse features\n            return_feat_list: list, names of feature to be returned, defualt () -> return all features\n            mask_feat_list, list, names of feature to be masked in hash transform\n        Return:\n            group_embedding_dict: defaultdict(list)\n    \"\"\"\n    group_embedding_dict = defaultdict(list)\n    for fc in sparse_feature_columns:\n        feature_name = fc.name\n        embedding_name = fc.embedding_name\n        if (len(return_feat_list) == 0 or feature_name in return_feat_list):\n            # TODO: add hash function\n            # if fc.use_hash:\n            #     raise NotImplementedError(\"hash function is not implemented in this version!\")\n            lookup_idx = np.array(sparse_input_dict[feature_name])\n            input_tensor = X[:, lookup_idx[0]:lookup_idx[1]].long()\n            emb = sparse_embedding_dict[embedding_name](input_tensor)\n            group_embedding_dict[fc.group_name].append(emb)\n    if to_list:\n        return list(chain.from_iterable(group_embedding_dict.values()))\n    return group_embedding_dict\n\n\ndef varlen_embedding_lookup(X, embedding_dict, sequence_input_dict, varlen_sparse_feature_columns):\n    varlen_embedding_vec_dict = {}\n    for fc in varlen_sparse_feature_columns:\n        feature_name = fc.name\n        embedding_name = fc.embedding_name\n        if fc.use_hash:\n            # lookup_idx = Hash(fc.vocabulary_size, mask_zero=True)(sequence_input_dict[feature_name])\n            # TODO: add hash function\n            lookup_idx = sequence_input_dict[feature_name]\n        else:\n            lookup_idx = sequence_input_dict[feature_name]\n        varlen_embedding_vec_dict[feature_name] = embedding_dict[embedding_name](\n            X[:, lookup_idx[0]:lookup_idx[1]].long())  # (lookup_idx)\n\n    return varlen_embedding_vec_dict\n\n\ndef get_dense_input(X, features, feature_columns):\n    dense_feature_columns = list(filter(lambda x: isinstance(\n        x, DenseFeat), feature_columns)) if feature_columns else []\n    dense_input_list = []\n    for fc in dense_feature_columns:\n        lookup_idx = np.array(features[fc.name])\n        input_tensor = X[:, lookup_idx[0]:lookup_idx[1]].float()\n        dense_input_list.append(input_tensor)\n    return dense_input_list\n\n\ndef maxlen_lookup(X, sparse_input_dict, maxlen_column):\n    if maxlen_column is None or len(maxlen_column)==0:\n        raise ValueError('please add max length column for VarLenSparseFeat of DIEN input')\n    lookup_idx = np.array(sparse_input_dict[maxlen_column[0]])\n    return X[:, lookup_idx[0]:lookup_idx[1]].long()\n\n\n# basemodel\n#-------------------------------------------------------------------------------------------------\nclass Linear(nn.Module):\n    def __init__(self, feature_columns, feature_index, init_std=0.0001, device='cpu'):\n        super(Linear, self).__init__()\n        self.feature_index = feature_index\n        self.device = device\n        self.sparse_feature_columns = list(\n            filter(lambda x: isinstance(x, SparseFeat), feature_columns)) if len(feature_columns) else []\n        self.dense_feature_columns = list(\n            filter(lambda x: isinstance(x, DenseFeat), feature_columns)) if len(feature_columns) else []\n\n        self.varlen_sparse_feature_columns = list(\n            filter(lambda x: isinstance(x, VarLenSparseFeat), feature_columns)) if len(feature_columns) else []\n\n        self.embedding_dict = create_embedding_matrix(feature_columns, init_std, linear=True, sparse=False,\n                                                      device=device)\n\n        #         nn.ModuleDict(\n        #             {feat.embedding_name: nn.Embedding(feat.dimension, 1, sparse=True) for feat in\n        #              self.sparse_feature_columns}\n        #         )\n        # .to(\"cuda:1\")\n        for tensor in self.embedding_dict.values():\n            nn.init.normal_(tensor.weight, mean=0, std=init_std)\n\n        if len(self.dense_feature_columns) > 0:\n            self.weight = nn.Parameter(torch.Tensor(sum(fc.dimension for fc in self.dense_feature_columns), 1)).to(\n                device)\n            torch.nn.init.normal_(self.weight, mean=0, std=init_std)\n\n    def forward(self, X):\n\n        sparse_embedding_list = [self.embedding_dict[feat.embedding_name](\n            X[:, self.feature_index[feat.name][0]:self.feature_index[feat.name][1]].long()) for\n            feat in self.sparse_feature_columns]\n\n        dense_value_list = [X[:, self.feature_index[feat.name][0]:self.feature_index[feat.name][1]] for feat in\n                            self.dense_feature_columns]\n\n        varlen_embedding_list = get_varlen_pooling_list(self.embedding_dict, X, self.feature_index,\n                                                        self.varlen_sparse_feature_columns, self.device)\n\n        sparse_embedding_list += varlen_embedding_list\n\n        if len(sparse_embedding_list) > 0 and len(dense_value_list) > 0:\n            linear_sparse_logit = torch.sum(\n                torch.cat(sparse_embedding_list, dim=-1), dim=-1, keepdim=False)\n            linear_dense_logit = torch.cat(\n                dense_value_list, dim=-1).matmul(self.weight)\n            linear_logit = linear_sparse_logit + linear_dense_logit\n        elif len(sparse_embedding_list) > 0:\n            linear_logit = torch.sum(\n                torch.cat(sparse_embedding_list, dim=-1), dim=-1, keepdim=False)\n        elif len(dense_value_list) > 0:\n            linear_logit = torch.cat(\n                dense_value_list, dim=-1).matmul(self.weight)\n        else:\n            linear_logit = torch.zeros([X.shape[0], 1])\n        return linear_logit\n\n\nclass BaseModel(nn.Module):\n    def __init__(self, linear_feature_columns, dnn_feature_columns, l2_reg_linear=1e-5, l2_reg_embedding=1e-5,\n                 init_std=0.0001, seed=1024, task='binary', device='cpu'):\n\n        super(BaseModel, self).__init__()\n        torch.manual_seed(seed)\n        self.dnn_feature_columns = dnn_feature_columns\n\n        self.reg_loss = torch.zeros((1,), device=device)\n        self.aux_loss = torch.zeros((1,), device=device)\n        self.device = device  # device\n\n        self.feature_index = build_input_features(\n            linear_feature_columns + dnn_feature_columns)\n        self.dnn_feature_columns = dnn_feature_columns\n\n        self.embedding_dict = create_embedding_matrix(dnn_feature_columns, init_std, sparse=False, device=device)\n        #         nn.ModuleDict(\n        #             {feat.embedding_name: nn.Embedding(feat.dimension, embedding_size, sparse=True) for feat in\n        #              self.dnn_feature_columns}\n        #         )\n\n        self.linear_model = Linear(\n            linear_feature_columns, self.feature_index, device=device)\n\n        self.regularization_weight = []\n\n        self.add_regularization_weight(\n            self.embedding_dict.parameters(), l2_reg_embedding)\n        self.add_regularization_weight(\n            self.linear_model.parameters(), l2_reg_linear)\n\n        self.out = PredictionLayer(task, )\n        self.to(device)\n        self._is_graph_network = True  # used for callbacks\n\n    def fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, initial_epoch=0, validation_split=0.,\n            validation_data=None, shuffle=True, callbacks=None):\n        \"\"\"\n\n        :param x: Numpy array of training data (if the model has a single input), or list of Numpy arrays (if the model has multiple inputs).If input layers in the model are named, you can also pass a\n            dictionary mapping input names to Numpy arrays.\n        :param y: Numpy array of target (label) data (if the model has a single output), or list of Numpy arrays (if the model has multiple outputs).\n        :param batch_size: Integer or `None`. Number of samples per gradient update. If unspecified, `batch_size` will default to 256.\n        :param epochs: Integer. Number of epochs to train the model. An epoch is an iteration over the entire `x` and `y` data provided. Note that in conjunction with `initial_epoch`, `epochs` is to be understood as \"final epoch\". The model is not trained for a number of iterations given by `epochs`, but merely until the epoch of index `epochs` is reached.\n        :param verbose: Integer. 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n        :param initial_epoch: Integer. Epoch at which to start training (useful for resuming a previous training run).\n        :param validation_split: Float between 0 and 1. Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. The validation data is selected from the last samples in the `x` and `y` data provided, before shuffling.\n        :param validation_data: tuple `(x_val, y_val)` or tuple `(x_val, y_val, val_sample_weights)` on which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data. `validation_data` will override `validation_split`.\n        :param shuffle: Boolean. Whether to shuffle the order of the batches at the beginning of each epoch.\n        :param callbacks: List of `deepctr_torch.callbacks.Callback` instances. List of callbacks to apply during training and validation (if ). See [callbacks](https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks). Now available: `EarlyStopping` , `ModelCheckpoint`\n\n        \"\"\"\n        if isinstance(x, dict):\n            x = [x[feature] for feature in self.feature_index]\n\n        do_validation = False\n        if validation_data:\n            do_validation = True\n            if len(validation_data) == 2:\n                val_x, val_y = validation_data\n                val_sample_weight = None\n            elif len(validation_data) == 3:\n                val_x, val_y, val_sample_weight = validation_data  # pylint: disable=unpacking-non-sequence\n            else:\n                raise ValueError(\n                    'When passing a `validation_data` argument, '\n                    'it must contain either 2 items (x_val, y_val), '\n                    'or 3 items (x_val, y_val, val_sample_weights), '\n                    'or alternatively it could be a dataset or a '\n                    'dataset or a dataset iterator. '\n                    'However we received `validation_data=%s`' % validation_data)\n            if isinstance(val_x, dict):\n                val_x = [val_x[feature] for feature in self.feature_index]\n\n        elif validation_split and 0. < validation_split < 1.:\n            do_validation = True\n            if hasattr(x[0], 'shape'):\n                split_at = int(x[0].shape[0] * (1. - validation_split))\n            else:\n                split_at = int(len(x[0]) * (1. - validation_split))\n            x, val_x = (slice_arrays(x, 0, split_at),\n                        slice_arrays(x, split_at))\n            y, val_y = (slice_arrays(y, 0, split_at),\n                        slice_arrays(y, split_at))\n\n        else:\n            val_x = []\n            val_y = []\n        for i in range(len(x)):\n            if len(x[i].shape) == 1:\n                x[i] = np.expand_dims(x[i], axis=1)\n\n        train_tensor_data = Data.TensorDataset(\n            torch.from_numpy(\n                np.concatenate(x, axis=-1)),\n            torch.from_numpy(y))\n        if batch_size is None:\n            batch_size = 256\n        train_loader = DataLoader(\n            dataset=train_tensor_data, shuffle=shuffle, batch_size=batch_size)\n\n        print(self.device, end=\"\\n\")\n        model = self.train()\n        loss_func = self.loss_func\n        optim = self.optim\n        \n        # ------------------------------------------------------------\n        reduceLR      = lr_scheduler.ReduceLROnPlateau(optim, mode='min', factor=0.1, patience=10, verbose=True)\n        \n        sample_num = len(train_tensor_data)\n        steps_per_epoch = (sample_num - 1) // batch_size + 1\n\n        callbacks = CallbackList(callbacks)\n        callbacks.set_model(self)\n        callbacks.on_train_begin()\n        self.stop_training = False  # used for early stopping\n\n        # Train\n        print(\"Train on {0} samples, validate on {1} samples, {2} steps per epoch\".format(\n            len(train_tensor_data), len(val_y), steps_per_epoch))\n        for epoch in range(initial_epoch, epochs):\n            callbacks.on_epoch_begin(epoch)\n            epoch_logs = {}\n            start_time = time.time()\n            loss_epoch = 0\n            total_loss_epoch = 0\n            train_result = {}\n            try:\n                with tqdm(enumerate(train_loader), disable=verbose != 1) as t:\n                    for index, (x_train, y_train) in t:\n                        x = x_train.to(self.device).float()\n                        y = y_train.to(self.device).float()\n\n                        y_pred = model(x).squeeze()\n\n                        optim.zero_grad()\n                        loss = loss_func(y_pred, y.squeeze(), reduction='sum')\n                        reg_loss = self.get_regularization_loss()\n\n                        total_loss = loss + reg_loss + self.aux_loss\n\n                        loss_epoch += loss.item()\n                        total_loss_epoch += total_loss.item()\n                        total_loss.backward(retain_graph=True)\n                        optim.step()\n\n                        if verbose > 0:\n                            for name, metric_fun in self.metrics.items():\n                                if name not in train_result:\n                                    train_result[name] = []\n                                train_result[name].append(metric_fun(\n                                    y.cpu().data.numpy(), y_pred.cpu().data.numpy().astype(\"float64\")))\n\n             \n            except KeyboardInterrupt:\n                t.close()\n                raise\n            t.close()\n           \n            \n            # Add epoch_logs\n            epoch_logs[\"loss\"] = total_loss_epoch / sample_num\n            \n           \n               \n                \n            for name, result in train_result.items():\n                epoch_logs[name] = np.sum(result) / steps_per_epoch\n\n            if do_validation:\n                eval_result = self.evaluate(val_x, val_y, batch_size)\n                for name, result in eval_result.items():\n                    epoch_logs[\"val_\" + name] = result\n            # verbose\n            if verbose > 0:\n                epoch_time = int(time.time() - start_time)\n                print('Epoch {0}/{1}'.format(epoch + 1, epochs))\n\n                eval_str = \"{0}s - loss: {1: .4f}\".format(\n                    epoch_time, epoch_logs[\"loss\"])\n\n                for name in self.metrics:\n                    eval_str += \" - \" + name + \\\n                                \": {0: .4f}\".format(epoch_logs[name])\n\n                if do_validation:\n                    i_tag = 1\n                    for name in self.metrics:\n                        eval_str += \" - \" + \"val_\" + name + \\\n                                    \": {0: .4f}\".format(epoch_logs[\"val_\" + name])\n                        \n                        # -----------------------------------------------------------\n                        if i_tag == 0:\n                            reduceLR.step(epoch_logs[\"val_\" + name])\n                            i_tag = 1\n                    \n                print(eval_str)\n            callbacks.on_epoch_end(epoch, epoch_logs)\n            if self.stop_training:\n                break\n\n        callbacks.on_train_end()\n\n    def evaluate(self, x, y, batch_size=256):\n        \"\"\"\n\n        :param x: Numpy array of test data (if the model has a single input), or list of Numpy arrays (if the model has multiple inputs).\n        :param y: Numpy array of target (label) data (if the model has a single output), or list of Numpy arrays (if the model has multiple outputs).\n        :param batch_size: Integer or `None`. Number of samples per evaluation step. If unspecified, `batch_size` will default to 256.\n        :return: Dict contains metric names and metric values.\n        \"\"\"\n        pred_ans = self.predict(x, batch_size)\n        eval_result = {}\n        for name, metric_fun in self.metrics.items():\n            eval_result[name] = metric_fun(y, pred_ans)\n        return eval_result\n\n    def predict(self, x, batch_size=256):\n        \"\"\"\n\n        :param x: The input data, as a Numpy array (or list of Numpy arrays if the model has multiple inputs).\n        :param batch_size: Integer. If unspecified, it will default to 256.\n        :return: Numpy array(s) of predictions.\n        \"\"\"\n        model = self.eval()\n        if isinstance(x, dict):\n            x = [x[feature] for feature in self.feature_index]\n        for i in range(len(x)):\n            if len(x[i].shape) == 1:\n                x[i] = np.expand_dims(x[i], axis=1)\n\n        tensor_data = Data.TensorDataset(\n            torch.from_numpy(np.concatenate(x, axis=-1)))\n        test_loader = DataLoader(\n            dataset=tensor_data, shuffle=False, batch_size=batch_size)\n\n        pred_ans = []\n        with torch.no_grad():\n            for index, x_test in enumerate(test_loader):\n                x = x_test[0].to(self.device).float()\n\n                y_pred = model(x).cpu().data.numpy()  # .squeeze()\n                pred_ans.append(y_pred)\n\n        return np.concatenate(pred_ans).astype(\"float64\")\n\n    def input_from_feature_columns(self, X, feature_columns, embedding_dict, support_dense=True):\n\n        sparse_feature_columns = list(\n            filter(lambda x: isinstance(x, SparseFeat), feature_columns)) if len(feature_columns) else []\n        dense_feature_columns = list(\n            filter(lambda x: isinstance(x, DenseFeat), feature_columns)) if len(feature_columns) else []\n\n        varlen_sparse_feature_columns = list(\n            filter(lambda x: isinstance(x, VarLenSparseFeat), feature_columns)) if feature_columns else []\n\n        if not support_dense and len(dense_feature_columns) > 0:\n            raise ValueError(\n                \"DenseFeat is not supported in dnn_feature_columns\")\n\n        sparse_embedding_list = [embedding_dict[feat.embedding_name](\n            X[:, self.feature_index[feat.name][0]:self.feature_index[feat.name][1]].long()) for\n            feat in sparse_feature_columns]\n\n        varlen_sparse_embedding_list = get_varlen_pooling_list(self.embedding_dict, X, self.feature_index,\n                                                               varlen_sparse_feature_columns, self.device)\n\n        dense_value_list = [X[:, self.feature_index[feat.name][0]:self.feature_index[feat.name][1]] for feat in\n                            dense_feature_columns]\n\n        return sparse_embedding_list + varlen_sparse_embedding_list, dense_value_list\n\n    def compute_input_dim(self, feature_columns, include_sparse=True, include_dense=True, feature_group=False):\n        sparse_feature_columns = list(\n            filter(lambda x: isinstance(x, (SparseFeat, VarLenSparseFeat)), feature_columns)) if len(\n            feature_columns) else []\n        dense_feature_columns = list(\n            filter(lambda x: isinstance(x, DenseFeat), feature_columns)) if len(feature_columns) else []\n\n        dense_input_dim = sum(\n            map(lambda x: x.dimension, dense_feature_columns))\n        if feature_group:\n            sparse_input_dim = len(sparse_feature_columns)\n        else:\n            sparse_input_dim = sum(feat.embedding_dim for feat in sparse_feature_columns)\n        input_dim = 0\n        if include_sparse:\n            input_dim += sparse_input_dim\n        if include_dense:\n            input_dim += dense_input_dim\n        return input_dim\n\n    def add_regularization_weight(self, weight_list, weight_decay, p=2):\n        self.regularization_weight.append((list(weight_list), weight_decay, p))\n\n    def get_regularization_loss(self, ):\n        total_reg_loss = torch.zeros((1,), device=self.device)\n        for weight_list, weight_decay, p in self.regularization_weight:\n            weight_reg_loss = torch.zeros((1,), device=self.device)\n            for w in weight_list:\n                if isinstance(w, tuple):\n                    l2_reg = torch.norm(w[1], p=p, )\n                else:\n                    l2_reg = torch.norm(w, p=p, )\n                weight_reg_loss = weight_reg_loss + l2_reg\n            reg_loss = weight_decay * weight_reg_loss\n            total_reg_loss += reg_loss\n        return total_reg_loss\n\n    def add_auxiliary_loss(self, aux_loss, alpha):\n        self.aux_loss = aux_loss * alpha\n\n    def compile(self, optimizer,\n                loss=None,\n                metrics=None,\n                ):\n        \"\"\"\n        :param optimizer: String (name of optimizer) or optimizer instance. See [optimizers](https://pytorch.org/docs/stable/optim.html).\n        :param loss: String (name of objective function) or objective function. See [losses](https://pytorch.org/docs/stable/nn.functional.html#loss-functions).\n        :param metrics: List of metrics to be evaluated by the model during training and testing. Typically you will use `metrics=['accuracy']`.\n        \"\"\"\n        self.metrics_names = [\"loss\"]\n        self.optim = self._get_optim(optimizer)\n        self.loss_func = self._get_loss_func(loss)\n        self.metrics = self._get_metrics(metrics)\n\n    def _get_optim(self, optimizer):\n        if isinstance(optimizer, str):\n            if optimizer == \"sgd\":\n                optim = torch.optim.SGD(self.parameters(), lr=0.01)\n            elif optimizer == \"adam\":\n                optim = torch.optim.Adam(self.parameters())  # 0.001\n            elif optimizer == \"adagrad\":\n                optim = torch.optim.Adagrad(self.parameters())  # 0.01\n            elif optimizer == \"rmsprop\":\n                optim = torch.optim.RMSprop(self.parameters())\n            else:\n                raise NotImplementedError\n        else:\n            optim = optimizer\n        return optim\n\n    def _get_loss_func(self, loss):\n        if isinstance(loss, str):\n            if loss == \"binary_crossentropy\":\n                loss_func = F.binary_cross_entropy\n            elif loss == \"mse\":\n                loss_func = F.mse_loss\n            elif loss == \"mae\":\n                loss_func = F.l1_loss\n            else:\n                raise NotImplementedError\n        else:\n            loss_func = loss\n        return loss_func\n\n    def _log_loss(self, y_true, y_pred, eps=1e-7, normalize=True, sample_weight=None, labels=None):\n        # change eps to improve calculation accuracy\n        return log_loss(y_true,\n                        y_pred,\n                        eps,\n                        normalize,\n                        sample_weight,\n                        labels)\n\n    def _get_metrics(self, metrics, set_eps=False):\n        metrics_ = {}\n        if metrics:\n            for metric in metrics:\n                if metric == \"binary_crossentropy\" or metric == \"logloss\":\n                    if set_eps:\n                        metrics_[metric] = self._log_loss\n                    else:\n                        metrics_[metric] = log_loss\n                if metric == \"auc\":\n                    metrics_[metric] = roc_auc_score\n                if metric == \"mse\":\n                    metrics_[metric] = mean_squared_error\n                if metric == \"accuracy\" or metric == \"acc\":\n                    metrics_[metric] = lambda y_true, y_pred: accuracy_score(\n                        y_true, np.where(y_pred > 0.5, 1, 0))\n                self.metrics_names.append(metric)\n        return metrics_\n\n    @property\n    def embedding_size(self, ):\n        feature_columns = self.dnn_feature_columns\n        sparse_feature_columns = list(\n            filter(lambda x: isinstance(x, (SparseFeat, VarLenSparseFeat)), feature_columns)) if len(\n            feature_columns) else []\n        embedding_size_set = set([feat.embedding_dim for feat in sparse_feature_columns])\n        if len(embedding_size_set) > 1:\n            raise ValueError(\"embedding_dim of SparseFeat and VarlenSparseFeat must be same in this model!\")\n        return list(embedding_size_set)[0]\n\n# interaction\n#-----------------------------------------------------------------------------------------------------------------\nclass FM(nn.Module):\n    \"\"\"Factorization Machine models pairwise (order-2) feature interactions\n     without linear term and bias.\n      Input shape\n        - 3D tensor with shape: ``(batch_size,field_size,embedding_size)``.\n      Output shape\n        - 2D tensor with shape: ``(batch_size, 1)``.\n      References\n        - [Factorization Machines](https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf)\n    \"\"\"\n\n    def __init__(self):\n        super(FM, self).__init__()\n\n    def forward(self, inputs):\n        fm_input = inputs\n\n        square_of_sum = torch.pow(torch.sum(fm_input, dim=1, keepdim=True), 2)\n        sum_of_square = torch.sum(fm_input * fm_input, dim=1, keepdim=True)\n        cross_term = square_of_sum - sum_of_square\n        cross_term = 0.5 * torch.sum(cross_term, dim=2, keepdim=False)\n\n        return cross_term\n\n\nclass BiInteractionPooling(nn.Module):\n    \"\"\"Bi-Interaction Layer used in Neural FM,compress the\n     pairwise element-wise product of features into one single vector.\n\n      Input shape\n        - A 3D tensor with shape:``(batch_size,field_size,embedding_size)``.\n\n      Output shape\n        - 3D tensor with shape: ``(batch_size,1,embedding_size)``.\n\n      References\n        - [He X, Chua T S. Neural factorization machines for sparse predictive analytics[C]//Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval. ACM, 2017: 355-364.](http://arxiv.org/abs/1708.05027)\n    \"\"\"\n\n    def __init__(self):\n        super(BiInteractionPooling, self).__init__()\n\n    def forward(self, inputs):\n        concated_embeds_value = inputs\n        square_of_sum = torch.pow(\n            torch.sum(concated_embeds_value, dim=1, keepdim=True), 2)\n        sum_of_square = torch.sum(\n            concated_embeds_value * concated_embeds_value, dim=1, keepdim=True)\n        cross_term = 0.5 * (square_of_sum - sum_of_square)\n        return cross_term\n\n\nclass SENETLayer(nn.Module):\n    \"\"\"SENETLayer used in FiBiNET.\n      Input shape\n        - A list of 3D tensor with shape: ``(batch_size,filed_size,embedding_size)``.\n      Output shape\n        - A list of 3D tensor with shape: ``(batch_size,filed_size,embedding_size)``.\n      Arguments\n        - **filed_size** : Positive integer, number of feature groups.\n        - **reduction_ratio** : Positive integer, dimensionality of the\n         attention network output space.\n        - **seed** : A Python integer to use as random seed.\n      References\n        - [FiBiNET: Combining Feature Importance and Bilinear feature Interaction for Click-Through Rate Prediction\nTongwen](https://arxiv.org/pdf/1905.09433.pdf)\n    \"\"\"\n\n    def __init__(self, filed_size, reduction_ratio=3, seed=1024, device='cpu'):\n        super(SENETLayer, self).__init__()\n        self.seed = seed\n        self.filed_size = filed_size\n        self.reduction_size = max(1, filed_size // reduction_ratio)\n        self.excitation = nn.Sequential(\n            nn.Linear(self.filed_size, self.reduction_size, bias=False),\n            nn.ReLU(),\n            nn.Linear(self.reduction_size, self.filed_size, bias=False),\n            nn.ReLU()\n        )\n        self.to(device)\n\n    def forward(self, inputs):\n        if len(inputs.shape) != 3:\n            raise ValueError(\n                \"Unexpected inputs dimensions %d, expect to be 3 dimensions\" % (len(inputs.shape)))\n        Z = torch.mean(inputs, dim=-1, out=None)\n        A = self.excitation(Z)\n        V = torch.mul(inputs, torch.unsqueeze(A, dim=2))\n\n        return V\n\n\nclass BilinearInteraction(nn.Module):\n    \"\"\"BilinearInteraction Layer used in FiBiNET.\n      Input shape\n        - A list of 3D tensor with shape: ``(batch_size,filed_size, embedding_size)``.\n      Output shape\n        - 3D tensor with shape: ``(batch_size,filed_size, embedding_size)``.\n      Arguments\n        - **filed_size** : Positive integer, number of feature groups.\n        - **str** : String, types of bilinear functions used in this layer.\n        - **seed** : A Python integer to use as random seed.\n      References\n        - [FiBiNET: Combining Feature Importance and Bilinear feature Interaction for Click-Through Rate Prediction\nTongwen](https://arxiv.org/pdf/1905.09433.pdf)\n    \"\"\"\n\n    def __init__(self, filed_size, embedding_size, bilinear_type=\"interaction\", seed=1024, device='cpu'):\n        super(BilinearInteraction, self).__init__()\n        self.bilinear_type = bilinear_type\n        self.seed = seed\n        self.bilinear = nn.ModuleList()\n        if self.bilinear_type == \"all\":\n            self.bilinear = nn.Linear(\n                embedding_size, embedding_size, bias=False)\n        elif self.bilinear_type == \"each\":\n            for i in range(filed_size):\n                self.bilinear.append(\n                    nn.Linear(embedding_size, embedding_size, bias=False))\n        elif self.bilinear_type == \"interaction\":\n            for i, j in itertools.combinations(range(filed_size), 2):\n                self.bilinear.append(\n                    nn.Linear(embedding_size, embedding_size, bias=False))\n        else:\n            raise NotImplementedError\n        self.to(device)\n\n    def forward(self, inputs):\n        if len(inputs.shape) != 3:\n            raise ValueError(\n                \"Unexpected inputs dimensions %d, expect to be 3 dimensions\" % (len(inputs.shape)))\n        inputs = torch.split(inputs, 1, dim=1)\n        if self.bilinear_type == \"all\":\n            p = [torch.mul(self.bilinear(v_i), v_j)\n                 for v_i, v_j in itertools.combinations(inputs, 2)]\n        elif self.bilinear_type == \"each\":\n            p = [torch.mul(self.bilinear[i](inputs[i]), inputs[j])\n                 for i, j in itertools.combinations(range(len(inputs)), 2)]\n        elif self.bilinear_type == \"interaction\":\n            p = [torch.mul(bilinear(v[0]), v[1])\n                 for v, bilinear in zip(itertools.combinations(inputs, 2), self.bilinear)]\n        else:\n            raise NotImplementedError\n        return torch.cat(p, dim=1)\n\n\nclass CIN(nn.Module):\n    \"\"\"Compressed Interaction Network used in xDeepFM.\n      Input shape\n        - 3D tensor with shape: ``(batch_size,field_size,embedding_size)``.\n      Output shape\n        - 2D tensor with shape: ``(batch_size, featuremap_num)`` ``featuremap_num =  sum(self.layer_size[:-1]) // 2 + self.layer_size[-1]`` if ``split_half=True``,else  ``sum(layer_size)`` .\n      Arguments\n        - **filed_size** : Positive integer, number of feature groups.\n        - **layer_size** : list of int.Feature maps in each layer.\n        - **activation** : activation function name used on feature maps.\n        - **split_half** : bool.if set to False, half of the feature maps in each hidden will connect to output unit.\n        - **seed** : A Python integer to use as random seed.\n      References\n        - [Lian J, Zhou X, Zhang F, et al. xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems[J]. arXiv preprint arXiv:1803.05170, 2018.] (https://arxiv.org/pdf/1803.05170.pdf)\n    \"\"\"\n\n    def __init__(self, field_size, layer_size=(128, 128), activation='relu', split_half=True, l2_reg=1e-5, seed=1024,\n                 device='cpu'):\n        super(CIN, self).__init__()\n        if len(layer_size) == 0:\n            raise ValueError(\n                \"layer_size must be a list(tuple) of length greater than 1\")\n\n        self.layer_size = layer_size\n        self.field_nums = [field_size]\n        self.split_half = split_half\n        self.activation = activation_layer(activation)\n        self.l2_reg = l2_reg\n        self.seed = seed\n\n        self.conv1ds = nn.ModuleList()\n        for i, size in enumerate(self.layer_size):\n            self.conv1ds.append(\n                nn.Conv1d(self.field_nums[-1] * self.field_nums[0], size, 1))\n\n            if self.split_half:\n                if i != len(self.layer_size) - 1 and size % 2 > 0:\n                    raise ValueError(\n                        \"layer_size must be even number except for the last layer when split_half=True\")\n\n                self.field_nums.append(size // 2)\n            else:\n                self.field_nums.append(size)\n\n        #         for tensor in self.conv1ds:\n        #             nn.init.normal_(tensor.weight, mean=0, std=init_std)\n        self.to(device)\n\n    def forward(self, inputs):\n        if len(inputs.shape) != 3:\n            raise ValueError(\n                \"Unexpected inputs dimensions %d, expect to be 3 dimensions\" % (len(inputs.shape)))\n        batch_size = inputs.shape[0]\n        dim = inputs.shape[-1]\n        hidden_nn_layers = [inputs]\n        final_result = []\n\n        for i, size in enumerate(self.layer_size):\n            # x^(k-1) * x^0\n            x = torch.einsum(\n                'bhd,bmd->bhmd', hidden_nn_layers[-1], hidden_nn_layers[0])\n            # x.shape = (batch_size , hi * m, dim)\n            x = x.reshape(\n                batch_size, hidden_nn_layers[-1].shape[1] * hidden_nn_layers[0].shape[1], dim)\n            # x.shape = (batch_size , hi, dim)\n            x = self.conv1ds[i](x)\n\n            if self.activation is None or self.activation == 'linear':\n                curr_out = x\n            else:\n                curr_out = self.activation(x)\n\n            if self.split_half:\n                if i != len(self.layer_size) - 1:\n                    next_hidden, direct_connect = torch.split(\n                        curr_out, 2 * [size // 2], 1)\n                else:\n                    direct_connect = curr_out\n                    next_hidden = 0\n            else:\n                direct_connect = curr_out\n                next_hidden = curr_out\n\n            final_result.append(direct_connect)\n            hidden_nn_layers.append(next_hidden)\n\n        result = torch.cat(final_result, dim=1)\n        result = torch.sum(result, -1)\n\n        return result\n\n\nclass AFMLayer(nn.Module):\n    \"\"\"Attentonal Factorization Machine models pairwise (order-2) feature\n    interactions without linear term and bias.\n      Input shape\n        - A list of 3D tensor with shape: ``(batch_size,1,embedding_size)``.\n      Output shape\n        - 2D tensor with shape: ``(batch_size, 1)``.\n      Arguments\n        - **in_features** : Positive integer, dimensionality of input features.\n        - **attention_factor** : Positive integer, dimensionality of the\n         attention network output space.\n        - **l2_reg_w** : float between 0 and 1. L2 regularizer strength\n         applied to attention network.\n        - **dropout_rate** : float between in [0,1). Fraction of the attention net output units to dropout.\n        - **seed** : A Python integer to use as random seed.\n      References\n        - [Attentional Factorization Machines : Learning the Weight of Feature\n        Interactions via Attention Networks](https://arxiv.org/pdf/1708.04617.pdf)\n    \"\"\"\n\n    def __init__(self, in_features, attention_factor=4, l2_reg_w=0, dropout_rate=0, seed=1024, device='cpu'):\n        super(AFMLayer, self).__init__()\n        self.attention_factor = attention_factor\n        self.l2_reg_w = l2_reg_w\n        self.dropout_rate = dropout_rate\n        self.seed = seed\n        embedding_size = in_features\n\n        self.attention_W = nn.Parameter(torch.Tensor(\n            embedding_size, self.attention_factor))\n\n        self.attention_b = nn.Parameter(torch.Tensor(self.attention_factor))\n\n        self.projection_h = nn.Parameter(\n            torch.Tensor(self.attention_factor, 1))\n\n        self.projection_p = nn.Parameter(torch.Tensor(embedding_size, 1))\n\n        for tensor in [self.attention_W, self.projection_h, self.projection_p]:\n            nn.init.xavier_normal_(tensor, )\n\n        for tensor in [self.attention_b]:\n            nn.init.zeros_(tensor, )\n\n        self.dropout = nn.Dropout(dropout_rate)\n\n        self.to(device)\n\n    def forward(self, inputs):\n        embeds_vec_list = inputs\n        row = []\n        col = []\n\n        for r, c in itertools.combinations(embeds_vec_list, 2):\n            row.append(r)\n            col.append(c)\n\n        p = torch.cat(row, dim=1)\n        q = torch.cat(col, dim=1)\n        inner_product = p * q\n\n        bi_interaction = inner_product\n        attention_temp = F.relu(torch.tensordot(\n            bi_interaction, self.attention_W, dims=([-1], [0])) + self.attention_b)\n\n        self.normalized_att_score = F.softmax(torch.tensordot(\n            attention_temp, self.projection_h, dims=([-1], [0])), dim=1)\n        attention_output = torch.sum(\n            self.normalized_att_score * bi_interaction, dim=1)\n\n        attention_output = self.dropout(attention_output)  # training\n\n        afm_out = torch.tensordot(\n            attention_output, self.projection_p, dims=([-1], [0]))\n        return afm_out\n\n\nclass InteractingLayer(nn.Module):\n    \"\"\"A Layer used in AutoInt that model the correlations between different feature fields by multi-head self-attention mechanism.\n      Input shape\n            - A 3D tensor with shape: ``(batch_size,field_size,embedding_size)``.\n      Output shape\n            - 3D tensor with shape:``(batch_size,field_size,att_embedding_size * head_num)``.\n      Arguments\n            - **in_features** : Positive integer, dimensionality of input features.\n            - **att_embedding_size**: int.The embedding size in multi-head self-attention network.\n            - **head_num**: int.The head number in multi-head  self-attention network.\n            - **use_res**: bool.Whether or not use standard residual connections before output.\n            - **seed**: A Python integer to use as random seed.\n      References\n            - [Song W, Shi C, Xiao Z, et al. AutoInt: Automatic Feature Interaction Learning via Self-Attentive Neural Networks[J]. arXiv preprint arXiv:1810.11921, 2018.](https://arxiv.org/abs/1810.11921)\n    \"\"\"\n\n    def __init__(self, in_features, att_embedding_size=8, head_num=2, use_res=True, seed=1024, device='cpu'):\n        super(InteractingLayer, self).__init__()\n        if head_num <= 0:\n            raise ValueError('head_num must be a int > 0')\n        self.att_embedding_size = att_embedding_size\n        self.head_num = head_num\n        self.use_res = use_res\n        self.seed = seed\n\n        embedding_size = in_features\n\n        self.W_Query = nn.Parameter(torch.Tensor(\n            embedding_size, self.att_embedding_size * self.head_num))\n\n        self.W_key = nn.Parameter(torch.Tensor(\n            embedding_size, self.att_embedding_size * self.head_num))\n\n        self.W_Value = nn.Parameter(torch.Tensor(\n            embedding_size, self.att_embedding_size * self.head_num))\n\n        if self.use_res:\n            self.W_Res = nn.Parameter(torch.Tensor(\n                embedding_size, self.att_embedding_size * self.head_num))\n        for tensor in self.parameters():\n            nn.init.normal_(tensor, mean=0.0, std=0.05)\n\n        self.to(device)\n\n    def forward(self, inputs):\n\n        if len(inputs.shape) != 3:\n            raise ValueError(\n                \"Unexpected inputs dimensions %d, expect to be 3 dimensions\" % (len(inputs.shape)))\n\n        querys = torch.tensordot(inputs, self.W_Query,\n                                 dims=([-1], [0]))  # None F D*head_num\n        keys = torch.tensordot(inputs, self.W_key, dims=([-1], [0]))\n        values = torch.tensordot(inputs, self.W_Value, dims=([-1], [0]))\n\n        # head_num None F D\n\n        querys = torch.stack(torch.split(\n            querys, self.att_embedding_size, dim=2))\n        keys = torch.stack(torch.split(keys, self.att_embedding_size, dim=2))\n        values = torch.stack(torch.split(\n            values, self.att_embedding_size, dim=2))\n        inner_product = torch.einsum(\n            'bnik,bnjk->bnij', querys, keys)  # head_num None F F\n\n        self.normalized_att_scores = F.softmax(\n            inner_product, dim=-1)  # head_num None F F\n        result = torch.matmul(self.normalized_att_scores,\n                              values)  # head_num None F D\n\n        result = torch.cat(torch.split(result, 1, ), dim=-1)\n        result = torch.squeeze(result, dim=0)  # None F D*head_num\n        if self.use_res:\n            result += torch.tensordot(inputs, self.W_Res, dims=([-1], [0]))\n        result = F.relu(result)\n\n        return result\n\n\nclass CrossNet(nn.Module):\n    \"\"\"The Cross Network part of Deep&Cross Network model,\n    which leans both low and high degree cross feature.\n      Input shape\n        - 2D tensor with shape: ``(batch_size, units)``.\n      Output shape\n        - 2D tensor with shape: ``(batch_size, units)``.\n      Arguments\n        - **in_features** : Positive integer, dimensionality of input features.\n        - **input_feature_num**: Positive integer, shape(Input tensor)[-1]\n        - **layer_num**: Positive integer, the cross layer number\n        - **parameterization**: string, ``\"vector\"``  or ``\"matrix\"`` ,  way to parameterize the cross network.\n        - **l2_reg**: float between 0 and 1. L2 regularizer strength applied to the kernel weights matrix\n        - **seed**: A Python integer to use as random seed.\n      References\n        - [Wang R, Fu B, Fu G, et al. Deep & cross network for ad click predictions[C]//Proceedings of the ADKDD'17. ACM, 2017: 12.](https://arxiv.org/abs/1708.05123)\n        - [Wang R, Shivanna R, Cheng D Z, et al. DCN-M: Improved Deep & Cross Network for Feature Cross Learning in Web-scale Learning to Rank Systems[J]. 2020.](https://arxiv.org/abs/2008.13535)\n    \"\"\"\n\n    def __init__(self, in_features, layer_num=2, parameterization='vector', seed=1024, device='cpu'):\n        super(CrossNet, self).__init__()\n        self.layer_num = layer_num\n        self.parameterization = parameterization\n        if self.parameterization == 'vector':\n            # weight in DCN.  (in_features, 1)\n            self.kernels = torch.nn.ParameterList(\n                [nn.Parameter(nn.init.xavier_normal_(torch.empty(in_features, 1))) for i in range(self.layer_num)])\n        elif self.parameterization == 'matrix':\n            # weight matrix in DCN-M.  (in_features, in_features)\n            self.kernels = torch.nn.ParameterList([nn.Parameter(nn.init.xavier_normal_(\n                torch.empty(in_features, in_features))) for i in range(self.layer_num)])\n        else:  # error\n            raise ValueError(\"parameterization should be 'vector' or 'matrix'\")\n\n        self.bias = torch.nn.ParameterList(\n            [nn.Parameter(nn.init.zeros_(torch.empty(in_features, 1))) for i in range(self.layer_num)])\n        self.to(device)\n\n    def forward(self, inputs):\n        x_0 = inputs.unsqueeze(2)\n        x_l = x_0\n        for i in range(self.layer_num):\n            if self.parameterization == 'vector':\n                xl_w = torch.tensordot(x_l, self.kernels[i], dims=([1], [0]))\n                dot_ = torch.matmul(x_0, xl_w)\n                x_l = dot_ + self.bias[i]\n            elif self.parameterization == 'matrix':\n                dot_ = torch.matmul(self.kernels[i], x_l)  # W * xi  (bs, in_features, 1)\n                dot_ = dot_ + self.bias[i]  # W * xi + b\n                dot_ = x_0 * dot_  # x0 · (W * xi + b)  Hadamard-product\n            else:  # error\n                print(\"parameterization should be 'vector' or 'matrix'\")\n                pass\n            x_l = dot_ + x_l\n        x_l = torch.squeeze(x_l, dim=2)\n        return x_l\n\n\nclass CrossNetMix(nn.Module):\n    \"\"\"The Cross Network part of DCN-Mix model, which improves DCN-M by:\n      1 add MOE to learn feature interactions in different subspaces\n      2 add nonlinear transformations in low-dimensional space\n      Input shape\n        - 2D tensor with shape: ``(batch_size, units)``.\n      Output shape\n        - 2D tensor with shape: ``(batch_size, units)``.\n      Arguments\n        - **in_features** : Positive integer, dimensionality of input features.\n        - **low_rank** : Positive integer, dimensionality of low-rank sapce.\n        - **num_experts** : Positive integer, number of experts.\n        - **layer_num**: Positive integer, the cross layer number\n        - **device**: str, e.g. ``\"cpu\"`` or ``\"cuda:0\"``\n      References\n        - [Wang R, Shivanna R, Cheng D Z, et al. DCN-M: Improved Deep & Cross Network for Feature Cross Learning in Web-scale Learning to Rank Systems[J]. 2020.](https://arxiv.org/abs/2008.13535)\n    \"\"\"\n\n    def __init__(self, in_features, low_rank=32, num_experts=4, layer_num=2, device='cpu'):\n        super(CrossNetMix, self).__init__()\n        self.layer_num = layer_num\n        self.num_experts = num_experts\n\n        # U: (in_features, low_rank)\n        self.U_list = torch.nn.ParameterList([nn.Parameter(nn.init.xavier_normal_(\n            torch.empty(num_experts, in_features, low_rank))) for i in range(self.layer_num)])\n        # V: (in_features, low_rank)\n        self.V_list = torch.nn.ParameterList([nn.Parameter(nn.init.xavier_normal_(\n            torch.empty(num_experts, in_features, low_rank))) for i in range(self.layer_num)])\n        # C: (low_rank, low_rank)\n        self.C_list = torch.nn.ParameterList([nn.Parameter(nn.init.xavier_normal_(\n            torch.empty(num_experts, low_rank, low_rank))) for i in range(self.layer_num)])\n        self.gating = nn.ModuleList([nn.Linear(in_features, 1, bias=False) for i in range(self.num_experts)])\n\n        self.bias = torch.nn.ParameterList([nn.Parameter(nn.init.zeros_(\n            torch.empty(in_features, 1))) for i in range(self.layer_num)])\n        self.to(device)\n\n    def forward(self, inputs):\n        x_0 = inputs.unsqueeze(2)  # (bs, in_features, 1)\n        x_l = x_0\n        for i in range(self.layer_num):\n            output_of_experts = []\n            gating_score_of_experts = []\n            for expert_id in range(self.num_experts):\n                # (1) G(x_l)\n                # compute the gating score by x_l\n                gating_score_of_experts.append(self.gating[expert_id](x_l.squeeze(2)))\n\n                # (2) E(x_l)\n                # project the input x_l to $\\mathbb{R}^{r}$\n                v_x = torch.matmul(self.V_list[i][expert_id].T, x_l)  # (bs, low_rank, 1)\n\n                # nonlinear activation in low rank space\n                v_x = torch.tanh(v_x)\n                v_x = torch.matmul(self.C_list[i][expert_id], v_x)\n                v_x = torch.tanh(v_x)\n\n                # project back to $\\mathbb{R}^{d}$\n                uv_x = torch.matmul(self.U_list[i][expert_id], v_x)  # (bs, in_features, 1)\n\n                dot_ = uv_x + self.bias[i]\n                dot_ = x_0 * dot_  # Hadamard-product\n\n                output_of_experts.append(dot_.squeeze(2))\n\n            # (3) mixture of low-rank experts\n            output_of_experts = torch.stack(output_of_experts, 2)  # (bs, in_features, num_experts)\n            gating_score_of_experts = torch.stack(gating_score_of_experts, 1)  # (bs, num_experts, 1)\n            moe_out = torch.matmul(output_of_experts, gating_score_of_experts.softmax(1))\n            x_l = moe_out + x_l  # (bs, in_features, 1)\n\n        x_l = x_l.squeeze()  # (bs, in_features)\n        return x_l\n\n\nclass InnerProductLayer(nn.Module):\n    \"\"\"InnerProduct Layer used in PNN that compute the element-wise\n    product or inner product between feature vectors.\n      Input shape\n        - a list of 3D tensor with shape: ``(batch_size,1,embedding_size)``.\n      Output shape\n        - 3D tensor with shape: ``(batch_size, N*(N-1)/2 ,1)`` if use reduce_sum. or 3D tensor with shape:\n        ``(batch_size, N*(N-1)/2, embedding_size )`` if not use reduce_sum.\n      Arguments\n        - **reduce_sum**: bool. Whether return inner product or element-wise product\n      References\n            - [Qu Y, Cai H, Ren K, et al. Product-based neural networks for user response prediction[C]//\n            Data Mining (ICDM), 2016 IEEE 16th International Conference on. IEEE, 2016: 1149-1154.]\n            (https://arxiv.org/pdf/1611.00144.pdf)\"\"\"\n\n    def __init__(self, reduce_sum=True, device='cpu'):\n        super(InnerProductLayer, self).__init__()\n        self.reduce_sum = reduce_sum\n        self.to(device)\n\n    def forward(self, inputs):\n\n        embed_list = inputs\n        row = []\n        col = []\n        num_inputs = len(embed_list)\n\n        for i in range(num_inputs - 1):\n            for j in range(i + 1, num_inputs):\n                row.append(i)\n                col.append(j)\n        p = torch.cat([embed_list[idx]\n                       for idx in row], dim=1)  # batch num_pairs k\n        q = torch.cat([embed_list[idx]\n                       for idx in col], dim=1)\n\n        inner_product = p * q\n        if self.reduce_sum:\n            inner_product = torch.sum(\n                inner_product, dim=2, keepdim=True)\n        return inner_product\n\n\nclass OutterProductLayer(nn.Module):\n    \"\"\"OutterProduct Layer used in PNN.This implemention is\n    adapted from code that the author of the paper published on https://github.com/Atomu2014/product-nets.\n      Input shape\n            - A list of N 3D tensor with shape: ``(batch_size,1,embedding_size)``.\n      Output shape\n            - 2D tensor with shape:``(batch_size,N*(N-1)/2 )``.\n      Arguments\n            - **filed_size** : Positive integer, number of feature groups.\n            - **kernel_type**: str. The kernel weight matrix type to use,can be mat,vec or num\n            - **seed**: A Python integer to use as random seed.\n      References\n            - [Qu Y, Cai H, Ren K, et al. Product-based neural networks for user response prediction[C]//Data Mining (ICDM), 2016 IEEE 16th International Conference on. IEEE, 2016: 1149-1154.](https://arxiv.org/pdf/1611.00144.pdf)\n    \"\"\"\n\n    def __init__(self, field_size, embedding_size, kernel_type='mat', seed=1024, device='cpu'):\n        super(OutterProductLayer, self).__init__()\n        self.kernel_type = kernel_type\n\n        num_inputs = field_size\n        num_pairs = int(num_inputs * (num_inputs - 1) / 2)\n        embed_size = embedding_size\n        if self.kernel_type == 'mat':\n\n            self.kernel = nn.Parameter(torch.Tensor(\n                embed_size, num_pairs, embed_size))\n\n        elif self.kernel_type == 'vec':\n            self.kernel = nn.Parameter(torch.Tensor(num_pairs, embed_size))\n\n        elif self.kernel_type == 'num':\n            self.kernel = nn.Parameter(torch.Tensor(num_pairs, 1))\n        nn.init.xavier_uniform_(self.kernel)\n\n        self.to(device)\n\n    def forward(self, inputs):\n        embed_list = inputs\n        row = []\n        col = []\n        num_inputs = len(embed_list)\n        for i in range(num_inputs - 1):\n            for j in range(i + 1, num_inputs):\n                row.append(i)\n                col.append(j)\n        p = torch.cat([embed_list[idx]\n                       for idx in row], dim=1)  # batch num_pairs k\n        q = torch.cat([embed_list[idx] for idx in col], dim=1)\n\n        # -------------------------\n        if self.kernel_type == 'mat':\n            p.unsqueeze_(dim=1)\n            # k     k* pair* k\n            # batch * pair\n            kp = torch.sum(\n\n                # batch * pair * k\n\n                torch.mul(\n\n                    # batch * pair * k\n\n                    torch.transpose(\n\n                        # batch * k * pair\n\n                        torch.sum(\n\n                            # batch * k * pair * k\n\n                            torch.mul(\n\n                                p, self.kernel),\n\n                            dim=-1),\n\n                        2, 1),\n\n                    q),\n\n                dim=-1)\n        else:\n            # 1 * pair * (k or 1)\n\n            k = torch.unsqueeze(self.kernel, 0)\n\n            # batch * pair\n\n            kp = torch.sum(p * q * k, dim=-1)\n\n            # p q # b * p * k\n\n        return kp\n\n\nclass ConvLayer(nn.Module):\n    \"\"\"Conv Layer used in CCPM.\n\n      Input shape\n            - A list of N 3D tensor with shape: ``(batch_size,1,filed_size,embedding_size)``.\n      Output shape\n            - A list of N 3D tensor with shape: ``(batch_size,last_filters,pooling_size,embedding_size)``.\n      Arguments\n            - **filed_size** : Positive integer, number of feature groups.\n            - **conv_kernel_width**: list. list of positive integer or empty list,the width of filter in each conv layer.\n            - **conv_filters**: list. list of positive integer or empty list,the number of filters in each conv layer.\n      Reference:\n            - Liu Q, Yu F, Wu S, et al. A convolutional click prediction model[C]//Proceedings of the 24th ACM International on Conference on Information and Knowledge Management. ACM, 2015: 1743-1746.(http://ir.ia.ac.cn/bitstream/173211/12337/1/A%20Convolutional%20Click%20Prediction%20Model.pdf)\n    \"\"\"\n\n    def __init__(self, field_size, conv_kernel_width, conv_filters, device='cpu'):\n        super(ConvLayer, self).__init__()\n        self.device = device\n        module_list = []\n        n = int(field_size)\n        l = len(conv_filters)\n        filed_shape = n\n        for i in range(1, l + 1):\n            if i == 1:\n                in_channels = 1\n            else:\n                in_channels = conv_filters[i - 2]\n            out_channels = conv_filters[i - 1]\n            width = conv_kernel_width[i - 1]\n            k = max(1, int((1 - pow(i / l, l - i)) * n)) if i < l else 3\n            module_list.append(Conv2dSame(in_channels=in_channels, out_channels=out_channels, kernel_size=(width, 1),\n                                          stride=1).to(self.device))\n            module_list.append(torch.nn.Tanh().to(self.device))\n\n            # KMaxPooling, extract top_k, returns tensors values\n            module_list.append(KMaxPooling(k=min(k, filed_shape), axis=2, device=self.device).to(self.device))\n            filed_shape = min(k, filed_shape)\n        self.conv_layer = nn.Sequential(*module_list)\n        self.to(device)\n        self.filed_shape = filed_shape\n\n    def forward(self, inputs):\n        return self.conv_layer(inputs)\n\n# DeepFM\n# -----------------------------------------------------------------------------------------------------------------\nclass DeepFM(BaseModel):\n    \"\"\"Instantiates the DeepFM Network architecture.\n\n    :param linear_feature_columns: An iterable containing all the features used by linear part of the model.\n    :param dnn_feature_columns: An iterable containing all the features used by deep part of the model.\n    :param use_fm: bool,use FM part or not\n    :param dnn_hidden_units: list,list of positive integer or empty list, the layer number and units in each layer of DNN\n    :param l2_reg_linear: float. L2 regularizer strength applied to linear part\n    :param l2_reg_embedding: float. L2 regularizer strength applied to embedding vector\n    :param l2_reg_dnn: float. L2 regularizer strength applied to DNN\n    :param init_std: float,to use as the initialize std of embedding vector\n    :param seed: integer ,to use as random seed.\n    :param dnn_dropout: float in [0,1), the probability we will drop out a given DNN coordinate.\n    :param dnn_activation: Activation function to use in DNN\n    :param dnn_use_bn: bool. Whether use BatchNormalization before activation or not in DNN\n    :param task: str, ``\"binary\"`` for  binary logloss or  ``\"regression\"`` for regression loss\n    :param device: str, ``\"cpu\"`` or ``\"cuda:0\"``\n    :return: A PyTorch model instance.\n    \n    \"\"\"\n\n    def __init__(self,\n                 linear_feature_columns, dnn_feature_columns, use_fm=True,\n                 dnn_hidden_units=(256, 128),\n                 l2_reg_linear=0.00001, l2_reg_embedding=0.00001, l2_reg_dnn=0, init_std=0.0001, seed=1024,\n                 dnn_dropout=0,\n                 dnn_activation='relu', dnn_use_bn=False, task='binary', device='cpu'):\n\n        super(DeepFM, self).__init__(linear_feature_columns, dnn_feature_columns, l2_reg_linear=l2_reg_linear,\n                                     l2_reg_embedding=l2_reg_embedding, init_std=init_std, seed=seed, task=task,\n                                     device=device)\n\n        self.use_fm = use_fm\n        self.use_dnn = len(dnn_feature_columns) > 0 and len(\n            dnn_hidden_units) > 0\n        if use_fm:\n            self.fm = FM()\n\n        if self.use_dnn:\n            self.dnn = DNN(self.compute_input_dim(dnn_feature_columns), dnn_hidden_units,\n                           activation=dnn_activation, l2_reg=l2_reg_dnn, dropout_rate=dnn_dropout, use_bn=dnn_use_bn,\n                           init_std=init_std, device=device)\n            self.dnn_linear = nn.Linear(\n                dnn_hidden_units[-1], 1, bias=False).to(device)\n\n            self.add_regularization_weight(\n                filter(lambda x: 'weight' in x[0] and 'bn' not in x[0], self.dnn.named_parameters()), l2_reg_dnn)\n            self.add_regularization_weight(self.dnn_linear.weight, l2_reg_dnn)\n        self.to(device)\n\n    def forward(self, X):\n\n        sparse_embedding_list, dense_value_list = self.input_from_feature_columns(X, self.dnn_feature_columns,\n                                                                                  self.embedding_dict)\n        logit = self.linear_model(X)\n\n        if self.use_fm and len(sparse_embedding_list) > 0:\n            fm_input = torch.cat(sparse_embedding_list, dim=1)\n            logit += self.fm(fm_input)\n\n        if self.use_dnn:\n            dnn_input = combined_dnn_input(\n                sparse_embedding_list, dense_value_list)\n            dnn_output = self.dnn(dnn_input)\n            dnn_logit = self.dnn_linear(dnn_output)\n            logit += dnn_logit\n\n        y_pred = self.out(logit)\n\n        return y_pred\n\n# -------------------------------------------------------------------------------\n# xDeepFm\nclass xDeepFM(BaseModel):\n    \"\"\"Instantiates the xDeepFM architecture.\n\n    :param linear_feature_columns: An iterable containing all the features used by linear part of the model.\n    :param dnn_feature_columns: An iterable containing all the features used by deep part of the model.\n    :param dnn_hidden_units: list,list of positive integer or empty list, the layer number and units in each layer of deep net\n    :param cin_layer_size: list,list of positive integer or empty list, the feature maps  in each hidden layer of Compressed Interaction Network\n    :param cin_split_half: bool.if set to True, half of the feature maps in each hidden will connect to output unit\n    :param cin_activation: activation function used on feature maps\n    :param l2_reg_linear: float. L2 regularizer strength applied to linear part\n    :param l2_reg_embedding: L2 regularizer strength applied to embedding vector\n    :param l2_reg_dnn: L2 regularizer strength applied to deep net\n    :param l2_reg_cin: L2 regularizer strength applied to CIN.\n    :param init_std: float,to use as the initialize std of embedding vector\n    :param seed: integer ,to use as random seed.\n    :param dnn_dropout: float in [0,1), the probability we will drop out a given DNN coordinate.\n    :param dnn_activation: Activation function to use in DNN\n    :param dnn_use_bn: bool. Whether use BatchNormalization before activation or not in DNN\n    :param task: str, ``\"binary\"`` for  binary logloss or  ``\"regression\"`` for regression loss\n    :param device: str, ``\"cpu\"`` or ``\"cuda:0\"``\n    :return: A PyTorch model instance.\n    \n    \"\"\"\n\n    def __init__(self, linear_feature_columns, dnn_feature_columns, dnn_hidden_units=(256, 256),\n                 cin_layer_size=(256, 128,), cin_split_half=True, cin_activation='relu', l2_reg_linear=0.00001,\n                 l2_reg_embedding=0.00001, l2_reg_dnn=0, l2_reg_cin=0, init_std=0.0001, seed=1024, dnn_dropout=0,\n                 dnn_activation='relu', dnn_use_bn=False, task='binary', device='cpu'):\n\n        super(xDeepFM, self).__init__(linear_feature_columns, dnn_feature_columns, l2_reg_linear=l2_reg_linear,\n                                      l2_reg_embedding=l2_reg_embedding, init_std=init_std, seed=seed, task=task,\n                                      device=device)\n        self.dnn_hidden_units = dnn_hidden_units\n        self.use_dnn = len(dnn_feature_columns) > 0 and len(dnn_hidden_units) > 0\n        if self.use_dnn:\n            self.dnn = DNN(self.compute_input_dim(dnn_feature_columns), dnn_hidden_units,\n                           activation=dnn_activation, l2_reg=l2_reg_dnn, dropout_rate=dnn_dropout, use_bn=dnn_use_bn,\n                           init_std=init_std, device=device)\n            self.dnn_linear = nn.Linear(dnn_hidden_units[-1], 1, bias=False).to(device)\n            self.add_regularization_weight(\n                filter(lambda x: 'weight' in x[0] and 'bn' not in x[0], self.dnn.named_parameters()), l2_reg_dnn)\n\n            self.add_regularization_weight(self.dnn_linear.weight, l2_reg_dnn)\n\n        self.cin_layer_size = cin_layer_size\n        self.use_cin = len(self.cin_layer_size) > 0 and len(dnn_feature_columns) > 0\n        if self.use_cin:\n            field_num = len(self.embedding_dict)\n            if cin_split_half == True:\n                self.featuremap_num = sum(\n                    cin_layer_size[:-1]) // 2 + cin_layer_size[-1]\n            else:\n                self.featuremap_num = sum(cin_layer_size)\n            self.cin = CIN(field_num, cin_layer_size,\n                           cin_activation, cin_split_half, l2_reg_cin, seed, device=device)\n            self.cin_linear = nn.Linear(self.featuremap_num, 1, bias=False).to(device)\n            self.add_regularization_weight(\n                filter(lambda x: 'weight' in x[0], self.cin.named_parameters()), l2_reg_cin)\n        \n          \n        #---------\n        field_num = len(self.embedding_dict)\n        att_layer_num=3\n        att_embedding_size=8\n        att_head_num=2\n        att_res=True\n        dnn_linear_in_feature2 = dnn_hidden_units[-1] + \\\n                                    field_num * att_embedding_size * att_head_num\n        self.dnn_linear2 = nn.Linear(dnn_linear_in_feature2, 1, bias=False).to(device)\n        self.int_layers = nn.ModuleList(\n            [InteractingLayer(self.embedding_size if i == 0 else att_embedding_size * att_head_num,\n                              att_embedding_size, att_head_num, att_res, device=device) for i in range(att_layer_num)])\n            \n        self.to(device)\n\n    def forward(self, X):\n\n        sparse_embedding_list, dense_value_list = self.input_from_feature_columns(X, self.dnn_feature_columns,\n                                                                                  self.embedding_dict)\n\n        linear_logit = self.linear_model(X)\n         \n        att_input = concat_fun(sparse_embedding_list, axis=1)\n        for layer in self.int_layers:\n            att_input = layer(att_input)\n        att_output = torch.flatten(att_input, start_dim=1)\n            \n        if self.use_cin:\n            cin_input = torch.cat(sparse_embedding_list, dim=1)\n            cin_output = self.cin(cin_input)\n            cin_logit = self.cin_linear(cin_output)\n        if self.use_dnn:\n            dnn_input = combined_dnn_input(sparse_embedding_list, dense_value_list)\n            dnn_output = self.dnn(dnn_input)\n            dnn_logit = self.dnn_linear(dnn_output)\n\n        if len(self.dnn_hidden_units) == 0 and len(self.cin_layer_size) == 0:  # only linear\n            final_logit = linear_logit\n        elif len(self.dnn_hidden_units) == 0 and len(self.cin_layer_size) > 0:  # linear + CIN\n            final_logit = linear_logit + cin_logit\n        elif len(self.dnn_hidden_units) > 0 and len(self.cin_layer_size) == 0:  # linear +　Deep\n            final_logit = linear_logit + dnn_logit\n        elif len(self.dnn_hidden_units) > 0 and len(self.cin_layer_size) > 0:  # linear + CIN + Deep\n            final_logit = linear_logit + dnn_logit + cin_logit\n        else:\n            raise NotImplementedError\n        \n        stack_out = concat_fun([att_output, dnn_output])\n        final_logit += self.dnn_linear2(stack_out)\n        y_pred = self.out(final_logit)\n\n        return y_pred\n\n#DCN-M\n#---------------------------------------------------------------------------------------------------------------\nclass DCNMix(BaseModel):\n    \"\"\"Instantiates the DCN-Mix model.\n\n    :param linear_feature_columns: An iterable containing all the features used by linear part of the model.\n    :param dnn_feature_columns: An iterable containing all the features used by deep part of the model.\n    :param cross_num: positive integet,cross layer number\n    :param dnn_hidden_units: list,list of positive integer or empty list, the layer number and units in each layer of DNN\n    :param l2_reg_embedding: float. L2 regularizer strength applied to embedding vector\n    :param l2_reg_cross: float. L2 regularizer strength applied to cross net\n    :param l2_reg_dnn: float. L2 regularizer strength applied to DNN\n    :param init_std: float,to use as the initialize std of embedding vector\n    :param seed: integer ,to use as random seed.\n    :param dnn_dropout: float in [0,1), the probability we will drop out a given DNN coordinate.\n    :param dnn_use_bn: bool. Whether use BatchNormalization before activation or not DNN\n    :param dnn_activation: Activation function to use in DNN\n    :param low_rank: Positive integer, dimensionality of low-rank sapce.\n    :param num_experts: Positive integer, number of experts.\n    :param task: str, ``\"binary\"`` for  binary logloss or  ``\"regression\"`` for regression loss\n    :param device: str, ``\"cpu\"`` or ``\"cuda:0\"``\n    :return: A PyTorch model instance.\n    \n    \"\"\"\n\n    def __init__(self, linear_feature_columns,\n                 dnn_feature_columns, cross_num=2,\n                 dnn_hidden_units=(128, 128), l2_reg_linear=0.0001,\n                 l2_reg_embedding=0.0001, l2_reg_cross=0.0001, l2_reg_dnn=0.001, init_std=0.0001, seed=1024,\n                 dnn_dropout=0.5, low_rank=32, num_experts=4,\n                 dnn_activation='relu', dnn_use_bn=True, task='binary', device='cpu'):\n\n        super(DCNMix, self).__init__(linear_feature_columns=linear_feature_columns,\n                                     dnn_feature_columns=dnn_feature_columns, l2_reg_embedding=l2_reg_embedding,\n                                     init_std=init_std, seed=seed, task=task, device=device)\n        self.dnn_hidden_units = dnn_hidden_units\n        self.cross_num = cross_num\n        self.dnn = DNN(self.compute_input_dim(dnn_feature_columns), dnn_hidden_units,\n                       activation=dnn_activation, use_bn=dnn_use_bn, l2_reg=l2_reg_dnn, dropout_rate=dnn_dropout,\n                       init_std=init_std, device=device)\n        if len(self.dnn_hidden_units) > 0 and self.cross_num > 0:\n            dnn_linear_in_feature = self.compute_input_dim(dnn_feature_columns) + dnn_hidden_units[-1]\n        elif len(self.dnn_hidden_units) > 0:\n            dnn_linear_in_feature = dnn_hidden_units[-1]\n        elif self.cross_num > 0:\n            dnn_linear_in_feature = self.compute_input_dim(dnn_feature_columns)\n\n        self.dnn_linear = nn.Linear(dnn_linear_in_feature, 1, bias=False).to(\n            device)\n        self.crossnet = CrossNetMix(in_features=self.compute_input_dim(dnn_feature_columns),\n                                    low_rank=low_rank, num_experts=num_experts,\n                                    layer_num=cross_num, device=device)\n        self.add_regularization_weight(\n            filter(lambda x: 'weight' in x[0] and 'bn' not in x[0], self.dnn.named_parameters()), l2_reg_dnn)\n        self.add_regularization_weight(self.dnn_linear.weight, l2_reg_linear)\n        self.add_regularization_weight(self.crossnet.U_list, l2_reg_cross)\n        self.add_regularization_weight(self.crossnet.V_list, l2_reg_cross)\n        self.add_regularization_weight(self.crossnet.C_list, l2_reg_cross)\n        \n        #-----\n        #afm\n        self.fm2 = AFMLayer(self.embedding_size, attention_factor=8, l2_reg_w=1e-5, dropout_rate=0.5,\n                               seed=1024, device=device)\n        self.add_regularization_weight(self.fm2.attention_W, weight_decay=1e-5)\n        \n        #---------\n        field_num = len(self.embedding_dict)\n        att_layer_num=3\n        att_embedding_size=8\n        att_head_num=2\n        att_res=True\n        dnn_linear_in_feature2 = dnn_hidden_units[-1] + \\\n                                    field_num * att_embedding_size * att_head_num\n        self.dnn_linear2 = nn.Linear(dnn_linear_in_feature2, 1, bias=False).to(device)\n        self.int_layers = nn.ModuleList(\n            [InteractingLayer(self.embedding_size if i == 0 else att_embedding_size * att_head_num,\n                              att_embedding_size, att_head_num, att_res, device=device) for i in range(att_layer_num)])\n\n\n        self.to(device)\n\n    def forward(self, X):\n\n        logit = self.linear_model(X)\n        sparse_embedding_list, dense_value_list = self.input_from_feature_columns(X, self.dnn_feature_columns,\n                                                                                  self.embedding_dict)\n\n        dnn_input = combined_dnn_input(sparse_embedding_list, dense_value_list)\n        \n        att_input = concat_fun(sparse_embedding_list, axis=1)\n        for layer in self.int_layers:\n            att_input = layer(att_input)\n        att_output = torch.flatten(att_input, start_dim=1)\n    \n        \n        #if len(sparse_embedding_list) > 0:\n        #    afm_output = self.fm2(sparse_embedding_list)\n\n        if len(self.dnn_hidden_units) > 0 and self.cross_num > 0:  # Deep & Cross\n            \n            deep_out = self.dnn(dnn_input)\n            cross_out = self.crossnet(dnn_input)\n            stack_out = torch.cat((cross_out, deep_out), dim=-1)\n            logit += self.dnn_linear(stack_out)\n            \n            stack_out = concat_fun([att_output, deep_out])\n            logit += self.dnn_linear2(stack_out)\n            \n            #logit += afm_output\n        elif len(self.dnn_hidden_units) > 0:  # Only Deep\n            deep_out = self.dnn(dnn_input)\n            logit += self.dnn_linear(deep_out)\n        elif self.cross_num > 0:  # Only Cross\n            cross_out = self.crossnet(dnn_input)\n            logit += self.dnn_linear(cross_out)\n        else:  # Error\n            pass\n        y_pred = self.out(logit)\n        return y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport os\n\nimport riiideducation\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import BatchNormalization,Dropout,Dense,Flatten,Conv1D\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.metrics import BinaryAccuracy\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check data available"},{"metadata":{},"cell_type":"markdown","source":"We have 4 datasets at our disposal"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"os.listdir('../input/riiid-test-answer-prediction')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nrows = 200 * 100000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lectures_csv = pd.read_csv(\"../input/riiid-test-answer-prediction/lectures.csv\")\nexample_test_csv = pd.read_csv(\"../input/riiid-test-answer-prediction/example_test.csv\")\ntrain_csv = pd.read_csv( \"../input/riiid-test-answer-prediction/train.csv\",\n                   usecols=[1, 2, 3, 4, 5, 7, 8, 9],\n                   dtype={'timestamp': 'int64',\n                          'user_id': 'int32',\n                          'content_id': 'int16',\n                          'content_type_id': 'int8',\n                          'task_container_id': 'int16',\n                          'answered_correctly':'int8',\n                          'prior_question_elapsed_time': 'float32',\n                          'prior_question_had_explanation': 'boolean'}\n                   )\n\nquestions_csv = pd.read_csv(\"../input/riiid-test-answer-prediction/questions.csv\")\nexample_test_csv = pd.read_csv(\"../input/riiid-test-answer-prediction/example_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Pre-Processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 0 if the event was a question being posed to the user, 1 if the event was the user watching a lecture. So, let's keep just the questions\ntrain_csv = train_csv[train_csv.content_type_id == 0]\n# read -1 as null, for lectures\ntrain_csv = train_csv[train_csv.answered_correctly != -1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv = train_csv.sort_values(['timestamp'], ascending=True).reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"content_mean_final = train_csv[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean'])\ncontent_mean_final.columns = [\"answered_correctly_content_mean\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_mean_final = train_csv[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean', 'sum', 'count'])\nuser_mean_final.columns = [\"answered_correctly_user_mean\", 'sum_correct', 'count']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#saving value to fillna\nelapsed_time_mean_final = train_csv.prior_question_elapsed_time.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv.drop(['timestamp', 'content_type_id'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Validation/Train datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"validation = pd.DataFrame()\nfor i in range(4):\n    last_records = train_csv.drop_duplicates('user_id', keep = 'last')\n    train_csv = train_csv[~train_csv.index.isin(last_records.index)]\n    validation = validation.append(last_records)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.DataFrame()\nfor i in range(15):\n    last_records = train_csv.drop_duplicates('user_id', keep = 'last')\n    train_csv = train_csv[~train_csv.index.isin(last_records.index)]\n    X = X.append(last_records)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_c = train_csv[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean'])\nresults_c.columns = [\"answered_correctly_content_mean\"]\n\nresults_u = train_csv[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean', 'sum', 'count'])\nresults_u.columns = [\"answered_correctly_user_mean\", 'sum_correct', 'count']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_time_mean = train_csv.prior_question_elapsed_time.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#clearing memory\ndel(train_csv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.merge(X, results_u, on=['user_id'], how=\"left\")\nX = pd.merge(X, results_c, on=['content_id'], how=\"left\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation = pd.merge(validation, results_u, on=['user_id'], how=\"left\")\nvalidation = pd.merge(validation, results_c, on=['content_id'], how=\"left\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = X['answered_correctly']\nX = X.drop(['answered_correctly'], axis=1)\n\ny_val = validation['answered_correctly']\nX_val = validation.drop(['answered_correctly'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lencoder = LabelEncoder()\n\nX['prior_question_had_explanation'].fillna(False, inplace = True)\nX['prior_question_had_explanation_enc'] = lencoder.fit_transform(X['prior_question_had_explanation'])\nX['answered_correctly_user_mean'].fillna(0.5,  inplace=True)\nX['answered_correctly_content_mean'].fillna(0.5,  inplace=True)\nX['sum_correct'].fillna(0, inplace = True)\nX['count'].fillna(0, inplace = True)\nX['prior_question_elapsed_time'].fillna(result_time_mean, inplace = True)\nX.fillna(0, inplace =True)\n\nX_val['prior_question_had_explanation'].fillna(False, inplace = True)\nX_val['prior_question_had_explanation_enc'] = lencoder.fit_transform(X_val['prior_question_had_explanation'])\nX_val['answered_correctly_user_mean'].fillna(0.5,  inplace=True)\nX_val['answered_correctly_content_mean'].fillna(0.5,  inplace=True)\nX_val['sum_correct'].fillna(0, inplace = True)\nX_val['count'].fillna(0, inplace = True)\nX_val['prior_question_elapsed_time'].fillna(result_time_mean, inplace = True)\nX_val.fillna(0, inplace =True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X[['answered_correctly_user_mean', 'answered_correctly_content_mean', 'sum_correct', 'count',\n       'prior_question_elapsed_time','prior_question_had_explanation_enc']]\nX_val = X_val[['answered_correctly_user_mean', 'answered_correctly_content_mean', 'sum_correct', 'count',\n       'prior_question_elapsed_time','prior_question_had_explanation_enc']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cont_columns = ['answered_correctly_user_mean', 'answered_correctly_content_mean', 'sum_correct', 'count',\n       'prior_question_elapsed_time']\n\ncat_columns = ['prior_question_had_explanation_enc']\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler(feature_range=(0, 1))\nfor col in cat_columns+cont_columns:\n    X[col] = scaler.fit_transform(X[col].values.reshape(-1,1))\n    X_val[col] = scaler.fit_transform(X_val[col].values.reshape(-1,1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### cnn"},{"metadata":{"trusted":true},"cell_type":"code","source":"fixlen_feature_columns = [SparseFeat(feat, 50000)\n                          for feat in cat_columns] + [DenseFeat(feat, 1, )\n                                                      for feat in cont_columns]\n\nfeature_names = get_feature_names(fixlen_feature_columns)\n\n# 3.generate input data for model\n\ntrain_model_input = {name: X[name] for name in feature_names}\ntest_model_input = {name: X_val[name] for name in feature_names}\n\ndevice = 'cpu'\nuse_cuda = True\nif use_cuda and torch.cuda.is_available():\n    print('cuda ready...')\n    device = 'cuda:0'\n\n'''\nmodel = DeepFM(linear_feature_columns=fixlen_feature_columns, dnn_feature_columns=fixlen_feature_columns,\n               task='binary',dnn_dropout=0.5, dnn_use_bn=True, \n               l2_reg_embedding=1e-5, device=device)\n\n'''\n\n'''\nmodel = DCNMix(linear_feature_columns=fixlen_feature_columns, dnn_feature_columns=fixlen_feature_columns,dnn_use_bn=True,\n            cross_num=2, dnn_hidden_units=[64,64,64,64,64,64,64,64,64,64,], dnn_dropout=0.5, device=device)\n\n'''\nmodel = xDeepFM(fixlen_feature_columns, fixlen_feature_columns, dnn_use_bn=True, dnn_dropout=0.5, device='cuda:0')\n\nmodel.compile(\"adam\", \"binary_crossentropy\",\n              metrics=[\"binary_crossentropy\", \"auc\"], )\n\nmodel.fit(train_model_input, y.values, batch_size=2**15, epochs=20, verbose=2, validation_split=0.2)\n\npred_ans = model.predict(test_model_input, 512)\nprint(\"\")\nprint(\"test LogLoss\", round(log_loss(y_val.values, pred_ans), 4))\nprint(\"test AUC\", round(roc_auc_score(y_val.values, pred_ans), 4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"env = riiideducation.make_env()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iter_test = env.iter_test()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for (test_df, sample_prediction_df) in iter_test:\n    test_df = pd.merge(test_df, user_mean_final, on=['user_id'],  how=\"left\")\n    test_df = pd.merge(test_df, content_mean_final, on=['content_id'],  how=\"left\")\n    \n    test_df['answered_correctly_user_mean'].fillna(0.5,  inplace=True)\n    test_df['answered_correctly_content_mean'].fillna(0.5,  inplace=True)\n    test_df['sum_correct'].fillna(0, inplace=True)\n    test_df['count'].fillna(0, inplace=True)\n    test_df['prior_question_elapsed_time'].fillna(elapsed_time_mean_final, inplace = True)\n    test_df['prior_question_had_explanation'].fillna(False, inplace=True)\n    test_df[\"prior_question_had_explanation_enc\"] = lencoder.transform(test_df[\"prior_question_had_explanation\"])\n    \n    test_df.fillna(-1, inplace=True)\n    \n    for col in cat_columns + cont_columns:\n        test_df[col] = scaler.fit_transform(test_df[col].values.reshape(-1,1))\n    \n    '''\n    fixlen_feature_columns = [SparseFeat(feat, 50000)\n                          for feat in cat_columns] + [DenseFeat(feat, 1, )\n                                                      for feat in cont_columns]\n    '''\n    \n    feature_names = get_feature_names(fixlen_feature_columns)\n    \n    test_model_input = {name: test_df[name] for name in feature_names}\n\n    test_df['answered_correctly'] = model.predict(test_model_input, 1024)\n\n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}
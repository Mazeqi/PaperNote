{"cells":[{"metadata":{},"cell_type":"markdown","source":"This is a small modification and combination of these two notebooks\n1. https://www.kaggle.com/takamotoki/lgbm-iii-part2 \n2. https://www.kaggle.com/code1110/riiid-lgb-hyperparameter-tuning\nHope that it will help you guys..."},{"metadata":{},"cell_type":"markdown","source":"# ## Reading Data and Importing Libraries ##"},{"metadata":{"trusted":true},"cell_type":"code","source":"import riiideducation\n# import dask.dataframe as dd\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\nenv = riiideducation.make_env()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nrows = 100 * 10000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/train.csv',\n                   usecols=[1, 2, 3, 4, 5, 7, 8, 9],\n                   #nrows = nrows,\n                   dtype={'timestamp': 'int64',\n                          'user_id': 'int32',\n                          'content_id': 'int16',\n                          'content_type_id': 'int8',\n                          'task_container_id': 'int16',\n                          'answered_correctly':'int8',\n                          'prior_question_elapsed_time': 'float32',\n                          'prior_question_had_explanation': 'boolean'}\n                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reading in question df\nquestions_df = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/questions.csv',                         \n                            usecols=[0, 3],\n                            dtype={'question_id': 'int16',\n                              'part': 'int8'}\n                          )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Affirmatives (True) for content_type_id are only for those with a different type of content (lectures). These are not real questions."},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#removing True or 1 for content_type_id\n\ntrain = train[train.content_type_id == False].sort_values('timestamp').reset_index(drop = True)\nelapsed_mean = train.prior_question_elapsed_time.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Extract Feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"# feature_1\nresults_c_final = train[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean','sum','count','std'])\nresults_c_final.columns = [\"content_y_mean\",\"content_y_sum\",\"content_y_count\",\"content_y_std\"]\n\n# feature_2\nresults_u_final = train[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean', 'sum', 'count','std'])\nresults_u_final.columns = ['user_y_mean', 'user_y_sum', 'user_y_count','user_y_std']\n\n# feature_3\nresults_ct_final = train[['content_id','prior_question_elapsed_time']].groupby(['content_id']).agg(['mean', 'sum', 'count','std'])\nresults_ct_final.columns = ['content_t_mean', 'content_t_sum', 'content_t_count','content_t_std']\n\n# feature_4\nresults_ut_final = train[['user_id','prior_question_elapsed_time']].groupby(['user_id']).agg(['mean', 'sum', 'count','std'])\nresults_ut_final.columns = ['user_t_mean', 'user_t_sum', 'user_t_count','user_t_std']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# feature_5\ngroup1 = train.loc[(train.content_type_id == False), ['task_container_id', 'user_id']].groupby(['task_container_id']).agg(['count'])\ngroup1.columns = ['avg_questions']\n\ngroup2 = train.loc[(train.content_type_id == False), ['task_container_id', 'user_id']].groupby(['task_container_id']).agg(['nunique'])\ngroup2.columns = ['avg_questions']\n\ngroup3 = group1 / group2\ngroup3['avg_questions_seen'] = group3.avg_questions.cumsum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.merge(train, questions_df, left_on = 'content_id', right_on = 'question_id', how = 'left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_q_final = train.loc[train.content_type_id == False, ['question_id','answered_correctly']].groupby(['question_id']).agg(['mean'])\nresults_q_final.columns = ['quest_pct']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_q2_final = train.loc[train.content_type_id == False, ['question_id','part']].groupby(['question_id']).agg(['count'])\nresults_q2_final.columns = ['count']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# feature_6\nquestion2 = pd.merge(questions_df, results_q_final, left_on = 'question_id', right_on = 'question_id', how = 'left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"question2 = pd.merge(question2, results_q2_final, left_on = 'question_id', right_on = 'question_id', how = 'left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"question2.quest_pct = round(question2.quest_pct,5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(['timestamp', 'content_type_id', 'question_id', 'part'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_c_tv = train[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean','sum','count','std'])\nresults_c_tv.columns = [\"content_y_mean\",\"content_y_sum\",\"content_y_count\",\"content_y_std\"]\n\nresults_u_tv = train[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean', 'sum', 'count','std'])\nresults_u_tv.columns = ['user_y_mean', 'user_y_sum', 'user_y_count','user_y_std']\n\nresults_ct_tv = train[['content_id','prior_question_elapsed_time']].groupby(['content_id']).agg(['mean', 'sum', 'count','std'])\nresults_ct_tv.columns = ['content_t_mean', 'content_t_sum', 'content_t_count','content_t_std']\n\nresults_ut_tv = train[['user_id','prior_question_elapsed_time']].groupby(['user_id']).agg(['mean', 'sum', 'count','std'])\nresults_ut_tv.columns = ['user_t_mean', 'user_t_sum', 'user_t_count','user_t_std']\n\nprior_mean_user = results_ut_tv.user_t_mean.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Validation Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"validation = pd.DataFrame()\n\nfor i in range(6):\n    last_records = train.drop_duplicates('user_id', keep = 'last')\n    train = train[~train.index.isin(last_records.index)]\n    validation = validation.append(last_records)\n    #print('validation : ', i)\n\n\nX = pd.DataFrame()\n\nfor i in range(30):\n    last_records = train.drop_duplicates('user_id', keep = 'last')\n    train = train[~train.index.isin(last_records.index)]\n    X = X.append(last_records)\n    #print('X : ', i)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.merge(X, results_u_tv, on=['user_id'], how=\"left\")\nX = pd.merge(X, results_c_tv, on=['content_id'], how=\"left\")\nX = pd.merge(X, results_ut_tv, on=['user_id'], how=\"left\")\nX = pd.merge(X, results_ct_tv, on=['content_id'], how=\"left\")\nX = pd.merge(X, group3, left_on=['task_container_id'], right_index= True, how=\"left\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation = pd.merge(validation, results_u_tv, on=['user_id'], how=\"left\")\nvalidation = pd.merge(validation, results_c_tv, on=['content_id'], how=\"left\")\nvalidation = pd.merge(validation, results_ut_tv, on=['user_id'], how=\"left\")\nvalidation = pd.merge(validation, results_ct_tv, on=['content_id'], how=\"left\")\nvalidation = pd.merge(validation, group3, left_on=['task_container_id'], right_index= True, how=\"left\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nlb_make = LabelEncoder()\n\nX.prior_question_had_explanation.fillna(False, inplace = True)\nvalidation.prior_question_had_explanation.fillna(False, inplace = True)\n\nvalidation[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(validation[\"prior_question_had_explanation\"])\nX[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(X[\"prior_question_had_explanation\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"content_mean = question2.quest_pct.mean()\n\nquestion2.quest_pct.mean()\n#there are a lot of high percentage questions, should use median instead?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#filling questions with no info with a new value\nquestion2.quest_pct = question2.quest_pct.mask((question2['count'] < 3), .65)\n\n\n#filling very hard new questions with a more reasonable value\nquestion2.quest_pct = question2.quest_pct.mask((question2.quest_pct < .2) & (question2['count'] < 21), .2)\n\n#filling very easy new questions with a more reasonable value\nquestion2.quest_pct = question2.quest_pct.mask((question2.quest_pct > .95) & (question2['count'] < 21), .95)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.merge(X, question2, left_on = 'content_id', right_on = 'question_id', how = 'left')\nvalidation = pd.merge(validation, question2, left_on = 'content_id', right_on = 'question_id', how = 'left')\nX.part = X.part - 1\nvalidation.part = validation.part - 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = X['answered_correctly']\nX = X.drop(['answered_correctly'], axis=1)\nX.head()\n\ny_val = validation['answered_correctly']\nX_val = validation.drop(['answered_correctly'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# training"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_features = [c for c in X.columns if c not in ['user_id','content_id','prior_question_had_explanation']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X[columns_features]\nX_val = X_val[columns_features]\n\nX.fillna(-1,  inplace=True)\nX_val.fillna(-1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\n\ny_true = np.array(y_val)\nlgb_train = lgb.Dataset(X, y, categorical_feature = ['part', 'prior_question_had_explanation_enc'],free_raw_data=False)\nlgb_eval = lgb.Dataset(X_val, y_val, categorical_feature = ['part', 'prior_question_had_explanation_enc'], reference=lgb_train, free_raw_data=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def objective(trial):    \n    params = {\n            'num_leaves': trial.suggest_int('num_leaves', 32, 512),\n            'boosting_type': 'gbdt',\n            'max_bin': trial.suggest_int('max_bin', 700, 900),\n            'objective': 'binary',\n            'metric': 'auc',\n            'max_depth': trial.suggest_int('max_depth', 4, 16),\n            'min_child_weight': trial.suggest_int('min_child_weight', 1, 16),\n            'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n            'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n            'bagging_freq': trial.suggest_int('bagging_freq', 1, 8),\n            'min_child_samples': trial.suggest_int('min_child_samples', 4, 80),\n            'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 1.0),\n            'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 1.0),\n            'early_stopping_rounds': 10\n            }\n    model = lgb.train(params, lgb_train, valid_sets=[lgb_train, lgb_eval], verbose_eval=1000, num_boost_round=1300)\n    val_pred = model.predict(X_val)\n    score = roc_auc_score(y_true, val_pred)\n    print(f\"AUC = {score}\")\n    return score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import optuna","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bayesian optimization\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of finished trials: {}'.format(len(study.trials)))\n\nprint('Best trial:')\ntrial = study.best_trial\n\nprint('  Value: {}'.format(trial.value))\n\nprint('  Params: ')\nfor key, value in trial.params.items():\n    print('    {}: {}'.format(key, value))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot history\nfrom optuna.visualization import plot_optimization_history\nplot_optimization_history(study)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = lgb.train(trial.params, lgb_train, valid_sets=[lgb_train, lgb_eval], verbose_eval=1000,num_boost_round=1300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_val)\nroc_auc_score(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#displaying the most important features by split\nlgb.plot_importance(model)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#displaying the most important features by gain\nlgb.plot_importance(model, importance_type = 'gain')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Making Predictions for New Data ##"},{"metadata":{"trusted":true},"cell_type":"code","source":"iter_test = env.iter_test()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for (test_df, sample_prediction_df) in iter_test:\n    test_df['task_container_id'] = test_df.task_container_id.mask(test_df.task_container_id > 9999, 9999)\n    test_df = pd.merge(test_df, group3, left_on=['task_container_id'], right_index= True, how=\"left\")\n    test_df = pd.merge(test_df, question2, left_on = 'content_id', right_on = 'question_id', how = 'left')\n    \n    test_df = pd.merge(test_df, results_u_final, on=['user_id'],  how=\"left\")\n    test_df = pd.merge(test_df, results_c_final, on=['content_id'],  how=\"left\")\n    test_df = pd.merge(test_df, results_ut_final, on=['user_id'],  how=\"left\")\n    test_df = pd.merge(test_df, results_ct_final, on=['content_id'],  how=\"left\")\n    \n    \n    test_df['quest_pct'].fillna(content_mean, inplace=True)\n    test_df['part'] = test_df.part - 1\n    test_df['part'].fillna(4, inplace = True)\n    \n    test_df['prior_question_elapsed_time'].fillna(elapsed_mean, inplace = True)\n    test_df['prior_question_had_explanation'].fillna(False, inplace=True)\n    test_df[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(test_df[\"prior_question_had_explanation\"])\n    \n   \n    \n    X_test = test_df[columns_features]\n    X_test.fillna(-1, inplace=True)\n\n    test_df['answered_correctly'] =  model.predict(X_test)\n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}
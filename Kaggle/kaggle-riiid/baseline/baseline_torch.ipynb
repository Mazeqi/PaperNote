{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import riiideducation\n",
    "#import dask.dataframe as dd\n",
    "import  pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import warnings\n",
    "import gc\n",
    "warnings.filterwarnings('ignore')\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = 'riiid_data/'\n",
    "file_train = 'train.csv'\n",
    "file_questions = 'questions.csv'\n",
    "file_lecture = 'lectures.csv'\n",
    "nrows =  100*100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\n",
    "                    dir_path + file_train, \n",
    "                    nrows=nrows, \n",
    "                    usecols=['row_id', 'timestamp', 'user_id', 'content_id', \n",
    "                             'content_type_id', 'task_container_id', 'answered_correctly',\n",
    "                            'prior_question_elapsed_time','prior_question_had_explanation'],\n",
    "                    dtype={\n",
    "                            'row_id': 'int64',\n",
    "                            'timestamp': 'int64',\n",
    "                            'user_id': 'int32',\n",
    "                            'content_id': 'int16',\n",
    "                            'content_type_id': 'int8',\n",
    "                            'task_container_id': 'int8',\n",
    "                            'answered_correctly': 'int8',\n",
    "                            'prior_question_elapsed_time': 'float32',\n",
    "                            'prior_question_had_explanation': 'str'\n",
    "                        }\n",
    "                   )\n",
    "#train = train[train.content_type_id == False]\n",
    "train_df = train_df.sort_values(['timestamp'], ascending=True)\n",
    "#train_df.drop(['timestamp'], axis=1,   inplace=True)\n",
    "\n",
    "\n",
    "questions_df = pd.read_csv(\n",
    "                        dir_path + file_questions, \n",
    "                        nrows=nrows,\n",
    "                        usecols=['question_id','bundle_id','part'], \n",
    "                        dtype={\n",
    "                            'question_id': 'int16',\n",
    "                            'bundle_id': 'int8',\n",
    "                            'part': 'int8',\n",
    "                       }\n",
    "                    )\n",
    "\n",
    "lectures_df = pd.read_csv(dir_path + file_lecture)\n",
    "train_df['prior_question_had_explanation'] = train_df['prior_question_had_explanation'].fillna('False').map({\"True\":True,\"False\":False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract lecture\n",
    "\n",
    "lectures_df['type_of'] = lectures_df['type_of'].replace('solving question', 'solving_question')\n",
    "\n",
    "lectures_df = pd.get_dummies(lectures_df, columns=['part', 'type_of'])\n",
    "\n",
    "part_lectures_columns = [column for column in lectures_df.columns if column.startswith('part')]\n",
    "\n",
    "types_of_lectures_columns = [column for column in lectures_df.columns if column.startswith('type_of_')]\n",
    "\n",
    "train_lectures = train_df[train_df.content_type_id == True].merge(lectures_df, left_on='content_id', right_on='lecture_id', how='left')\n",
    "\n",
    "user_lecture_stats_part = train_lectures.groupby('user_id')[part_lectures_columns + types_of_lectures_columns].sum()\n",
    "\n",
    "# add boolean features\n",
    "for column in user_lecture_stats_part.columns:\n",
    "    bool_column = column + '_boolean'\n",
    "    user_lecture_stats_part[bool_column] = (user_lecture_stats_part[column] > 0).astype(int)\n",
    "    \n",
    "del(train_lectures)\n",
    "train_df = train_df[train_df.content_type_id == False].sort_values('timestamp').reset_index(drop = True)\n",
    "elapsed_mean = train_df.prior_question_elapsed_time.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract train\n",
    "\n",
    "group1 = train_df.loc[(train_df.content_type_id == False), ['task_container_id', 'user_id']].groupby(['task_container_id']).agg(['count'])\n",
    "group1.columns = ['avg_questions']\n",
    "\n",
    "group2 = train_df.loc[(train_df.content_type_id == False), ['task_container_id', 'user_id']].groupby(['task_container_id']).agg(['nunique'])\n",
    "group2.columns = ['avg_questions']\n",
    "\n",
    "group3 = group1 / group2\n",
    "group3['avg_questions_seen'] = group3.avg_questions.cumsum()\n",
    "\n",
    "results_u_final = train_df.loc[train_df.content_type_id == False, ['user_id','answered_correctly']].groupby(['user_id']).agg(['mean'])\n",
    "results_u_final.columns = ['answered_correctly_user']\n",
    "\n",
    "results_u2_final = train_df.loc[train_df.content_type_id == False, ['user_id','prior_question_had_explanation']].groupby(['user_id']).agg(['mean'])\n",
    "results_u2_final.columns = ['explanation_mean_user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract question\n",
    "train_df = pd.merge(train_df, questions_df, left_on = 'content_id', right_on = 'question_id', how = 'left')\n",
    "\n",
    "results_q_final = train_df.loc[train_df.content_type_id == False, ['question_id','answered_correctly']].groupby(['question_id']).agg(['mean'])\n",
    "results_q_final.columns = ['quest_pct']\n",
    "\n",
    "results_q2_final = train_df.loc[train_df.content_type_id == False, ['question_id','part']].groupby(['question_id']).agg(['count'])\n",
    "results_q2_final.columns = ['count']\n",
    "\n",
    "question2 = pd.merge(questions_df, results_q_final, left_on = 'question_id', right_on = 'question_id', how = 'left')\n",
    "\n",
    "question2 = pd.merge(question2, results_q2_final, left_on = 'question_id', right_on = 'question_id', how = 'left')\n",
    "\n",
    "question2.quest_pct = round(question2.quest_pct,5)\n",
    "\n",
    "prior_mean_user = results_u2_final.explanation_mean_user.mean()\n",
    "\n",
    "train_df.drop(['timestamp', 'part', 'question_id', 'part', 'bundle_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract train\n",
    "X = train_df.iloc[:,:]\n",
    "#train_df = train_df[~train_df.index.isin(X.index)]\n",
    "\n",
    "results_u_X = train_df[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean'])\n",
    "results_u_X.columns = ['answered_correctly_user']\n",
    "\n",
    "results_u2_X = train_df[['user_id','prior_question_had_explanation']].groupby(['user_id']).agg(['mean'])\n",
    "results_u2_X.columns = ['explanation_mean_user']\n",
    "\n",
    "X = pd.merge(X, group3, left_on=['task_container_id'], right_index= True, how=\"left\")\n",
    "X = pd.merge(X, results_u_X, on=['user_id'], how=\"left\")\n",
    "X = pd.merge(X, results_u2_X, on=['user_id'], how=\"left\")\n",
    "X = pd.merge(X, user_lecture_stats_part, on=['user_id'], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_mean = question2.quest_pct.mean()\n",
    "question2.quest_pct.mean()\n",
    "#there are a lot of high percentage questions, should use median instead?\n",
    "\n",
    "#filling questions with no info with a new value\n",
    "question2.quest_pct = question2.quest_pct.mask((question2['count'] < 3), .65)\n",
    "\n",
    "\n",
    "#filling very hard new questions with a more reasonable value\n",
    "question2.quest_pct = question2.quest_pct.mask((question2.quest_pct < .2) & (question2['count'] < 21), .2)\n",
    "\n",
    "#filling very easy new questions with a more reasonable value\n",
    "question2.quest_pct = question2.quest_pct.mask((question2.quest_pct > .95) & (question2['count'] < 21), .95)\n",
    "\n",
    "X = pd.merge(X, question2, left_on = 'content_id', right_on = 'question_id', how = 'left')\n",
    "\n",
    "# validation = pd.merge(validation, question2, left_on = 'content_id', right_on = 'question_id', how = 'left')\n",
    "X.part = X.part - 1\n",
    "# validation.part = validation.part - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['answered_correctly']\n",
    "y.fillna(0, inplace = True)\n",
    "X = X.drop(['answered_correctly'], axis=1)\n",
    "#y_val = validation['answered_correctly']\n",
    "#X_val = validation.drop(['answered_correctly'], axis=1)\n",
    "\n",
    "# Filling with 0.5 for simplicity; there could likely be a better value\n",
    "X['answered_correctly_user'].fillna(0.65,  inplace=True)\n",
    "X['explanation_mean_user'].fillna(prior_mean_user,  inplace=True)\n",
    "X['quest_pct'].fillna(content_mean, inplace=True)\n",
    "\n",
    "X['part'].fillna(4, inplace = True)\n",
    "X['avg_questions_seen'].fillna(1, inplace = True)\n",
    "X['prior_question_elapsed_time'].fillna(elapsed_mean, inplace = True)\n",
    "#X['prior_question_had_explanation_enc'].fillna(0, inplace = True)\n",
    "\n",
    "X['part_1'].fillna(0, inplace = True)\n",
    "X['part_2'].fillna(0, inplace = True)\n",
    "X['part_3'].fillna(0, inplace = True)\n",
    "X['part_4'].fillna(0, inplace = True)\n",
    "X['part_5'].fillna(0, inplace = True)\n",
    "X['part_6'].fillna(0, inplace = True)\n",
    "X['part_7'].fillna(0, inplace = True)\n",
    "X['type_of_concept'].fillna(0, inplace = True)\n",
    "X['type_of_intention'].fillna(0, inplace = True)\n",
    "X['type_of_solving_question'].fillna(0, inplace = True)\n",
    "X['type_of_starter'].fillna(0, inplace = True)\n",
    "X['part_1_boolean'].fillna(0, inplace = True)\n",
    "X['part_2_boolean'].fillna(0, inplace = True)\n",
    "X['part_3_boolean'].fillna(0, inplace = True)\n",
    "X['part_4_boolean'].fillna(0, inplace = True)\n",
    "X['part_5_boolean'].fillna(0, inplace = True)\n",
    "X['part_6_boolean'].fillna(0, inplace = True)\n",
    "X['part_7_boolean'].fillna(0, inplace = True)\n",
    "X['type_of_concept_boolean'].fillna(0, inplace = True)\n",
    "X['type_of_intention_boolean'].fillna(0, inplace = True)\n",
    "X['type_of_solving_question_boolean'].fillna(0, inplace = True)\n",
    "X['type_of_starter_boolean'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9804604 entries, 0 to 9804603\n",
      "Data columns (total 38 columns):\n",
      " #   Column                            Dtype  \n",
      "---  ------                            -----  \n",
      " 0   row_id                            int64  \n",
      " 1   user_id                           int32  \n",
      " 2   content_id                        int16  \n",
      " 3   content_type_id                   int8   \n",
      " 4   task_container_id                 int8   \n",
      " 5   prior_question_elapsed_time       float32\n",
      " 6   prior_question_had_explanation    bool   \n",
      " 7   avg_questions                     float64\n",
      " 8   avg_questions_seen                float64\n",
      " 9   answered_correctly_user           float64\n",
      " 10  explanation_mean_user             float64\n",
      " 11  part_1                            float64\n",
      " 12  part_2                            float64\n",
      " 13  part_3                            float64\n",
      " 14  part_4                            float64\n",
      " 15  part_5                            float64\n",
      " 16  part_6                            float64\n",
      " 17  part_7                            float64\n",
      " 18  type_of_concept                   float64\n",
      " 19  type_of_intention                 float64\n",
      " 20  type_of_solving_question          float64\n",
      " 21  type_of_starter                   float64\n",
      " 22  part_1_boolean                    float64\n",
      " 23  part_2_boolean                    float64\n",
      " 24  part_3_boolean                    float64\n",
      " 25  part_4_boolean                    float64\n",
      " 26  part_5_boolean                    float64\n",
      " 27  part_6_boolean                    float64\n",
      " 28  part_7_boolean                    float64\n",
      " 29  type_of_concept_boolean           float64\n",
      " 30  type_of_intention_boolean         float64\n",
      " 31  type_of_solving_question_boolean  float64\n",
      " 32  type_of_starter_boolean           float64\n",
      " 33  question_id                       int16  \n",
      " 34  bundle_id                         int8   \n",
      " 35  part                              int8   \n",
      " 36  quest_pct                         float64\n",
      " 37  count                             float64\n",
      "dtypes: bool(1), float32(1), float64(28), int16(2), int32(1), int64(1), int8(4)\n",
      "memory usage: 2.3 GB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['prior_question_had_explanation','bundle_id','user_id', 'content_id', 'task_container_id']\n",
    "\n",
    "cont_columns = ['answered_correctly_user', 'explanation_mean_user', 'quest_pct', 'avg_questions_seen','prior_question_elapsed_time', 'part',\n",
    "                'part_1', 'part_2', 'part_3', 'part_4', 'part_5', 'part_6', 'part_7',\n",
    "               'type_of_concept', 'type_of_intention', 'type_of_solving_question', 'type_of_starter',\n",
    "               'part_1_boolean', 'part_2_boolean', 'part_3_boolean', 'part_4_boolean', 'part_5_boolean', 'part_6_boolean', 'part_7_boolean',\n",
    "               'type_of_concept_boolean', 'type_of_intention_boolean', 'type_of_solving_question_boolean', 'type_of_starter_boolean']\n",
    "\n",
    "#cont_columns = ['answered_correctly_user', 'explanation_mean_user', 'quest_pct', 'avg_questions_seen','prior_question_elapsed_time', ]\n",
    "\n",
    "features=cat_columns+cont_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior_question_had_explanation\n",
      "bundle_id\n",
      "user_id\n",
      "content_id\n",
      "task_container_id\n"
     ]
    }
   ],
   "source": [
    "def encode(df,cols):\n",
    "    enc =  {}\n",
    "    for col in cols:\n",
    "        print(col)\n",
    "        lbencoder = LabelEncoder()\n",
    "        lb = lbencoder.fit(df[col].values)\n",
    "        df[col]=lb.transform(df[col].values)\n",
    "        enc[col]=lb\n",
    "        \n",
    "    return df,enc\n",
    "\n",
    "X,enc_dict = encode(X,cat_columns)\n",
    "\n",
    "scale_dict={}\n",
    "fix_missing={}\n",
    "\n",
    "\n",
    "for col in cont_columns:\n",
    "    scaler = RobustScaler()\n",
    "    scale_dict[col]=scaler.fit(X[col].values.reshape(-1,1))\n",
    "    X[col] = scale_dict[col].transform(X[col].values.reshape(-1,1))\n",
    "    fix_missing[col] = X[col].mode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 1), (256, 50), (39491, 50), (13500, 50), (256, 50)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dims = [X[col].nunique() for col in cat_columns]\n",
    "cat_embs = [(dim, min(50,(dim+1)//2)) for dim in cat_dims]\n",
    "cat_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidDataset(Dataset):\n",
    "    def __init__(self, df,targets,cat_features,cont_features,mode='train'):\n",
    "        self.mode = mode\n",
    "        self.data_cont = df[cont_features].values\n",
    "        self.data_cat = df[cat_features].values\n",
    "        if mode=='train':\n",
    "            self.targets = targets.values \n",
    "        print(self.data_cont.shape)\n",
    "        print(self.data_cat.shape)\n",
    "        print(self.targets.shape)\n",
    "    def __len__(self):\n",
    "        return len(self.data_cont)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "            sample = {'data_cont': self.data_cont[idx], 'data_cat':self.data_cat[idx], 'target' : self.targets[idx]}\n",
    "            return sample\n",
    "        elif self.mode == 'test':\n",
    "            sample = {'data_cont': self.data_cont[idx], 'data_cat':self.data_cat[idx], 'target' : 0}\n",
    "            #return torch.FloatTensor(self.data_cont[idx]), torch.LongTensor(self.data_cat[idx]), 0\n",
    "            return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collater(data):\n",
    "    data_conts = [d_i['data_cont'] for d_i in data]\n",
    "    \n",
    "    data_cats = [d_i['data_cat'] for d_i in data]\n",
    "    \n",
    "    targets = [d_i['target'] for d_i in data]\n",
    "    \n",
    "    data_conts = np.stack(data_conts, axis=0)\n",
    "    \n",
    "    data_cats  =np.stack(data_cats, axis=0)\n",
    "    \n",
    "    targets  = np.stack(targets, axis=0)\n",
    "    \n",
    "    return {'data_cont' : torch.FloatTensor(data_conts), 'data_cat' : torch.LongTensor(data_cats), 'target' :  torch.FloatTensor(targets)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from sklearn.metrics import *\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import PackedSequence\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "try:\n",
    "    from tensorflow.python.keras.callbacks import CallbackList\n",
    "except ImportError:\n",
    "    from tensorflow.python.keras._impl.keras.callbacks import CallbackList\n",
    "    \n",
    "from collections import OrderedDict, namedtuple, defaultdict\n",
    "from itertools import chain\n",
    "\n",
    "# -------------------------------------------------------------------------------------\n",
    "# activation\n",
    "class Dice(nn.Module):\n",
    "    \"\"\"The Data Adaptive Activation Function in DIN,which can be viewed as a generalization of PReLu and can adaptively adjust the rectified point according to distribution of input data.\n",
    "\n",
    "    Input shape:\n",
    "        - 2 dims: [batch_size, embedding_size(features)]\n",
    "        - 3 dims: [batch_size, num_features, embedding_size(features)]\n",
    "\n",
    "    Output shape:\n",
    "        - Same shape as input.\n",
    "    \n",
    "    References\n",
    "        - [Zhou G, Zhu X, Song C, et al. Deep interest network for click-through rate prediction[C]//Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. ACM, 2018: 1059-1068.](https://arxiv.org/pdf/1706.06978.pdf)\n",
    "        - https://github.com/zhougr1993/DeepInterestNetwork, https://github.com/fanoping/DIN-pytorch\n",
    "    \"\"\"\n",
    "    def __init__(self, emb_size, dim=2, epsilon=1e-8, device='cpu'):\n",
    "        super(Dice, self).__init__()\n",
    "        assert dim == 2 or dim == 3\n",
    "\n",
    "        self.bn = nn.BatchNorm1d(emb_size, eps=epsilon)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dim = dim\n",
    "\n",
    "        if self.dim == 2:\n",
    "            self.alpha = torch.zeros((emb_size,)).to(device)\n",
    "        else:\n",
    "            self.alpha = torch.zeros((emb_size, 1)).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert x.dim() == self.dim\n",
    "        if self.dim == 2:\n",
    "            x_p = self.sigmoid(self.bn(x))\n",
    "            out = self.alpha * (1 - x_p) * x + x_p * x\n",
    "        else:\n",
    "            x = torch.transpose(x, 1, 2)\n",
    "            x_p = self.sigmoid(self.bn(x))\n",
    "            out = self.alpha * (1 - x_p) * x + x_p * x\n",
    "            out = torch.transpose(out, 1, 2)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class Identity(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return X\n",
    "\n",
    "\n",
    "def activation_layer(act_name, hidden_size=None, dice_dim=2):\n",
    "    \"\"\"Construct activation layers\n",
    "\n",
    "    Args:\n",
    "        act_name: str or nn.Module, name of activation function\n",
    "        hidden_size: int, used for Dice activation\n",
    "        dice_dim: int, used for Dice activation\n",
    "    Return:\n",
    "        act_layer: activation layer\n",
    "    \"\"\"\n",
    "    if isinstance(act_name, str):\n",
    "        if act_name.lower() == 'sigmoid':\n",
    "            act_layer = nn.Sigmoid()\n",
    "        elif act_name.lower() == 'linear':\n",
    "            act_layer = Identity()\n",
    "        elif act_name.lower() == 'relu':\n",
    "            act_layer = nn.ReLU(inplace=True)\n",
    "        elif act_name.lower() == 'dice':\n",
    "            assert dice_dim\n",
    "            act_layer = Dice(hidden_size, dice_dim)\n",
    "        elif act_name.lower() == 'prelu':\n",
    "            act_layer = nn.PReLU()\n",
    "    elif issubclass(act_name, nn.Module):\n",
    "        act_layer = act_name()\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    return act_layer\n",
    "\n",
    "\n",
    "class LocalActivationUnit(nn.Module):\n",
    "    \"\"\"The LocalActivationUnit used in DIN with which the representation of\n",
    "        user interests varies adaptively given different candidate items.\n",
    "\n",
    "    Input shape\n",
    "        - A list of two 3D tensor with shape:  ``(batch_size, 1, embedding_size)`` and ``(batch_size, T, embedding_size)``\n",
    "\n",
    "    Output shape\n",
    "        - 3D tensor with shape: ``(batch_size, T, 1)``.\n",
    "\n",
    "    Arguments\n",
    "        - **hidden_units**:list of positive integer, the attention net layer number and units in each layer.\n",
    "\n",
    "        - **activation**: Activation function to use in attention net.\n",
    "\n",
    "        - **l2_reg**: float between 0 and 1. L2 regularizer strength applied to the kernel weights matrix of attention net.\n",
    "\n",
    "        - **dropout_rate**: float in [0,1). Fraction of the units to dropout in attention net.\n",
    "\n",
    "        - **use_bn**: bool. Whether use BatchNormalization before activation or not in attention net.\n",
    "\n",
    "        - **seed**: A Python integer to use as random seed.\n",
    "\n",
    "    References\n",
    "        - [Zhou G, Zhu X, Song C, et al. Deep interest network for click-through rate prediction[C]//Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. ACM, 2018: 1059-1068.](https://arxiv.org/pdf/1706.06978.pdf)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_units=(64, 32), embedding_dim=4, activation='sigmoid', dropout_rate=0, dice_dim=3,\n",
    "                 l2_reg=0, use_bn=False):\n",
    "        super(LocalActivationUnit, self).__init__()\n",
    "\n",
    "        self.dnn = DNN(inputs_dim=4 * embedding_dim,\n",
    "                       hidden_units=hidden_units,\n",
    "                       activation=activation,\n",
    "                       l2_reg=l2_reg,\n",
    "                       dropout_rate=dropout_rate,\n",
    "                       dice_dim=dice_dim,\n",
    "                       use_bn=use_bn)\n",
    "\n",
    "        self.dense = nn.Linear(hidden_units[-1], 1)\n",
    "\n",
    "    def forward(self, query, user_behavior):\n",
    "        # query ad            : size -> batch_size * 1 * embedding_size\n",
    "        # user behavior       : size -> batch_size * time_seq_len * embedding_size\n",
    "        user_behavior_len = user_behavior.size(1)\n",
    "\n",
    "        queries = query.expand(-1, user_behavior_len, -1)\n",
    "\n",
    "        attention_input = torch.cat([queries, user_behavior, queries - user_behavior, queries * user_behavior],\n",
    "                                    dim=-1)  # as the source code, subtraction simulates verctors' difference\n",
    "        attention_output = self.dnn(attention_input)\n",
    "\n",
    "        attention_score = self.dense(attention_output)  # [B, T, 1]\n",
    "\n",
    "        return attention_score\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------\n",
    "# core\n",
    "class DNN(nn.Module):\n",
    "    \"\"\"The Multi Layer Percetron\n",
    "\n",
    "      Input shape\n",
    "        - nD tensor with shape: ``(batch_size, ..., input_dim)``. The most common situation would be a 2D input with shape ``(batch_size, input_dim)``.\n",
    "\n",
    "      Output shape\n",
    "        - nD tensor with shape: ``(batch_size, ..., hidden_size[-1])``. For instance, for a 2D input with shape ``(batch_size, input_dim)``, the output would have shape ``(batch_size, hidden_size[-1])``.\n",
    "\n",
    "      Arguments\n",
    "        - **inputs_dim**: input feature dimension.\n",
    "\n",
    "        - **hidden_units**:list of positive integer, the layer number and units in each layer.\n",
    "\n",
    "        - **activation**: Activation function to use.\n",
    "\n",
    "        - **l2_reg**: float between 0 and 1. L2 regularizer strength applied to the kernel weights matrix.\n",
    "\n",
    "        - **dropout_rate**: float in [0,1). Fraction of the units to dropout.\n",
    "\n",
    "        - **use_bn**: bool. Whether use BatchNormalization before activation or not.\n",
    "\n",
    "        - **seed**: A Python integer to use as random seed.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inputs_dim, hidden_units, activation='relu', l2_reg=0, dropout_rate=0, use_bn=False,\n",
    "                 init_std=0.0001, dice_dim=3, seed=1024, device='cpu'):\n",
    "        super(DNN, self).__init__()\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.seed = seed\n",
    "        self.l2_reg = l2_reg\n",
    "        self.use_bn = use_bn\n",
    "        if len(hidden_units) == 0:\n",
    "            raise ValueError(\"hidden_units is empty!!\")\n",
    "        hidden_units = [inputs_dim] + list(hidden_units)\n",
    "\n",
    "        self.linears = nn.ModuleList(\n",
    "            [nn.Linear(hidden_units[i], hidden_units[i + 1]) for i in range(len(hidden_units) - 1)])\n",
    "\n",
    "        if self.use_bn:\n",
    "            self.bn = nn.ModuleList(\n",
    "                [nn.BatchNorm1d(hidden_units[i + 1]) for i in range(len(hidden_units) - 1)])\n",
    "\n",
    "        self.activation_layers = nn.ModuleList(\n",
    "            [activation_layer(activation, hidden_units[i + 1], dice_dim) for i in range(len(hidden_units) - 1)])\n",
    "\n",
    "        for name, tensor in self.linears.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.normal_(tensor, mean=0, std=init_std)\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        deep_input = inputs\n",
    "\n",
    "        for i in range(len(self.linears)):\n",
    "\n",
    "            fc = self.linears[i](deep_input)\n",
    "\n",
    "            if self.use_bn:\n",
    "                fc = self.bn[i](fc)\n",
    "\n",
    "            fc = self.activation_layers[i](fc)\n",
    "\n",
    "            fc = self.dropout(fc)\n",
    "            deep_input = fc\n",
    "        return deep_input\n",
    "\n",
    "\n",
    "class PredictionLayer(nn.Module):\n",
    "    \"\"\"\n",
    "      Arguments\n",
    "         - **task**: str, ``\"binary\"`` for  binary logloss or  ``\"regression\"`` for regression loss\n",
    "         - **use_bias**: bool.Whether add bias term or not.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, task='binary', use_bias=True, **kwargs):\n",
    "        if task not in [\"binary\", \"multiclass\", \"regression\"]:\n",
    "            raise ValueError(\"task must be binary,multiclass or regression\")\n",
    "\n",
    "        super(PredictionLayer, self).__init__()\n",
    "        self.use_bias = use_bias\n",
    "        self.task = task\n",
    "        if self.use_bias:\n",
    "            self.bias = nn.Parameter(torch.zeros((1,)))\n",
    "\n",
    "    def forward(self, X):\n",
    "        output = X\n",
    "        if self.use_bias:\n",
    "            output += self.bias\n",
    "        if self.task == \"binary\":\n",
    "            output = torch.sigmoid(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class Conv2dSame(nn.Conv2d):\n",
    "    \"\"\" Tensorflow like 'SAME' convolution wrapper for 2D convolutions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1, bias=True):\n",
    "        super(Conv2dSame, self).__init__(\n",
    "            in_channels, out_channels, kernel_size, stride, 0, dilation,\n",
    "            groups, bias)\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ih, iw = x.size()[-2:]\n",
    "        kh, kw = self.weight.size()[-2:]\n",
    "        oh = math.ceil(ih / self.stride[0])\n",
    "        ow = math.ceil(iw / self.stride[1])\n",
    "        pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)\n",
    "        pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2])\n",
    "        out = F.conv2d(x, self.weight, self.bias, self.stride,\n",
    "                       self.padding, self.dilation, self.groups)\n",
    "        return out\n",
    "\n",
    "    \n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# sequence\n",
    "class SequencePoolingLayer(nn.Module):\n",
    "    \"\"\"The SequencePoolingLayer is used to apply pooling operation(sum,mean,max) on variable-length sequence feature/multi-value feature.\n",
    "\n",
    "      Input shape\n",
    "        - A list of two  tensor [seq_value,seq_len]\n",
    "\n",
    "        - seq_value is a 3D tensor with shape: ``(batch_size, T, embedding_size)``\n",
    "\n",
    "        - seq_len is a 2D tensor with shape : ``(batch_size, 1)``,indicate valid length of each sequence.\n",
    "\n",
    "      Output shape\n",
    "        - 3D tensor with shape: ``(batch_size, 1, embedding_size)``.\n",
    "\n",
    "      Arguments\n",
    "        - **mode**:str.Pooling operation to be used,can be sum,mean or max.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mode='mean', supports_masking=False, device='cpu'):\n",
    "\n",
    "        super(SequencePoolingLayer, self).__init__()\n",
    "        if mode not in ['sum', 'mean', 'max']:\n",
    "            raise ValueError('parameter mode should in [sum, mean, max]')\n",
    "        self.supports_masking = supports_masking\n",
    "        self.mode = mode\n",
    "        self.device = device\n",
    "        self.eps = torch.FloatTensor([1e-8]).to(device)\n",
    "        self.to(device)\n",
    "\n",
    "    def _sequence_mask(self, lengths, maxlen=None, dtype=torch.bool):\n",
    "        # Returns a mask tensor representing the first N positions of each cell.\n",
    "        if maxlen is None:\n",
    "            maxlen = lengths.max()\n",
    "        row_vector = torch.arange(0, maxlen, 1).to(self.device)\n",
    "        matrix = torch.unsqueeze(lengths, dim=-1)\n",
    "        mask = row_vector < matrix\n",
    "\n",
    "        mask.type(dtype)\n",
    "        return mask\n",
    "\n",
    "    def forward(self, seq_value_len_list):\n",
    "        if self.supports_masking:\n",
    "            uiseq_embed_list, mask = seq_value_len_list  # [B, T, E], [B, 1]\n",
    "            mask = mask.float()\n",
    "            user_behavior_length = torch.sum(mask, dim=-1, keepdim=True)\n",
    "            mask = mask.unsqueeze(2)\n",
    "        else:\n",
    "            uiseq_embed_list, user_behavior_length = seq_value_len_list  # [B, T, E], [B, 1]\n",
    "            mask = self._sequence_mask(user_behavior_length, maxlen=uiseq_embed_list.shape[1],\n",
    "                                       dtype=torch.float32)  # [B, 1, maxlen]\n",
    "            mask = torch.transpose(mask, 1, 2)  # [B, maxlen, 1]\n",
    "\n",
    "        embedding_size = uiseq_embed_list.shape[-1]\n",
    "\n",
    "        mask = torch.repeat_interleave(mask, embedding_size, dim=2)  # [B, maxlen, E]\n",
    "\n",
    "        if self.mode == 'max':\n",
    "            hist = uiseq_embed_list - (1 - mask) * 1e9\n",
    "            hist = torch.max(hist, dim=1, keepdim=True)[0]\n",
    "            return hist\n",
    "        hist = uiseq_embed_list * mask.float()\n",
    "        hist = torch.sum(hist, dim=1, keepdim=False)\n",
    "\n",
    "        if self.mode == 'mean':\n",
    "            hist = torch.div(hist, user_behavior_length.type(torch.float32) + self.eps)\n",
    "\n",
    "        hist = torch.unsqueeze(hist, dim=1)\n",
    "        return hist\n",
    "\n",
    "\n",
    "class AttentionSequencePoolingLayer(nn.Module):\n",
    "    \"\"\"The Attentional sequence pooling operation used in DIN & DIEN.\n",
    "\n",
    "        Arguments\n",
    "          - **att_hidden_units**:list of positive integer, the attention net layer number and units in each layer.\n",
    "\n",
    "          - **att_activation**: Activation function to use in attention net.\n",
    "\n",
    "          - **weight_normalization**: bool.Whether normalize the attention score of local activation unit.\n",
    "\n",
    "          - **supports_masking**:If True,the input need to support masking.\n",
    "\n",
    "        References\n",
    "          - [Zhou G, Zhu X, Song C, et al. Deep interest network for click-through rate prediction[C]//Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. ACM, 2018: 1059-1068.](https://arxiv.org/pdf/1706.06978.pdf)\n",
    "      \"\"\"\n",
    "\n",
    "    def __init__(self, att_hidden_units=(80, 40), att_activation='sigmoid', weight_normalization=False,\n",
    "                 return_score=False, supports_masking=False, embedding_dim=4, **kwargs):\n",
    "        super(AttentionSequencePoolingLayer, self).__init__()\n",
    "        self.return_score = return_score\n",
    "        self.weight_normalization = weight_normalization\n",
    "        self.supports_masking = supports_masking\n",
    "        self.local_att = LocalActivationUnit(hidden_units=att_hidden_units, embedding_dim=embedding_dim,\n",
    "                                             activation=att_activation,\n",
    "                                             dropout_rate=0, use_bn=False)\n",
    "\n",
    "    def forward(self, query, keys, keys_length, mask=None):\n",
    "        \"\"\"\n",
    "        Input shape\n",
    "          - A list of three tensor: [query,keys,keys_length]\n",
    "\n",
    "          - query is a 3D tensor with shape:  ``(batch_size, 1, embedding_size)``\n",
    "\n",
    "          - keys is a 3D tensor with shape:   ``(batch_size, T, embedding_size)``\n",
    "\n",
    "          - keys_length is a 2D tensor with shape: ``(batch_size, 1)``\n",
    "\n",
    "        Output shape\n",
    "          - 3D tensor with shape: ``(batch_size, 1, embedding_size)``.\n",
    "        \"\"\"\n",
    "        batch_size, max_length, dim = keys.size()\n",
    "\n",
    "        # Mask\n",
    "        if self.supports_masking:\n",
    "            if mask is None:\n",
    "                raise ValueError(\"When supports_masking=True,input must support masking\")\n",
    "            keys_masks = mask.unsqueeze(1)\n",
    "        else:\n",
    "            keys_masks = torch.arange(max_length, device=keys_length.device, dtype=keys_length.dtype).repeat(batch_size,\n",
    "                                                                                                             1)  # [B, T]\n",
    "            keys_masks = keys_masks < keys_length.view(-1, 1)  # 0, 1 mask\n",
    "            keys_masks = keys_masks.unsqueeze(1)  # [B, 1, T]\n",
    "\n",
    "        attention_score = self.local_att(query, keys)  # [B, T, 1]\n",
    "\n",
    "        outputs = torch.transpose(attention_score, 1, 2)  # [B, 1, T]\n",
    "\n",
    "        if self.weight_normalization:\n",
    "            paddings = torch.ones_like(outputs) * (-2 ** 32 + 1)\n",
    "        else:\n",
    "            paddings = torch.zeros_like(outputs)\n",
    "\n",
    "        outputs = torch.where(keys_masks, outputs, paddings)  # [B, 1, T]\n",
    "\n",
    "        # Scale\n",
    "        # outputs = outputs / (keys.shape[-1] ** 0.05)\n",
    "\n",
    "        if self.weight_normalization:\n",
    "            outputs = F.softmax(outputs, dim=-1)  # [B, 1, T]\n",
    "\n",
    "        if not self.return_score:\n",
    "            # Weighted sum\n",
    "            outputs = torch.matmul(outputs, keys)  # [B, 1, E]\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class KMaxPooling(nn.Module):\n",
    "    \"\"\"K Max pooling that selects the k biggest value along the specific axis.\n",
    "\n",
    "      Input shape\n",
    "        -  nD tensor with shape: ``(batch_size, ..., input_dim)``.\n",
    "\n",
    "      Output shape\n",
    "        - nD tensor with shape: ``(batch_size, ..., output_dim)``.\n",
    "\n",
    "      Arguments\n",
    "        - **k**: positive integer, number of top elements to look for along the ``axis`` dimension.\n",
    "\n",
    "        - **axis**: positive integer, the dimension to look for elements.\n",
    "\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, k, axis, device='cpu'):\n",
    "        super(KMaxPooling, self).__init__()\n",
    "        self.k = k\n",
    "        self.axis = axis\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.axis < 0 or self.axis >= len(input.shape):\n",
    "            raise ValueError(\"axis must be 0~%d,now is %d\" %\n",
    "                             (len(input.shape) - 1, self.axis))\n",
    "\n",
    "        if self.k < 1 or self.k > input.shape[self.axis]:\n",
    "            raise ValueError(\"k must be in 1 ~ %d,now k is %d\" %\n",
    "                             (input.shape[self.axis], self.k))\n",
    "\n",
    "        out = torch.topk(input, k=self.k, dim=self.axis, sorted=True)[0]\n",
    "        return out\n",
    "\n",
    "\n",
    "class AGRUCell(nn.Module):\n",
    "    \"\"\" Attention based GRU (AGRU)\n",
    "\n",
    "        Reference:\n",
    "        -  Deep Interest Evolution Network for Click-Through Rate Prediction[J]. arXiv preprint arXiv:1809.03672, 2018.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super(AGRUCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "        # (W_ir|W_iz|W_ih)\n",
    "        self.weight_ih = nn.Parameter(torch.Tensor(3 * hidden_size, input_size))\n",
    "        self.register_parameter('weight_ih', self.weight_ih)\n",
    "        # (W_hr|W_hz|W_hh)\n",
    "        self.weight_hh = nn.Parameter(torch.Tensor(3 * hidden_size, hidden_size))\n",
    "        self.register_parameter('weight_hh', self.weight_hh)\n",
    "        if bias:\n",
    "            # (b_ir|b_iz|b_ih)\n",
    "            self.bias_ih = nn.Parameter(torch.Tensor(3 * hidden_size))\n",
    "            self.register_parameter('bias_ih', self.bias_ih)\n",
    "            # (b_hr|b_hz|b_hh)\n",
    "            self.bias_hh = nn.Parameter(torch.Tensor(3 * hidden_size))\n",
    "            self.register_parameter('bias_hh', self.bias_hh)\n",
    "            for tensor in [self.bias_ih, self.bias_hh]:\n",
    "                nn.init.zeros_(tensor, )\n",
    "        else:\n",
    "            self.register_parameter('bias_ih', None)\n",
    "            self.register_parameter('bias_hh', None)\n",
    "\n",
    "    def forward(self, input, hx, att_score):\n",
    "        gi = F.linear(input, self.weight_ih, self.bias_ih)\n",
    "        gh = F.linear(hx, self.weight_hh, self.bias_hh)\n",
    "        i_r, i_z, i_n = gi.chunk(3, 1)\n",
    "        h_r, h_z, h_n = gh.chunk(3, 1)\n",
    "\n",
    "        reset_gate = torch.sigmoid(i_r + h_r)\n",
    "        # update_gate = torch.sigmoid(i_z + h_z)\n",
    "        new_state = torch.tanh(i_n + reset_gate * h_n)\n",
    "\n",
    "        att_score = att_score.view(-1, 1)\n",
    "        hy = (1. - att_score) * hx + att_score * new_state\n",
    "        return hy\n",
    "\n",
    "\n",
    "class AUGRUCell(nn.Module):\n",
    "    \"\"\" Effect of GRU with attentional update gate (AUGRU)\n",
    "\n",
    "        Reference:\n",
    "        -  Deep Interest Evolution Network for Click-Through Rate Prediction[J]. arXiv preprint arXiv:1809.03672, 2018.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super(AUGRUCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "        # (W_ir|W_iz|W_ih)\n",
    "        self.weight_ih = nn.Parameter(torch.Tensor(3 * hidden_size, input_size))\n",
    "        self.register_parameter('weight_ih', self.weight_ih)\n",
    "        # (W_hr|W_hz|W_hh)\n",
    "        self.weight_hh = nn.Parameter(torch.Tensor(3 * hidden_size, hidden_size))\n",
    "        self.register_parameter('weight_hh', self.weight_hh)\n",
    "        if bias:\n",
    "            # (b_ir|b_iz|b_ih)\n",
    "            self.bias_ih = nn.Parameter(torch.Tensor(3 * hidden_size))\n",
    "            self.register_parameter('bias_ih', self.bias_ih)\n",
    "            # (b_hr|b_hz|b_hh)\n",
    "            self.bias_hh = nn.Parameter(torch.Tensor(3 * hidden_size))\n",
    "            self.register_parameter('bias_ih', self.bias_hh)\n",
    "            for tensor in [self.bias_ih, self.bias_hh]:\n",
    "                nn.init.zeros_(tensor, )\n",
    "        else:\n",
    "            self.register_parameter('bias_ih', None)\n",
    "            self.register_parameter('bias_hh', None)\n",
    "\n",
    "    def forward(self, input, hx, att_score):\n",
    "        gi = F.linear(input, self.weight_ih, self.bias_ih)\n",
    "        gh = F.linear(hx, self.weight_hh, self.bias_hh)\n",
    "        i_r, i_z, i_n = gi.chunk(3, 1)\n",
    "        h_r, h_z, h_n = gh.chunk(3, 1)\n",
    "\n",
    "        reset_gate = torch.sigmoid(i_r + h_r)\n",
    "        update_gate = torch.sigmoid(i_z + h_z)\n",
    "        new_state = torch.tanh(i_n + reset_gate * h_n)\n",
    "\n",
    "        att_score = att_score.view(-1, 1)\n",
    "        update_gate = att_score * update_gate\n",
    "        hy = (1. - update_gate) * hx + update_gate * new_state\n",
    "        return hy\n",
    "\n",
    "\n",
    "class DynamicGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bias=True, gru_type='AGRU'):\n",
    "        super(DynamicGRU, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        if gru_type == 'AGRU':\n",
    "            self.rnn = AGRUCell(input_size, hidden_size, bias)\n",
    "        elif gru_type == 'AUGRU':\n",
    "            self.rnn = AUGRUCell(input_size, hidden_size, bias)\n",
    "\n",
    "    def forward(self, input, att_scores=None, hx=None):\n",
    "        if not isinstance(input, PackedSequence) or not isinstance(att_scores, PackedSequence):\n",
    "            raise NotImplementedError(\"DynamicGRU only supports packed input and att_scores\")\n",
    "\n",
    "        input, batch_sizes, sorted_indices, unsorted_indices = input\n",
    "        att_scores, _, _, _ = att_scores\n",
    "\n",
    "        max_batch_size = int(batch_sizes[0])\n",
    "        if hx is None:\n",
    "            hx = torch.zeros(max_batch_size, self.hidden_size,\n",
    "                             dtype=input.dtype, device=input.device)\n",
    "\n",
    "        outputs = torch.zeros(input.size(0), self.hidden_size,\n",
    "                              dtype=input.dtype, device=input.device)\n",
    "\n",
    "        begin = 0\n",
    "        for batch in batch_sizes:\n",
    "            new_hx = self.rnn(\n",
    "                input[begin:begin + batch],\n",
    "                hx[0:batch],\n",
    "                att_scores[begin:begin + batch])\n",
    "            outputs[begin:begin + batch] = new_hx\n",
    "            hx = new_hx\n",
    "            begin += batch\n",
    "        return PackedSequence(outputs, batch_sizes, sorted_indices, unsorted_indices)\n",
    "\n",
    "# utils\n",
    "#-------------------------------------------------------------------------------------\n",
    "def concat_fun(inputs, axis=-1):\n",
    "    if len(inputs) == 1:\n",
    "        return inputs[0]\n",
    "    else:\n",
    "        return torch.cat(inputs, dim=axis)\n",
    "\n",
    "\n",
    "def slice_arrays(arrays, start=None, stop=None):\n",
    "    \"\"\"Slice an array or list of arrays.\n",
    "\n",
    "    This takes an array-like, or a list of\n",
    "    array-likes, and outputs:\n",
    "        - arrays[start:stop] if `arrays` is an array-like\n",
    "        - [x[start:stop] for x in arrays] if `arrays` is a list\n",
    "\n",
    "    Can also work on list/array of indices: `slice_arrays(x, indices)`\n",
    "\n",
    "    Arguments:\n",
    "        arrays: Single array or list of arrays.\n",
    "        start: can be an integer index (start index)\n",
    "            or a list/array of indices\n",
    "        stop: integer (stop index); should be None if\n",
    "            `start` was a list.\n",
    "\n",
    "    Returns:\n",
    "        A slice of the array(s).\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the value of start is a list and stop is not None.\n",
    "    \"\"\"\n",
    "\n",
    "    if arrays is None:\n",
    "        return [None]\n",
    "\n",
    "    if isinstance(arrays, np.ndarray):\n",
    "        arrays = [arrays]\n",
    "\n",
    "    if isinstance(start, list) and stop is not None:\n",
    "        raise ValueError('The stop argument has to be None if the value of start '\n",
    "                         'is a list.')\n",
    "    elif isinstance(arrays, list):\n",
    "        if hasattr(start, '__len__'):\n",
    "            # hdf5 datasets only support list objects as indices\n",
    "            if hasattr(start, 'shape'):\n",
    "                start = start.tolist()\n",
    "            return [None if x is None else x[start] for x in arrays]\n",
    "        else:\n",
    "            if len(arrays) == 1:\n",
    "                return arrays[0][start:stop]\n",
    "            return [None if x is None else x[start:stop] for x in arrays]\n",
    "    else:\n",
    "        if hasattr(start, '__len__'):\n",
    "            if hasattr(start, 'shape'):\n",
    "                start = start.tolist()\n",
    "            return arrays[start]\n",
    "        elif hasattr(start, '__getitem__'):\n",
    "            return arrays[start:stop]\n",
    "        else:\n",
    "            return [None]\n",
    "\n",
    "#inputs\n",
    "#-------------------------------------------------------------------------------------\n",
    "DEFAULT_GROUP_NAME = \"default_group\"\n",
    "\n",
    "\n",
    "class SparseFeat(namedtuple('SparseFeat',\n",
    "                            ['name', 'vocabulary_size', 'embedding_dim', 'use_hash', 'dtype', 'embedding_name',\n",
    "                             'group_name'])):\n",
    "    __slots__ = ()\n",
    "\n",
    "    def __new__(cls, name, vocabulary_size, embedding_dim=4, use_hash=False, dtype=\"int32\", embedding_name=None,\n",
    "                group_name=DEFAULT_GROUP_NAME):\n",
    "        if embedding_name is None:\n",
    "            embedding_name = name\n",
    "        if embedding_dim == \"auto\":\n",
    "            embedding_dim = 6 * int(pow(vocabulary_size, 0.25))\n",
    "        if use_hash:\n",
    "            print(\n",
    "                \"Notice! Feature Hashing on the fly currently is not supported in torch version,you can use tensorflow version!\")\n",
    "        return super(SparseFeat, cls).__new__(cls, name, vocabulary_size, embedding_dim, use_hash, dtype,\n",
    "                                              embedding_name, group_name)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self.name.__hash__()\n",
    "\n",
    "\n",
    "class VarLenSparseFeat(namedtuple('VarLenSparseFeat',\n",
    "                                  ['sparsefeat', 'maxlen', 'combiner', 'length_name'])):\n",
    "    __slots__ = ()\n",
    "\n",
    "    def __new__(cls, sparsefeat, maxlen, combiner=\"mean\", length_name=None):\n",
    "        return super(VarLenSparseFeat, cls).__new__(cls, sparsefeat, maxlen, combiner, length_name)\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self.sparsefeat.name\n",
    "\n",
    "    @property\n",
    "    def vocabulary_size(self):\n",
    "        return self.sparsefeat.vocabulary_size\n",
    "\n",
    "    @property\n",
    "    def embedding_dim(self):\n",
    "        return self.sparsefeat.embedding_dim\n",
    "\n",
    "    @property\n",
    "    def dtype(self):\n",
    "        return self.sparsefeat.dtype\n",
    "\n",
    "    @property\n",
    "    def embedding_name(self):\n",
    "        return self.sparsefeat.embedding_name\n",
    "\n",
    "    @property\n",
    "    def group_name(self):\n",
    "        return self.sparsefeat.group_name\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self.name.__hash__()\n",
    "\n",
    "\n",
    "class DenseFeat(namedtuple('DenseFeat', ['name', 'dimension', 'dtype'])):\n",
    "    __slots__ = ()\n",
    "\n",
    "    def __new__(cls, name, dimension=1, dtype=\"float32\"):\n",
    "        return super(DenseFeat, cls).__new__(cls, name, dimension, dtype)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self.name.__hash__()\n",
    "\n",
    "\n",
    "def get_feature_names(feature_columns):\n",
    "    features = build_input_features(feature_columns)\n",
    "    return list(features.keys())\n",
    "\n",
    "\n",
    "# def get_inputs_list(inputs):\n",
    "#     return list(chain(*list(map(lambda x: x.values(), filter(lambda x: x is not None, inputs)))))\n",
    "\n",
    "\n",
    "def build_input_features(feature_columns):\n",
    "    # Return OrderedDict: {feature_name:(start, start+dimension)}\n",
    "\n",
    "    features = OrderedDict()\n",
    "\n",
    "    start = 0\n",
    "    for feat in feature_columns:\n",
    "        feat_name = feat.name\n",
    "        if feat_name in features:\n",
    "            continue\n",
    "        if isinstance(feat, SparseFeat):\n",
    "            features[feat_name] = (start, start + 1)\n",
    "            start += 1\n",
    "        elif isinstance(feat, DenseFeat):\n",
    "            features[feat_name] = (start, start + feat.dimension)\n",
    "            start += feat.dimension\n",
    "        elif isinstance(feat, VarLenSparseFeat):\n",
    "            features[feat_name] = (start, start + feat.maxlen)\n",
    "            start += feat.maxlen\n",
    "            if feat.length_name is not None and feat.length_name not in features:\n",
    "                features[feat.length_name] = (start, start + 1)\n",
    "                start += 1\n",
    "        else:\n",
    "            raise TypeError(\"Invalid feature column type,got\", type(feat))\n",
    "    return features\n",
    "\n",
    "\n",
    "def combined_dnn_input(sparse_embedding_list, dense_value_list):\n",
    "    if len(sparse_embedding_list) > 0 and len(dense_value_list) > 0:\n",
    "        sparse_dnn_input = torch.flatten(\n",
    "            torch.cat(sparse_embedding_list, dim=-1), start_dim=1)\n",
    "        dense_dnn_input = torch.flatten(\n",
    "            torch.cat(dense_value_list, dim=-1), start_dim=1)\n",
    "        return concat_fun([sparse_dnn_input, dense_dnn_input])\n",
    "    elif len(sparse_embedding_list) > 0:\n",
    "        return torch.flatten(torch.cat(sparse_embedding_list, dim=-1), start_dim=1)\n",
    "    elif len(dense_value_list) > 0:\n",
    "        return torch.flatten(torch.cat(dense_value_list, dim=-1), start_dim=1)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "def get_varlen_pooling_list(embedding_dict, features, feature_index, varlen_sparse_feature_columns, device):\n",
    "    varlen_sparse_embedding_list = []\n",
    "\n",
    "    for feat in varlen_sparse_feature_columns:\n",
    "        seq_emb = embedding_dict[feat.embedding_name](\n",
    "            features[:, feature_index[feat.name][0]:feature_index[feat.name][1]].long())\n",
    "        if feat.length_name is None:\n",
    "            seq_mask = features[:, feature_index[feat.name][0]:feature_index[feat.name][1]].long() != 0\n",
    "\n",
    "            emb = SequencePoolingLayer(mode=feat.combiner, supports_masking=True, device=device)(\n",
    "                [seq_emb, seq_mask])\n",
    "        else:\n",
    "            seq_length = features[:,\n",
    "                         feature_index[feat.length_name][0]:feature_index[feat.length_name][1]].long()\n",
    "            emb = SequencePoolingLayer(mode=feat.combiner, supports_masking=False, device=device)(\n",
    "                [seq_emb, seq_length])\n",
    "        varlen_sparse_embedding_list.append(emb)\n",
    "    return varlen_sparse_embedding_list\n",
    "\n",
    "\n",
    "def create_embedding_matrix(feature_columns, init_std=0.0001, linear=False, sparse=False, device='cpu'):\n",
    "    # Return nn.ModuleDict: for sparse features, {embedding_name: nn.Embedding}\n",
    "    # for varlen sparse features, {embedding_name: nn.EmbeddingBag}\n",
    "    sparse_feature_columns = list(\n",
    "        filter(lambda x: isinstance(x, SparseFeat), feature_columns)) if len(feature_columns) else []\n",
    "\n",
    "    varlen_sparse_feature_columns = list(\n",
    "        filter(lambda x: isinstance(x, VarLenSparseFeat), feature_columns)) if len(feature_columns) else []\n",
    "\n",
    "    embedding_dict = nn.ModuleDict(\n",
    "        {feat.embedding_name: nn.Embedding(feat.vocabulary_size, feat.embedding_dim if not linear else 1, sparse=sparse)\n",
    "         for feat in\n",
    "         sparse_feature_columns + varlen_sparse_feature_columns}\n",
    "    )\n",
    "\n",
    "    # for feat in varlen_sparse_feature_columns:\n",
    "    #     embedding_dict[feat.embedding_name] = nn.EmbeddingBag(\n",
    "    #         feat.dimension, embedding_size, sparse=sparse, mode=feat.combiner)\n",
    "\n",
    "    for tensor in embedding_dict.values():\n",
    "        nn.init.normal_(tensor.weight, mean=0, std=init_std)\n",
    "\n",
    "    return embedding_dict.to(device)\n",
    "\n",
    "\n",
    "def input_from_feature_columns(self, X, feature_columns, embedding_dict, support_dense=True):\n",
    "    sparse_feature_columns = list(\n",
    "        filter(lambda x: isinstance(x, SparseFeat), feature_columns)) if len(feature_columns) else []\n",
    "    dense_feature_columns = list(\n",
    "        filter(lambda x: isinstance(x, DenseFeat), feature_columns)) if len(feature_columns) else []\n",
    "\n",
    "    varlen_sparse_feature_columns = list(\n",
    "        filter(lambda x: isinstance(x, VarLenSparseFeat), feature_columns)) if feature_columns else []\n",
    "\n",
    "    if not support_dense and len(dense_feature_columns) > 0:\n",
    "        raise ValueError(\n",
    "            \"DenseFeat is not supported in dnn_feature_columns\")\n",
    "\n",
    "    sparse_embedding_list = [embedding_dict[feat.embedding_name](\n",
    "        X[:, self.feature_index[feat.name][0]:self.feature_index[feat.name][1]].long()) for\n",
    "        feat in sparse_feature_columns]\n",
    "\n",
    "    varlen_sparse_embedding_list = get_varlen_pooling_list(self.embedding_dict, X, self.feature_index,\n",
    "                                                           varlen_sparse_feature_columns, self.device)\n",
    "\n",
    "    dense_value_list = [X[:, self.feature_index[feat.name][0]:self.feature_index[feat.name][1]] for feat in\n",
    "                        dense_feature_columns]\n",
    "\n",
    "    return sparse_embedding_list + varlen_sparse_embedding_list, dense_value_list\n",
    "\n",
    "\n",
    "\n",
    "def embedding_lookup(X, sparse_embedding_dict, sparse_input_dict, sparse_feature_columns, return_feat_list=(),\n",
    "                     mask_feat_list=(), to_list=False):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            X: input Tensor [batch_size x hidden_dim]\n",
    "            sparse_embedding_dict: nn.ModuleDict, {embedding_name: nn.Embedding}\n",
    "            sparse_input_dict: OrderedDict, {feature_name:(start, start+dimension)}\n",
    "            sparse_feature_columns: list, sparse features\n",
    "            return_feat_list: list, names of feature to be returned, defualt () -> return all features\n",
    "            mask_feat_list, list, names of feature to be masked in hash transform\n",
    "        Return:\n",
    "            group_embedding_dict: defaultdict(list)\n",
    "    \"\"\"\n",
    "    group_embedding_dict = defaultdict(list)\n",
    "    for fc in sparse_feature_columns:\n",
    "        feature_name = fc.name\n",
    "        embedding_name = fc.embedding_name\n",
    "        if (len(return_feat_list) == 0 or feature_name in return_feat_list):\n",
    "            # TODO: add hash function\n",
    "            # if fc.use_hash:\n",
    "            #     raise NotImplementedError(\"hash function is not implemented in this version!\")\n",
    "            lookup_idx = np.array(sparse_input_dict[feature_name])\n",
    "            input_tensor = X[:, lookup_idx[0]:lookup_idx[1]].long()\n",
    "            emb = sparse_embedding_dict[embedding_name](input_tensor)\n",
    "            group_embedding_dict[fc.group_name].append(emb)\n",
    "    if to_list:\n",
    "        return list(chain.from_iterable(group_embedding_dict.values()))\n",
    "    return group_embedding_dict\n",
    "\n",
    "\n",
    "def varlen_embedding_lookup(X, embedding_dict, sequence_input_dict, varlen_sparse_feature_columns):\n",
    "    varlen_embedding_vec_dict = {}\n",
    "    for fc in varlen_sparse_feature_columns:\n",
    "        feature_name = fc.name\n",
    "        embedding_name = fc.embedding_name\n",
    "        if fc.use_hash:\n",
    "            # lookup_idx = Hash(fc.vocabulary_size, mask_zero=True)(sequence_input_dict[feature_name])\n",
    "            # TODO: add hash function\n",
    "            lookup_idx = sequence_input_dict[feature_name]\n",
    "        else:\n",
    "            lookup_idx = sequence_input_dict[feature_name]\n",
    "        varlen_embedding_vec_dict[feature_name] = embedding_dict[embedding_name](\n",
    "            X[:, lookup_idx[0]:lookup_idx[1]].long())  # (lookup_idx)\n",
    "\n",
    "    return varlen_embedding_vec_dict\n",
    "\n",
    "\n",
    "def get_dense_input(X, features, feature_columns):\n",
    "    dense_feature_columns = list(filter(lambda x: isinstance(\n",
    "        x, DenseFeat), feature_columns)) if feature_columns else []\n",
    "    dense_input_list = []\n",
    "    for fc in dense_feature_columns:\n",
    "        lookup_idx = np.array(features[fc.name])\n",
    "        input_tensor = X[:, lookup_idx[0]:lookup_idx[1]].float()\n",
    "        dense_input_list.append(input_tensor)\n",
    "    return dense_input_list\n",
    "\n",
    "\n",
    "def maxlen_lookup(X, sparse_input_dict, maxlen_column):\n",
    "    if maxlen_column is None or len(maxlen_column)==0:\n",
    "        raise ValueError('please add max length column for VarLenSparseFeat of DIEN input')\n",
    "    lookup_idx = np.array(sparse_input_dict[maxlen_column[0]])\n",
    "    return X[:, lookup_idx[0]:lookup_idx[1]].long()\n",
    "\n",
    "\n",
    "# basemodel\n",
    "#-------------------------------------------------------------------------------------------------\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, feature_columns, feature_index, init_std=0.0001, device='cpu'):\n",
    "        super(Linear, self).__init__()\n",
    "        self.feature_index = feature_index\n",
    "        self.device = device\n",
    "        self.sparse_feature_columns = list(\n",
    "            filter(lambda x: isinstance(x, SparseFeat), feature_columns)) if len(feature_columns) else []\n",
    "        self.dense_feature_columns = list(\n",
    "            filter(lambda x: isinstance(x, DenseFeat), feature_columns)) if len(feature_columns) else []\n",
    "\n",
    "        self.varlen_sparse_feature_columns = list(\n",
    "            filter(lambda x: isinstance(x, VarLenSparseFeat), feature_columns)) if len(feature_columns) else []\n",
    "\n",
    "        self.embedding_dict = create_embedding_matrix(feature_columns, init_std, linear=True, sparse=False,\n",
    "                                                      device=device)\n",
    "\n",
    "        #         nn.ModuleDict(\n",
    "        #             {feat.embedding_name: nn.Embedding(feat.dimension, 1, sparse=True) for feat in\n",
    "        #              self.sparse_feature_columns}\n",
    "        #         )\n",
    "        # .to(\"cuda:1\")\n",
    "        for tensor in self.embedding_dict.values():\n",
    "            nn.init.normal_(tensor.weight, mean=0, std=init_std)\n",
    "\n",
    "        if len(self.dense_feature_columns) > 0:\n",
    "            self.weight = nn.Parameter(torch.Tensor(sum(fc.dimension for fc in self.dense_feature_columns), 1)).to(\n",
    "                device)\n",
    "            torch.nn.init.normal_(self.weight, mean=0, std=init_std)\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        sparse_embedding_list = [self.embedding_dict[feat.embedding_name](\n",
    "            X[:, self.feature_index[feat.name][0]:self.feature_index[feat.name][1]].long()) for\n",
    "            feat in self.sparse_feature_columns]\n",
    "\n",
    "        dense_value_list = [X[:, self.feature_index[feat.name][0]:self.feature_index[feat.name][1]] for feat in\n",
    "                            self.dense_feature_columns]\n",
    "\n",
    "        varlen_embedding_list = get_varlen_pooling_list(self.embedding_dict, X, self.feature_index,\n",
    "                                                        self.varlen_sparse_feature_columns, self.device)\n",
    "\n",
    "        sparse_embedding_list += varlen_embedding_list\n",
    "\n",
    "        if len(sparse_embedding_list) > 0 and len(dense_value_list) > 0:\n",
    "            linear_sparse_logit = torch.sum(\n",
    "                torch.cat(sparse_embedding_list, dim=-1), dim=-1, keepdim=False)\n",
    "            linear_dense_logit = torch.cat(\n",
    "                dense_value_list, dim=-1).matmul(self.weight)\n",
    "            linear_logit = linear_sparse_logit + linear_dense_logit\n",
    "        elif len(sparse_embedding_list) > 0:\n",
    "            linear_logit = torch.sum(\n",
    "                torch.cat(sparse_embedding_list, dim=-1), dim=-1, keepdim=False)\n",
    "        elif len(dense_value_list) > 0:\n",
    "            linear_logit = torch.cat(\n",
    "                dense_value_list, dim=-1).matmul(self.weight)\n",
    "        else:\n",
    "            linear_logit = torch.zeros([X.shape[0], 1])\n",
    "        return linear_logit\n",
    "\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, linear_feature_columns, dnn_feature_columns, l2_reg_linear=1e-5, l2_reg_embedding=1e-5,\n",
    "                 init_std=0.0001, seed=1024, task='binary', device='cpu'):\n",
    "\n",
    "        super(BaseModel, self).__init__()\n",
    "        torch.manual_seed(seed)\n",
    "        self.dnn_feature_columns = dnn_feature_columns\n",
    "\n",
    "        self.reg_loss = torch.zeros((1,), device=device)\n",
    "        self.aux_loss = torch.zeros((1,), device=device)\n",
    "        self.device = device  # device\n",
    "\n",
    "        self.feature_index = build_input_features(\n",
    "            linear_feature_columns + dnn_feature_columns)\n",
    "        self.dnn_feature_columns = dnn_feature_columns\n",
    "\n",
    "        self.embedding_dict = create_embedding_matrix(dnn_feature_columns, init_std, sparse=False, device=device)\n",
    "        #         nn.ModuleDict(\n",
    "        #             {feat.embedding_name: nn.Embedding(feat.dimension, embedding_size, sparse=True) for feat in\n",
    "        #              self.dnn_feature_columns}\n",
    "        #         )\n",
    "\n",
    "        self.linear_model = Linear(\n",
    "            linear_feature_columns, self.feature_index, device=device)\n",
    "\n",
    "        self.regularization_weight = []\n",
    "\n",
    "        self.add_regularization_weight(\n",
    "            self.embedding_dict.parameters(), l2_reg_embedding)\n",
    "        self.add_regularization_weight(\n",
    "            self.linear_model.parameters(), l2_reg_linear)\n",
    "\n",
    "        self.out = PredictionLayer(task, )\n",
    "        self.to(device)\n",
    "        self._is_graph_network = True  # used for callbacks\n",
    "\n",
    "    def fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, initial_epoch=0, validation_split=0.,\n",
    "            validation_data=None, shuffle=True, callbacks=None):\n",
    "        \"\"\"\n",
    "\n",
    "        :param x: Numpy array of training data (if the model has a single input), or list of Numpy arrays (if the model has multiple inputs).If input layers in the model are named, you can also pass a\n",
    "            dictionary mapping input names to Numpy arrays.\n",
    "        :param y: Numpy array of target (label) data (if the model has a single output), or list of Numpy arrays (if the model has multiple outputs).\n",
    "        :param batch_size: Integer or `None`. Number of samples per gradient update. If unspecified, `batch_size` will default to 256.\n",
    "        :param epochs: Integer. Number of epochs to train the model. An epoch is an iteration over the entire `x` and `y` data provided. Note that in conjunction with `initial_epoch`, `epochs` is to be understood as \"final epoch\". The model is not trained for a number of iterations given by `epochs`, but merely until the epoch of index `epochs` is reached.\n",
    "        :param verbose: Integer. 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
    "        :param initial_epoch: Integer. Epoch at which to start training (useful for resuming a previous training run).\n",
    "        :param validation_split: Float between 0 and 1. Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. The validation data is selected from the last samples in the `x` and `y` data provided, before shuffling.\n",
    "        :param validation_data: tuple `(x_val, y_val)` or tuple `(x_val, y_val, val_sample_weights)` on which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data. `validation_data` will override `validation_split`.\n",
    "        :param shuffle: Boolean. Whether to shuffle the order of the batches at the beginning of each epoch.\n",
    "        :param callbacks: List of `deepctr_torch.callbacks.Callback` instances. List of callbacks to apply during training and validation (if ). See [callbacks](https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks). Now available: `EarlyStopping` , `ModelCheckpoint`\n",
    "\n",
    "        \"\"\"\n",
    "        if isinstance(x, dict):\n",
    "            x = [x[feature] for feature in self.feature_index]\n",
    "\n",
    "        do_validation = False\n",
    "        if validation_data:\n",
    "            do_validation = True\n",
    "            if len(validation_data) == 2:\n",
    "                val_x, val_y = validation_data\n",
    "                val_sample_weight = None\n",
    "            elif len(validation_data) == 3:\n",
    "                val_x, val_y, val_sample_weight = validation_data  # pylint: disable=unpacking-non-sequence\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    'When passing a `validation_data` argument, '\n",
    "                    'it must contain either 2 items (x_val, y_val), '\n",
    "                    'or 3 items (x_val, y_val, val_sample_weights), '\n",
    "                    'or alternatively it could be a dataset or a '\n",
    "                    'dataset or a dataset iterator. '\n",
    "                    'However we received `validation_data=%s`' % validation_data)\n",
    "            if isinstance(val_x, dict):\n",
    "                val_x = [val_x[feature] for feature in self.feature_index]\n",
    "\n",
    "        elif validation_split and 0. < validation_split < 1.:\n",
    "            do_validation = True\n",
    "            if hasattr(x[0], 'shape'):\n",
    "                split_at = int(x[0].shape[0] * (1. - validation_split))\n",
    "            else:\n",
    "                split_at = int(len(x[0]) * (1. - validation_split))\n",
    "            x, val_x = (slice_arrays(x, 0, split_at),\n",
    "                        slice_arrays(x, split_at))\n",
    "            y, val_y = (slice_arrays(y, 0, split_at),\n",
    "                        slice_arrays(y, split_at))\n",
    "\n",
    "        else:\n",
    "            val_x = []\n",
    "            val_y = []\n",
    "        for i in range(len(x)):\n",
    "            if len(x[i].shape) == 1:\n",
    "                x[i] = np.expand_dims(x[i], axis=1)\n",
    "\n",
    "        train_tensor_data = Data.TensorDataset(\n",
    "            torch.from_numpy(\n",
    "                np.concatenate(x, axis=-1)),\n",
    "            torch.from_numpy(y))\n",
    "        if batch_size is None:\n",
    "            batch_size = 256\n",
    "        train_loader = DataLoader(\n",
    "            dataset=train_tensor_data, shuffle=shuffle, batch_size=batch_size)\n",
    "\n",
    "        print(self.device, end=\"\\n\")\n",
    "        model = self.train()\n",
    "        loss_func = self.loss_func\n",
    "        optim = self.optim\n",
    "        \n",
    "        # ------------------------------------------------------------\n",
    "        reduceLR      = lr_scheduler.ReduceLROnPlateau(optim, mode='min', factor=0.01, patience=8, eps=1e-4, verbose=True)\n",
    "        \n",
    "        sample_num = len(train_tensor_data)\n",
    "        steps_per_epoch = (sample_num - 1) // batch_size + 1\n",
    "\n",
    "        callbacks = CallbackList(callbacks)\n",
    "        callbacks.set_model(self)\n",
    "        callbacks.on_train_begin()\n",
    "        self.stop_training = False  # used for early stopping\n",
    "\n",
    "        # Train\n",
    "        print(\"Train on {0} samples, validate on {1} samples, {2} steps per epoch\".format(\n",
    "            len(train_tensor_data), len(val_y), steps_per_epoch))\n",
    "        for epoch in range(initial_epoch, epochs):\n",
    "            callbacks.on_epoch_begin(epoch)\n",
    "            epoch_logs = {}\n",
    "            start_time = time.time()\n",
    "            loss_epoch = 0\n",
    "            total_loss_epoch = 0\n",
    "            train_result = {}\n",
    "            try:\n",
    "                with tqdm(enumerate(train_loader), disable=verbose != 1) as t:\n",
    "                    for index, (x_train, y_train) in t:\n",
    "                        x = x_train.to(self.device).float()\n",
    "                        y = y_train.to(self.device).float()\n",
    "\n",
    "                        y_pred = model(x).squeeze()\n",
    "\n",
    "                        optim.zero_grad()\n",
    "                        loss = loss_func(y_pred, y.squeeze(), reduction='sum')\n",
    "                        reg_loss = self.get_regularization_loss()\n",
    "\n",
    "                        total_loss = loss + reg_loss + self.aux_loss\n",
    "\n",
    "                        loss_epoch += loss.item()\n",
    "                        total_loss_epoch += total_loss.item()\n",
    "                        total_loss.backward(retain_graph=True)\n",
    "                        optim.step()\n",
    "\n",
    "                        if verbose > 0:\n",
    "                            for name, metric_fun in self.metrics.items():\n",
    "                                if name not in train_result:\n",
    "                                    train_result[name] = []\n",
    "                                train_result[name].append(metric_fun(\n",
    "                                    y.cpu().data.numpy(), y_pred.cpu().data.numpy().astype(\"float64\")))\n",
    "\n",
    "             \n",
    "            except KeyboardInterrupt:\n",
    "                t.close()\n",
    "                raise\n",
    "            t.close()\n",
    "           \n",
    "            \n",
    "            # Add epoch_logs\n",
    "            epoch_logs[\"loss\"] = total_loss_epoch / sample_num\n",
    "            \n",
    "           \n",
    "               \n",
    "                \n",
    "            for name, result in train_result.items():\n",
    "                epoch_logs[name] = np.sum(result) / steps_per_epoch\n",
    "\n",
    "            if do_validation:\n",
    "                eval_result = self.evaluate(val_x, val_y, batch_size)\n",
    "                for name, result in eval_result.items():\n",
    "                    epoch_logs[\"val_\" + name] = result\n",
    "            # verbose\n",
    "            if verbose > 0:\n",
    "                epoch_time = int(time.time() - start_time)\n",
    "                print('Epoch {0}/{1}'.format(epoch + 1, epochs))\n",
    "\n",
    "                eval_str = \"{0}s - loss: {1: .4f}\".format(\n",
    "                    epoch_time, epoch_logs[\"loss\"])\n",
    "\n",
    "                for name in self.metrics:\n",
    "                    eval_str += \" - \" + name + \\\n",
    "                                \": {0: .4f}\".format(epoch_logs[name])\n",
    "\n",
    "                if do_validation:\n",
    "                    i_tag = 0\n",
    "                    for name in self.metrics:\n",
    "                        eval_str += \" - \" + \"val_\" + name + \\\n",
    "                                    \": {0: .4f}\".format(epoch_logs[\"val_\" + name])\n",
    "                        \n",
    "                        # -----------------------------------------------------------\n",
    "                        if i_tag == 0:\n",
    "                            reduceLR.step(epoch_logs[\"val_\" + name])\n",
    "                            i_tag = 1\n",
    "                    \n",
    "                print(eval_str)\n",
    "            callbacks.on_epoch_end(epoch, epoch_logs)\n",
    "            if self.stop_training:\n",
    "                break\n",
    "\n",
    "        callbacks.on_train_end()\n",
    "\n",
    "    def evaluate(self, x, y, batch_size=256):\n",
    "        \"\"\"\n",
    "\n",
    "        :param x: Numpy array of test data (if the model has a single input), or list of Numpy arrays (if the model has multiple inputs).\n",
    "        :param y: Numpy array of target (label) data (if the model has a single output), or list of Numpy arrays (if the model has multiple outputs).\n",
    "        :param batch_size: Integer or `None`. Number of samples per evaluation step. If unspecified, `batch_size` will default to 256.\n",
    "        :return: Dict contains metric names and metric values.\n",
    "        \"\"\"\n",
    "        pred_ans = self.predict(x, batch_size)\n",
    "        eval_result = {}\n",
    "        for name, metric_fun in self.metrics.items():\n",
    "            eval_result[name] = metric_fun(y, pred_ans)\n",
    "        return eval_result\n",
    "\n",
    "    def predict(self, x, batch_size=256):\n",
    "        \"\"\"\n",
    "\n",
    "        :param x: The input data, as a Numpy array (or list of Numpy arrays if the model has multiple inputs).\n",
    "        :param batch_size: Integer. If unspecified, it will default to 256.\n",
    "        :return: Numpy array(s) of predictions.\n",
    "        \"\"\"\n",
    "        model = self.eval()\n",
    "        if isinstance(x, dict):\n",
    "            x = [x[feature] for feature in self.feature_index]\n",
    "        for i in range(len(x)):\n",
    "            if len(x[i].shape) == 1:\n",
    "                x[i] = np.expand_dims(x[i], axis=1)\n",
    "\n",
    "        tensor_data = Data.TensorDataset(\n",
    "            torch.from_numpy(np.concatenate(x, axis=-1)))\n",
    "        test_loader = DataLoader(\n",
    "            dataset=tensor_data, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "        pred_ans = []\n",
    "        with torch.no_grad():\n",
    "            for index, x_test in enumerate(test_loader):\n",
    "                x = x_test[0].to(self.device).float()\n",
    "\n",
    "                y_pred = model(x).cpu().data.numpy()  # .squeeze()\n",
    "                pred_ans.append(y_pred)\n",
    "\n",
    "        return np.concatenate(pred_ans).astype(\"float64\")\n",
    "\n",
    "    def input_from_feature_columns(self, X, feature_columns, embedding_dict, support_dense=True):\n",
    "\n",
    "        sparse_feature_columns = list(\n",
    "            filter(lambda x: isinstance(x, SparseFeat), feature_columns)) if len(feature_columns) else []\n",
    "        dense_feature_columns = list(\n",
    "            filter(lambda x: isinstance(x, DenseFeat), feature_columns)) if len(feature_columns) else []\n",
    "\n",
    "        varlen_sparse_feature_columns = list(\n",
    "            filter(lambda x: isinstance(x, VarLenSparseFeat), feature_columns)) if feature_columns else []\n",
    "\n",
    "        if not support_dense and len(dense_feature_columns) > 0:\n",
    "            raise ValueError(\n",
    "                \"DenseFeat is not supported in dnn_feature_columns\")\n",
    "\n",
    "        sparse_embedding_list = [embedding_dict[feat.embedding_name](\n",
    "            X[:, self.feature_index[feat.name][0]:self.feature_index[feat.name][1]].long()) for\n",
    "            feat in sparse_feature_columns]\n",
    "\n",
    "        varlen_sparse_embedding_list = get_varlen_pooling_list(self.embedding_dict, X, self.feature_index,\n",
    "                                                               varlen_sparse_feature_columns, self.device)\n",
    "\n",
    "        dense_value_list = [X[:, self.feature_index[feat.name][0]:self.feature_index[feat.name][1]] for feat in\n",
    "                            dense_feature_columns]\n",
    "\n",
    "        return sparse_embedding_list + varlen_sparse_embedding_list, dense_value_list\n",
    "\n",
    "    def compute_input_dim(self, feature_columns, include_sparse=True, include_dense=True, feature_group=False):\n",
    "        sparse_feature_columns = list(\n",
    "            filter(lambda x: isinstance(x, (SparseFeat, VarLenSparseFeat)), feature_columns)) if len(\n",
    "            feature_columns) else []\n",
    "        dense_feature_columns = list(\n",
    "            filter(lambda x: isinstance(x, DenseFeat), feature_columns)) if len(feature_columns) else []\n",
    "\n",
    "        dense_input_dim = sum(\n",
    "            map(lambda x: x.dimension, dense_feature_columns))\n",
    "        if feature_group:\n",
    "            sparse_input_dim = len(sparse_feature_columns)\n",
    "        else:\n",
    "            sparse_input_dim = sum(feat.embedding_dim for feat in sparse_feature_columns)\n",
    "        input_dim = 0\n",
    "        if include_sparse:\n",
    "            input_dim += sparse_input_dim\n",
    "        if include_dense:\n",
    "            input_dim += dense_input_dim\n",
    "        return input_dim\n",
    "\n",
    "    def add_regularization_weight(self, weight_list, weight_decay, p=2):\n",
    "        self.regularization_weight.append((list(weight_list), weight_decay, p))\n",
    "\n",
    "    def get_regularization_loss(self, ):\n",
    "        total_reg_loss = torch.zeros((1,), device=self.device)\n",
    "        for weight_list, weight_decay, p in self.regularization_weight:\n",
    "            weight_reg_loss = torch.zeros((1,), device=self.device)\n",
    "            for w in weight_list:\n",
    "                if isinstance(w, tuple):\n",
    "                    l2_reg = torch.norm(w[1], p=p, )\n",
    "                else:\n",
    "                    l2_reg = torch.norm(w, p=p, )\n",
    "                weight_reg_loss = weight_reg_loss + l2_reg\n",
    "            reg_loss = weight_decay * weight_reg_loss\n",
    "            total_reg_loss += reg_loss\n",
    "        return total_reg_loss\n",
    "\n",
    "    def add_auxiliary_loss(self, aux_loss, alpha):\n",
    "        self.aux_loss = aux_loss * alpha\n",
    "\n",
    "    def compile(self, optimizer,\n",
    "                loss=None,\n",
    "                metrics=None,\n",
    "                ):\n",
    "        \"\"\"\n",
    "        :param optimizer: String (name of optimizer) or optimizer instance. See [optimizers](https://pytorch.org/docs/stable/optim.html).\n",
    "        :param loss: String (name of objective function) or objective function. See [losses](https://pytorch.org/docs/stable/nn.functional.html#loss-functions).\n",
    "        :param metrics: List of metrics to be evaluated by the model during training and testing. Typically you will use `metrics=['accuracy']`.\n",
    "        \"\"\"\n",
    "        self.metrics_names = [\"loss\"]\n",
    "        self.optim = self._get_optim(optimizer)\n",
    "        self.loss_func = self._get_loss_func(loss)\n",
    "        self.metrics = self._get_metrics(metrics)\n",
    "\n",
    "    def _get_optim(self, optimizer):\n",
    "        if isinstance(optimizer, str):\n",
    "            if optimizer == \"sgd\":\n",
    "                optim = torch.optim.SGD(self.parameters(), lr=0.01)\n",
    "            elif optimizer == \"adam\":\n",
    "                optim = torch.optim.Adam(self.parameters())  # 0.001\n",
    "            elif optimizer == \"adagrad\":\n",
    "                optim = torch.optim.Adagrad(self.parameters())  # 0.01\n",
    "            elif optimizer == \"rmsprop\":\n",
    "                optim = torch.optim.RMSprop(self.parameters())\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "        else:\n",
    "            optim = optimizer\n",
    "        return optim\n",
    "\n",
    "    def _get_loss_func(self, loss):\n",
    "        if isinstance(loss, str):\n",
    "            if loss == \"binary_crossentropy\":\n",
    "                loss_func = F.binary_cross_entropy\n",
    "            elif loss == \"mse\":\n",
    "                loss_func = F.mse_loss\n",
    "            elif loss == \"mae\":\n",
    "                loss_func = F.l1_loss\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "        else:\n",
    "            loss_func = loss\n",
    "        return loss_func\n",
    "\n",
    "    def _log_loss(self, y_true, y_pred, eps=1e-7, normalize=True, sample_weight=None, labels=None):\n",
    "        # change eps to improve calculation accuracy\n",
    "        return log_loss(y_true,\n",
    "                        y_pred,\n",
    "                        eps,\n",
    "                        normalize,\n",
    "                        sample_weight,\n",
    "                        labels)\n",
    "\n",
    "    def _get_metrics(self, metrics, set_eps=False):\n",
    "        metrics_ = {}\n",
    "        if metrics:\n",
    "            for metric in metrics:\n",
    "                if metric == \"binary_crossentropy\" or metric == \"logloss\":\n",
    "                    if set_eps:\n",
    "                        metrics_[metric] = self._log_loss\n",
    "                    else:\n",
    "                        metrics_[metric] = log_loss\n",
    "                if metric == \"auc\":\n",
    "                    metrics_[metric] = roc_auc_score\n",
    "                if metric == \"mse\":\n",
    "                    metrics_[metric] = mean_squared_error\n",
    "                if metric == \"accuracy\" or metric == \"acc\":\n",
    "                    metrics_[metric] = lambda y_true, y_pred: accuracy_score(\n",
    "                        y_true, np.where(y_pred > 0.5, 1, 0))\n",
    "                self.metrics_names.append(metric)\n",
    "        return metrics_\n",
    "\n",
    "    @property\n",
    "    def embedding_size(self, ):\n",
    "        feature_columns = self.dnn_feature_columns\n",
    "        sparse_feature_columns = list(\n",
    "            filter(lambda x: isinstance(x, (SparseFeat, VarLenSparseFeat)), feature_columns)) if len(\n",
    "            feature_columns) else []\n",
    "        embedding_size_set = set([feat.embedding_dim for feat in sparse_feature_columns])\n",
    "        if len(embedding_size_set) > 1:\n",
    "            raise ValueError(\"embedding_dim of SparseFeat and VarlenSparseFeat must be same in this model!\")\n",
    "        return list(embedding_size_set)[0]\n",
    "\n",
    "# interaction\n",
    "#-----------------------------------------------------------------------------------------------------------------\n",
    "class FM(nn.Module):\n",
    "    \"\"\"Factorization Machine models pairwise (order-2) feature interactions\n",
    "     without linear term and bias.\n",
    "      Input shape\n",
    "        - 3D tensor with shape: ``(batch_size,field_size,embedding_size)``.\n",
    "      Output shape\n",
    "        - 2D tensor with shape: ``(batch_size, 1)``.\n",
    "      References\n",
    "        - [Factorization Machines](https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FM, self).__init__()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        fm_input = inputs\n",
    "\n",
    "        square_of_sum = torch.pow(torch.sum(fm_input, dim=1, keepdim=True), 2)\n",
    "        sum_of_square = torch.sum(fm_input * fm_input, dim=1, keepdim=True)\n",
    "        cross_term = square_of_sum - sum_of_square\n",
    "        cross_term = 0.5 * torch.sum(cross_term, dim=2, keepdim=False)\n",
    "\n",
    "        return cross_term\n",
    "\n",
    "\n",
    "class BiInteractionPooling(nn.Module):\n",
    "    \"\"\"Bi-Interaction Layer used in Neural FM,compress the\n",
    "     pairwise element-wise product of features into one single vector.\n",
    "\n",
    "      Input shape\n",
    "        - A 3D tensor with shape:``(batch_size,field_size,embedding_size)``.\n",
    "\n",
    "      Output shape\n",
    "        - 3D tensor with shape: ``(batch_size,1,embedding_size)``.\n",
    "\n",
    "      References\n",
    "        - [He X, Chua T S. Neural factorization machines for sparse predictive analytics[C]//Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval. ACM, 2017: 355-364.](http://arxiv.org/abs/1708.05027)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BiInteractionPooling, self).__init__()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        concated_embeds_value = inputs\n",
    "        square_of_sum = torch.pow(\n",
    "            torch.sum(concated_embeds_value, dim=1, keepdim=True), 2)\n",
    "        sum_of_square = torch.sum(\n",
    "            concated_embeds_value * concated_embeds_value, dim=1, keepdim=True)\n",
    "        cross_term = 0.5 * (square_of_sum - sum_of_square)\n",
    "        return cross_term\n",
    "\n",
    "\n",
    "class SENETLayer(nn.Module):\n",
    "    \"\"\"SENETLayer used in FiBiNET.\n",
    "      Input shape\n",
    "        - A list of 3D tensor with shape: ``(batch_size,filed_size,embedding_size)``.\n",
    "      Output shape\n",
    "        - A list of 3D tensor with shape: ``(batch_size,filed_size,embedding_size)``.\n",
    "      Arguments\n",
    "        - **filed_size** : Positive integer, number of feature groups.\n",
    "        - **reduction_ratio** : Positive integer, dimensionality of the\n",
    "         attention network output space.\n",
    "        - **seed** : A Python integer to use as random seed.\n",
    "      References\n",
    "        - [FiBiNET: Combining Feature Importance and Bilinear feature Interaction for Click-Through Rate Prediction\n",
    "Tongwen](https://arxiv.org/pdf/1905.09433.pdf)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filed_size, reduction_ratio=3, seed=1024, device='cpu'):\n",
    "        super(SENETLayer, self).__init__()\n",
    "        self.seed = seed\n",
    "        self.filed_size = filed_size\n",
    "        self.reduction_size = max(1, filed_size // reduction_ratio)\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Linear(self.filed_size, self.reduction_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.reduction_size, self.filed_size, bias=False),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if len(inputs.shape) != 3:\n",
    "            raise ValueError(\n",
    "                \"Unexpected inputs dimensions %d, expect to be 3 dimensions\" % (len(inputs.shape)))\n",
    "        Z = torch.mean(inputs, dim=-1, out=None)\n",
    "        A = self.excitation(Z)\n",
    "        V = torch.mul(inputs, torch.unsqueeze(A, dim=2))\n",
    "\n",
    "        return V\n",
    "\n",
    "\n",
    "class BilinearInteraction(nn.Module):\n",
    "    \"\"\"BilinearInteraction Layer used in FiBiNET.\n",
    "      Input shape\n",
    "        - A list of 3D tensor with shape: ``(batch_size,filed_size, embedding_size)``.\n",
    "      Output shape\n",
    "        - 3D tensor with shape: ``(batch_size,filed_size, embedding_size)``.\n",
    "      Arguments\n",
    "        - **filed_size** : Positive integer, number of feature groups.\n",
    "        - **str** : String, types of bilinear functions used in this layer.\n",
    "        - **seed** : A Python integer to use as random seed.\n",
    "      References\n",
    "        - [FiBiNET: Combining Feature Importance and Bilinear feature Interaction for Click-Through Rate Prediction\n",
    "Tongwen](https://arxiv.org/pdf/1905.09433.pdf)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filed_size, embedding_size, bilinear_type=\"interaction\", seed=1024, device='cpu'):\n",
    "        super(BilinearInteraction, self).__init__()\n",
    "        self.bilinear_type = bilinear_type\n",
    "        self.seed = seed\n",
    "        self.bilinear = nn.ModuleList()\n",
    "        if self.bilinear_type == \"all\":\n",
    "            self.bilinear = nn.Linear(\n",
    "                embedding_size, embedding_size, bias=False)\n",
    "        elif self.bilinear_type == \"each\":\n",
    "            for i in range(filed_size):\n",
    "                self.bilinear.append(\n",
    "                    nn.Linear(embedding_size, embedding_size, bias=False))\n",
    "        elif self.bilinear_type == \"interaction\":\n",
    "            for i, j in itertools.combinations(range(filed_size), 2):\n",
    "                self.bilinear.append(\n",
    "                    nn.Linear(embedding_size, embedding_size, bias=False))\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if len(inputs.shape) != 3:\n",
    "            raise ValueError(\n",
    "                \"Unexpected inputs dimensions %d, expect to be 3 dimensions\" % (len(inputs.shape)))\n",
    "        inputs = torch.split(inputs, 1, dim=1)\n",
    "        if self.bilinear_type == \"all\":\n",
    "            p = [torch.mul(self.bilinear(v_i), v_j)\n",
    "                 for v_i, v_j in itertools.combinations(inputs, 2)]\n",
    "        elif self.bilinear_type == \"each\":\n",
    "            p = [torch.mul(self.bilinear[i](inputs[i]), inputs[j])\n",
    "                 for i, j in itertools.combinations(range(len(inputs)), 2)]\n",
    "        elif self.bilinear_type == \"interaction\":\n",
    "            p = [torch.mul(bilinear(v[0]), v[1])\n",
    "                 for v, bilinear in zip(itertools.combinations(inputs, 2), self.bilinear)]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        return torch.cat(p, dim=1)\n",
    "\n",
    "\n",
    "class CIN(nn.Module):\n",
    "    \"\"\"Compressed Interaction Network used in xDeepFM.\n",
    "      Input shape\n",
    "        - 3D tensor with shape: ``(batch_size,field_size,embedding_size)``.\n",
    "      Output shape\n",
    "        - 2D tensor with shape: ``(batch_size, featuremap_num)`` ``featuremap_num =  sum(self.layer_size[:-1]) // 2 + self.layer_size[-1]`` if ``split_half=True``,else  ``sum(layer_size)`` .\n",
    "      Arguments\n",
    "        - **filed_size** : Positive integer, number of feature groups.\n",
    "        - **layer_size** : list of int.Feature maps in each layer.\n",
    "        - **activation** : activation function name used on feature maps.\n",
    "        - **split_half** : bool.if set to False, half of the feature maps in each hidden will connect to output unit.\n",
    "        - **seed** : A Python integer to use as random seed.\n",
    "      References\n",
    "        - [Lian J, Zhou X, Zhang F, et al. xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems[J]. arXiv preprint arXiv:1803.05170, 2018.] (https://arxiv.org/pdf/1803.05170.pdf)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, field_size, layer_size=(128, 128), activation='relu', split_half=True, l2_reg=1e-5, seed=1024,\n",
    "                 device='cpu'):\n",
    "        super(CIN, self).__init__()\n",
    "        if len(layer_size) == 0:\n",
    "            raise ValueError(\n",
    "                \"layer_size must be a list(tuple) of length greater than 1\")\n",
    "\n",
    "        self.layer_size = layer_size\n",
    "        self.field_nums = [field_size]\n",
    "        self.split_half = split_half\n",
    "        self.activation = activation_layer(activation)\n",
    "        self.l2_reg = l2_reg\n",
    "        self.seed = seed\n",
    "\n",
    "        self.conv1ds = nn.ModuleList()\n",
    "        for i, size in enumerate(self.layer_size):\n",
    "            self.conv1ds.append(\n",
    "                nn.Conv1d(self.field_nums[-1] * self.field_nums[0], size, 1))\n",
    "\n",
    "            if self.split_half:\n",
    "                if i != len(self.layer_size) - 1 and size % 2 > 0:\n",
    "                    raise ValueError(\n",
    "                        \"layer_size must be even number except for the last layer when split_half=True\")\n",
    "\n",
    "                self.field_nums.append(size // 2)\n",
    "            else:\n",
    "                self.field_nums.append(size)\n",
    "\n",
    "        #         for tensor in self.conv1ds:\n",
    "        #             nn.init.normal_(tensor.weight, mean=0, std=init_std)\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if len(inputs.shape) != 3:\n",
    "            raise ValueError(\n",
    "                \"Unexpected inputs dimensions %d, expect to be 3 dimensions\" % (len(inputs.shape)))\n",
    "        batch_size = inputs.shape[0]\n",
    "        dim = inputs.shape[-1]\n",
    "        hidden_nn_layers = [inputs]\n",
    "        final_result = []\n",
    "\n",
    "        for i, size in enumerate(self.layer_size):\n",
    "            # x^(k-1) * x^0\n",
    "            x = torch.einsum(\n",
    "                'bhd,bmd->bhmd', hidden_nn_layers[-1], hidden_nn_layers[0])\n",
    "            # x.shape = (batch_size , hi * m, dim)\n",
    "            x = x.reshape(\n",
    "                batch_size, hidden_nn_layers[-1].shape[1] * hidden_nn_layers[0].shape[1], dim)\n",
    "            # x.shape = (batch_size , hi, dim)\n",
    "            x = self.conv1ds[i](x)\n",
    "\n",
    "            if self.activation is None or self.activation == 'linear':\n",
    "                curr_out = x\n",
    "            else:\n",
    "                curr_out = self.activation(x)\n",
    "\n",
    "            if self.split_half:\n",
    "                if i != len(self.layer_size) - 1:\n",
    "                    next_hidden, direct_connect = torch.split(\n",
    "                        curr_out, 2 * [size // 2], 1)\n",
    "                else:\n",
    "                    direct_connect = curr_out\n",
    "                    next_hidden = 0\n",
    "            else:\n",
    "                direct_connect = curr_out\n",
    "                next_hidden = curr_out\n",
    "\n",
    "            final_result.append(direct_connect)\n",
    "            hidden_nn_layers.append(next_hidden)\n",
    "\n",
    "        result = torch.cat(final_result, dim=1)\n",
    "        result = torch.sum(result, -1)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "class AFMLayer(nn.Module):\n",
    "    \"\"\"Attentonal Factorization Machine models pairwise (order-2) feature\n",
    "    interactions without linear term and bias.\n",
    "      Input shape\n",
    "        - A list of 3D tensor with shape: ``(batch_size,1,embedding_size)``.\n",
    "      Output shape\n",
    "        - 2D tensor with shape: ``(batch_size, 1)``.\n",
    "      Arguments\n",
    "        - **in_features** : Positive integer, dimensionality of input features.\n",
    "        - **attention_factor** : Positive integer, dimensionality of the\n",
    "         attention network output space.\n",
    "        - **l2_reg_w** : float between 0 and 1. L2 regularizer strength\n",
    "         applied to attention network.\n",
    "        - **dropout_rate** : float between in [0,1). Fraction of the attention net output units to dropout.\n",
    "        - **seed** : A Python integer to use as random seed.\n",
    "      References\n",
    "        - [Attentional Factorization Machines : Learning the Weight of Feature\n",
    "        Interactions via Attention Networks](https://arxiv.org/pdf/1708.04617.pdf)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, attention_factor=4, l2_reg_w=0, dropout_rate=0, seed=1024, device='cpu'):\n",
    "        super(AFMLayer, self).__init__()\n",
    "        self.attention_factor = attention_factor\n",
    "        self.l2_reg_w = l2_reg_w\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.seed = seed\n",
    "        embedding_size = in_features\n",
    "\n",
    "        self.attention_W = nn.Parameter(torch.Tensor(\n",
    "            embedding_size, self.attention_factor))\n",
    "\n",
    "        self.attention_b = nn.Parameter(torch.Tensor(self.attention_factor))\n",
    "\n",
    "        self.projection_h = nn.Parameter(\n",
    "            torch.Tensor(self.attention_factor, 1))\n",
    "\n",
    "        self.projection_p = nn.Parameter(torch.Tensor(embedding_size, 1))\n",
    "\n",
    "        for tensor in [self.attention_W, self.projection_h, self.projection_p]:\n",
    "            nn.init.xavier_normal_(tensor, )\n",
    "\n",
    "        for tensor in [self.attention_b]:\n",
    "            nn.init.zeros_(tensor, )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds_vec_list = inputs\n",
    "        row = []\n",
    "        col = []\n",
    "\n",
    "        for r, c in itertools.combinations(embeds_vec_list, 2):\n",
    "            row.append(r)\n",
    "            col.append(c)\n",
    "\n",
    "        p = torch.cat(row, dim=1)\n",
    "        q = torch.cat(col, dim=1)\n",
    "        inner_product = p * q\n",
    "\n",
    "        bi_interaction = inner_product\n",
    "        attention_temp = F.relu(torch.tensordot(\n",
    "            bi_interaction, self.attention_W, dims=([-1], [0])) + self.attention_b)\n",
    "\n",
    "        self.normalized_att_score = F.softmax(torch.tensordot(\n",
    "            attention_temp, self.projection_h, dims=([-1], [0])), dim=1)\n",
    "        attention_output = torch.sum(\n",
    "            self.normalized_att_score * bi_interaction, dim=1)\n",
    "\n",
    "        attention_output = self.dropout(attention_output)  # training\n",
    "\n",
    "        afm_out = torch.tensordot(\n",
    "            attention_output, self.projection_p, dims=([-1], [0]))\n",
    "        return afm_out\n",
    "\n",
    "\n",
    "class InteractingLayer(nn.Module):\n",
    "    \"\"\"A Layer used in AutoInt that model the correlations between different feature fields by multi-head self-attention mechanism.\n",
    "      Input shape\n",
    "            - A 3D tensor with shape: ``(batch_size,field_size,embedding_size)``.\n",
    "      Output shape\n",
    "            - 3D tensor with shape:``(batch_size,field_size,att_embedding_size * head_num)``.\n",
    "      Arguments\n",
    "            - **in_features** : Positive integer, dimensionality of input features.\n",
    "            - **att_embedding_size**: int.The embedding size in multi-head self-attention network.\n",
    "            - **head_num**: int.The head number in multi-head  self-attention network.\n",
    "            - **use_res**: bool.Whether or not use standard residual connections before output.\n",
    "            - **seed**: A Python integer to use as random seed.\n",
    "      References\n",
    "            - [Song W, Shi C, Xiao Z, et al. AutoInt: Automatic Feature Interaction Learning via Self-Attentive Neural Networks[J]. arXiv preprint arXiv:1810.11921, 2018.](https://arxiv.org/abs/1810.11921)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, att_embedding_size=8, head_num=2, use_res=True, seed=1024, device='cpu'):\n",
    "        super(InteractingLayer, self).__init__()\n",
    "        if head_num <= 0:\n",
    "            raise ValueError('head_num must be a int > 0')\n",
    "        self.att_embedding_size = att_embedding_size\n",
    "        self.head_num = head_num\n",
    "        self.use_res = use_res\n",
    "        self.seed = seed\n",
    "\n",
    "        embedding_size = in_features\n",
    "\n",
    "        self.W_Query = nn.Parameter(torch.Tensor(\n",
    "            embedding_size, self.att_embedding_size * self.head_num))\n",
    "\n",
    "        self.W_key = nn.Parameter(torch.Tensor(\n",
    "            embedding_size, self.att_embedding_size * self.head_num))\n",
    "\n",
    "        self.W_Value = nn.Parameter(torch.Tensor(\n",
    "            embedding_size, self.att_embedding_size * self.head_num))\n",
    "\n",
    "        if self.use_res:\n",
    "            self.W_Res = nn.Parameter(torch.Tensor(\n",
    "                embedding_size, self.att_embedding_size * self.head_num))\n",
    "        for tensor in self.parameters():\n",
    "            nn.init.normal_(tensor, mean=0.0, std=0.05)\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        if len(inputs.shape) != 3:\n",
    "            raise ValueError(\n",
    "                \"Unexpected inputs dimensions %d, expect to be 3 dimensions\" % (len(inputs.shape)))\n",
    "\n",
    "        querys = torch.tensordot(inputs, self.W_Query,\n",
    "                                 dims=([-1], [0]))  # None F D*head_num\n",
    "        keys = torch.tensordot(inputs, self.W_key, dims=([-1], [0]))\n",
    "        values = torch.tensordot(inputs, self.W_Value, dims=([-1], [0]))\n",
    "\n",
    "        # head_num None F D\n",
    "\n",
    "        querys = torch.stack(torch.split(\n",
    "            querys, self.att_embedding_size, dim=2))\n",
    "        keys = torch.stack(torch.split(keys, self.att_embedding_size, dim=2))\n",
    "        values = torch.stack(torch.split(\n",
    "            values, self.att_embedding_size, dim=2))\n",
    "        inner_product = torch.einsum(\n",
    "            'bnik,bnjk->bnij', querys, keys)  # head_num None F F\n",
    "\n",
    "        self.normalized_att_scores = F.softmax(\n",
    "            inner_product, dim=-1)  # head_num None F F\n",
    "        result = torch.matmul(self.normalized_att_scores,\n",
    "                              values)  # head_num None F D\n",
    "\n",
    "        result = torch.cat(torch.split(result, 1, ), dim=-1)\n",
    "        result = torch.squeeze(result, dim=0)  # None F D*head_num\n",
    "        if self.use_res:\n",
    "            result += torch.tensordot(inputs, self.W_Res, dims=([-1], [0]))\n",
    "        result = F.relu(result)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "class CrossNet(nn.Module):\n",
    "    \"\"\"The Cross Network part of Deep&Cross Network model,\n",
    "    which leans both low and high degree cross feature.\n",
    "      Input shape\n",
    "        - 2D tensor with shape: ``(batch_size, units)``.\n",
    "      Output shape\n",
    "        - 2D tensor with shape: ``(batch_size, units)``.\n",
    "      Arguments\n",
    "        - **in_features** : Positive integer, dimensionality of input features.\n",
    "        - **input_feature_num**: Positive integer, shape(Input tensor)[-1]\n",
    "        - **layer_num**: Positive integer, the cross layer number\n",
    "        - **parameterization**: string, ``\"vector\"``  or ``\"matrix\"`` ,  way to parameterize the cross network.\n",
    "        - **l2_reg**: float between 0 and 1. L2 regularizer strength applied to the kernel weights matrix\n",
    "        - **seed**: A Python integer to use as random seed.\n",
    "      References\n",
    "        - [Wang R, Fu B, Fu G, et al. Deep & cross network for ad click predictions[C]//Proceedings of the ADKDD'17. ACM, 2017: 12.](https://arxiv.org/abs/1708.05123)\n",
    "        - [Wang R, Shivanna R, Cheng D Z, et al. DCN-M: Improved Deep & Cross Network for Feature Cross Learning in Web-scale Learning to Rank Systems[J]. 2020.](https://arxiv.org/abs/2008.13535)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, layer_num=2, parameterization='vector', seed=1024, device='cpu'):\n",
    "        super(CrossNet, self).__init__()\n",
    "        self.layer_num = layer_num\n",
    "        self.parameterization = parameterization\n",
    "        if self.parameterization == 'vector':\n",
    "            # weight in DCN.  (in_features, 1)\n",
    "            self.kernels = torch.nn.ParameterList(\n",
    "                [nn.Parameter(nn.init.xavier_normal_(torch.empty(in_features, 1))) for i in range(self.layer_num)])\n",
    "        elif self.parameterization == 'matrix':\n",
    "            # weight matrix in DCN-M.  (in_features, in_features)\n",
    "            self.kernels = torch.nn.ParameterList([nn.Parameter(nn.init.xavier_normal_(\n",
    "                torch.empty(in_features, in_features))) for i in range(self.layer_num)])\n",
    "        else:  # error\n",
    "            raise ValueError(\"parameterization should be 'vector' or 'matrix'\")\n",
    "\n",
    "        self.bias = torch.nn.ParameterList(\n",
    "            [nn.Parameter(nn.init.zeros_(torch.empty(in_features, 1))) for i in range(self.layer_num)])\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x_0 = inputs.unsqueeze(2)\n",
    "        x_l = x_0\n",
    "        for i in range(self.layer_num):\n",
    "            if self.parameterization == 'vector':\n",
    "                xl_w = torch.tensordot(x_l, self.kernels[i], dims=([1], [0]))\n",
    "                dot_ = torch.matmul(x_0, xl_w)\n",
    "                x_l = dot_ + self.bias[i]\n",
    "            elif self.parameterization == 'matrix':\n",
    "                dot_ = torch.matmul(self.kernels[i], x_l)  # W * xi  (bs, in_features, 1)\n",
    "                dot_ = dot_ + self.bias[i]  # W * xi + b\n",
    "                dot_ = x_0 * dot_  # x0 · (W * xi + b)  Hadamard-product\n",
    "            else:  # error\n",
    "                print(\"parameterization should be 'vector' or 'matrix'\")\n",
    "                pass\n",
    "            x_l = dot_ + x_l\n",
    "        x_l = torch.squeeze(x_l, dim=2)\n",
    "        return x_l\n",
    "\n",
    "\n",
    "class CrossNetMix(nn.Module):\n",
    "    \"\"\"The Cross Network part of DCN-Mix model, which improves DCN-M by:\n",
    "      1 add MOE to learn feature interactions in different subspaces\n",
    "      2 add nonlinear transformations in low-dimensional space\n",
    "      Input shape\n",
    "        - 2D tensor with shape: ``(batch_size, units)``.\n",
    "      Output shape\n",
    "        - 2D tensor with shape: ``(batch_size, units)``.\n",
    "      Arguments\n",
    "        - **in_features** : Positive integer, dimensionality of input features.\n",
    "        - **low_rank** : Positive integer, dimensionality of low-rank sapce.\n",
    "        - **num_experts** : Positive integer, number of experts.\n",
    "        - **layer_num**: Positive integer, the cross layer number\n",
    "        - **device**: str, e.g. ``\"cpu\"`` or ``\"cuda:0\"``\n",
    "      References\n",
    "        - [Wang R, Shivanna R, Cheng D Z, et al. DCN-M: Improved Deep & Cross Network for Feature Cross Learning in Web-scale Learning to Rank Systems[J]. 2020.](https://arxiv.org/abs/2008.13535)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, low_rank=32, num_experts=4, layer_num=2, device='cpu'):\n",
    "        super(CrossNetMix, self).__init__()\n",
    "        self.layer_num = layer_num\n",
    "        self.num_experts = num_experts\n",
    "\n",
    "        # U: (in_features, low_rank)\n",
    "        self.U_list = torch.nn.ParameterList([nn.Parameter(nn.init.xavier_normal_(\n",
    "            torch.empty(num_experts, in_features, low_rank))) for i in range(self.layer_num)])\n",
    "        # V: (in_features, low_rank)\n",
    "        self.V_list = torch.nn.ParameterList([nn.Parameter(nn.init.xavier_normal_(\n",
    "            torch.empty(num_experts, in_features, low_rank))) for i in range(self.layer_num)])\n",
    "        # C: (low_rank, low_rank)\n",
    "        self.C_list = torch.nn.ParameterList([nn.Parameter(nn.init.xavier_normal_(\n",
    "            torch.empty(num_experts, low_rank, low_rank))) for i in range(self.layer_num)])\n",
    "        self.gating = nn.ModuleList([nn.Linear(in_features, 1, bias=False) for i in range(self.num_experts)])\n",
    "\n",
    "        self.bias = torch.nn.ParameterList([nn.Parameter(nn.init.zeros_(\n",
    "            torch.empty(in_features, 1))) for i in range(self.layer_num)])\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x_0 = inputs.unsqueeze(2)  # (bs, in_features, 1)\n",
    "        x_l = x_0\n",
    "        for i in range(self.layer_num):\n",
    "            output_of_experts = []\n",
    "            gating_score_of_experts = []\n",
    "            for expert_id in range(self.num_experts):\n",
    "                # (1) G(x_l)\n",
    "                # compute the gating score by x_l\n",
    "                gating_score_of_experts.append(self.gating[expert_id](x_l.squeeze(2)))\n",
    "\n",
    "                # (2) E(x_l)\n",
    "                # project the input x_l to $\\mathbb{R}^{r}$\n",
    "                v_x = torch.matmul(self.V_list[i][expert_id].T, x_l)  # (bs, low_rank, 1)\n",
    "\n",
    "                # nonlinear activation in low rank space\n",
    "                v_x = torch.tanh(v_x)\n",
    "                v_x = torch.matmul(self.C_list[i][expert_id], v_x)\n",
    "                v_x = torch.tanh(v_x)\n",
    "\n",
    "                # project back to $\\mathbb{R}^{d}$\n",
    "                uv_x = torch.matmul(self.U_list[i][expert_id], v_x)  # (bs, in_features, 1)\n",
    "\n",
    "                dot_ = uv_x + self.bias[i]\n",
    "                dot_ = x_0 * dot_  # Hadamard-product\n",
    "\n",
    "                output_of_experts.append(dot_.squeeze(2))\n",
    "\n",
    "            # (3) mixture of low-rank experts\n",
    "            output_of_experts = torch.stack(output_of_experts, 2)  # (bs, in_features, num_experts)\n",
    "            gating_score_of_experts = torch.stack(gating_score_of_experts, 1)  # (bs, num_experts, 1)\n",
    "            moe_out = torch.matmul(output_of_experts, gating_score_of_experts.softmax(1))\n",
    "            x_l = moe_out + x_l  # (bs, in_features, 1)\n",
    "\n",
    "        x_l = x_l.squeeze()  # (bs, in_features)\n",
    "        return x_l\n",
    "\n",
    "\n",
    "class InnerProductLayer(nn.Module):\n",
    "    \"\"\"InnerProduct Layer used in PNN that compute the element-wise\n",
    "    product or inner product between feature vectors.\n",
    "      Input shape\n",
    "        - a list of 3D tensor with shape: ``(batch_size,1,embedding_size)``.\n",
    "      Output shape\n",
    "        - 3D tensor with shape: ``(batch_size, N*(N-1)/2 ,1)`` if use reduce_sum. or 3D tensor with shape:\n",
    "        ``(batch_size, N*(N-1)/2, embedding_size )`` if not use reduce_sum.\n",
    "      Arguments\n",
    "        - **reduce_sum**: bool. Whether return inner product or element-wise product\n",
    "      References\n",
    "            - [Qu Y, Cai H, Ren K, et al. Product-based neural networks for user response prediction[C]//\n",
    "            Data Mining (ICDM), 2016 IEEE 16th International Conference on. IEEE, 2016: 1149-1154.]\n",
    "            (https://arxiv.org/pdf/1611.00144.pdf)\"\"\"\n",
    "\n",
    "    def __init__(self, reduce_sum=True, device='cpu'):\n",
    "        super(InnerProductLayer, self).__init__()\n",
    "        self.reduce_sum = reduce_sum\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        embed_list = inputs\n",
    "        row = []\n",
    "        col = []\n",
    "        num_inputs = len(embed_list)\n",
    "\n",
    "        for i in range(num_inputs - 1):\n",
    "            for j in range(i + 1, num_inputs):\n",
    "                row.append(i)\n",
    "                col.append(j)\n",
    "        p = torch.cat([embed_list[idx]\n",
    "                       for idx in row], dim=1)  # batch num_pairs k\n",
    "        q = torch.cat([embed_list[idx]\n",
    "                       for idx in col], dim=1)\n",
    "\n",
    "        inner_product = p * q\n",
    "        if self.reduce_sum:\n",
    "            inner_product = torch.sum(\n",
    "                inner_product, dim=2, keepdim=True)\n",
    "        return inner_product\n",
    "\n",
    "\n",
    "class OutterProductLayer(nn.Module):\n",
    "    \"\"\"OutterProduct Layer used in PNN.This implemention is\n",
    "    adapted from code that the author of the paper published on https://github.com/Atomu2014/product-nets.\n",
    "      Input shape\n",
    "            - A list of N 3D tensor with shape: ``(batch_size,1,embedding_size)``.\n",
    "      Output shape\n",
    "            - 2D tensor with shape:``(batch_size,N*(N-1)/2 )``.\n",
    "      Arguments\n",
    "            - **filed_size** : Positive integer, number of feature groups.\n",
    "            - **kernel_type**: str. The kernel weight matrix type to use,can be mat,vec or num\n",
    "            - **seed**: A Python integer to use as random seed.\n",
    "      References\n",
    "            - [Qu Y, Cai H, Ren K, et al. Product-based neural networks for user response prediction[C]//Data Mining (ICDM), 2016 IEEE 16th International Conference on. IEEE, 2016: 1149-1154.](https://arxiv.org/pdf/1611.00144.pdf)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, field_size, embedding_size, kernel_type='mat', seed=1024, device='cpu'):\n",
    "        super(OutterProductLayer, self).__init__()\n",
    "        self.kernel_type = kernel_type\n",
    "\n",
    "        num_inputs = field_size\n",
    "        num_pairs = int(num_inputs * (num_inputs - 1) / 2)\n",
    "        embed_size = embedding_size\n",
    "        if self.kernel_type == 'mat':\n",
    "\n",
    "            self.kernel = nn.Parameter(torch.Tensor(\n",
    "                embed_size, num_pairs, embed_size))\n",
    "\n",
    "        elif self.kernel_type == 'vec':\n",
    "            self.kernel = nn.Parameter(torch.Tensor(num_pairs, embed_size))\n",
    "\n",
    "        elif self.kernel_type == 'num':\n",
    "            self.kernel = nn.Parameter(torch.Tensor(num_pairs, 1))\n",
    "        nn.init.xavier_uniform_(self.kernel)\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embed_list = inputs\n",
    "        row = []\n",
    "        col = []\n",
    "        num_inputs = len(embed_list)\n",
    "        for i in range(num_inputs - 1):\n",
    "            for j in range(i + 1, num_inputs):\n",
    "                row.append(i)\n",
    "                col.append(j)\n",
    "        p = torch.cat([embed_list[idx]\n",
    "                       for idx in row], dim=1)  # batch num_pairs k\n",
    "        q = torch.cat([embed_list[idx] for idx in col], dim=1)\n",
    "\n",
    "        # -------------------------\n",
    "        if self.kernel_type == 'mat':\n",
    "            p.unsqueeze_(dim=1)\n",
    "            # k     k* pair* k\n",
    "            # batch * pair\n",
    "            kp = torch.sum(\n",
    "\n",
    "                # batch * pair * k\n",
    "\n",
    "                torch.mul(\n",
    "\n",
    "                    # batch * pair * k\n",
    "\n",
    "                    torch.transpose(\n",
    "\n",
    "                        # batch * k * pair\n",
    "\n",
    "                        torch.sum(\n",
    "\n",
    "                            # batch * k * pair * k\n",
    "\n",
    "                            torch.mul(\n",
    "\n",
    "                                p, self.kernel),\n",
    "\n",
    "                            dim=-1),\n",
    "\n",
    "                        2, 1),\n",
    "\n",
    "                    q),\n",
    "\n",
    "                dim=-1)\n",
    "        else:\n",
    "            # 1 * pair * (k or 1)\n",
    "\n",
    "            k = torch.unsqueeze(self.kernel, 0)\n",
    "\n",
    "            # batch * pair\n",
    "\n",
    "            kp = torch.sum(p * q * k, dim=-1)\n",
    "\n",
    "            # p q # b * p * k\n",
    "\n",
    "        return kp\n",
    "\n",
    "\n",
    "class ConvLayer(nn.Module):\n",
    "    \"\"\"Conv Layer used in CCPM.\n",
    "\n",
    "      Input shape\n",
    "            - A list of N 3D tensor with shape: ``(batch_size,1,filed_size,embedding_size)``.\n",
    "      Output shape\n",
    "            - A list of N 3D tensor with shape: ``(batch_size,last_filters,pooling_size,embedding_size)``.\n",
    "      Arguments\n",
    "            - **filed_size** : Positive integer, number of feature groups.\n",
    "            - **conv_kernel_width**: list. list of positive integer or empty list,the width of filter in each conv layer.\n",
    "            - **conv_filters**: list. list of positive integer or empty list,the number of filters in each conv layer.\n",
    "      Reference:\n",
    "            - Liu Q, Yu F, Wu S, et al. A convolutional click prediction model[C]//Proceedings of the 24th ACM International on Conference on Information and Knowledge Management. ACM, 2015: 1743-1746.(http://ir.ia.ac.cn/bitstream/173211/12337/1/A%20Convolutional%20Click%20Prediction%20Model.pdf)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, field_size, conv_kernel_width, conv_filters, device='cpu'):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        self.device = device\n",
    "        module_list = []\n",
    "        n = int(field_size)\n",
    "        l = len(conv_filters)\n",
    "        filed_shape = n\n",
    "        for i in range(1, l + 1):\n",
    "            if i == 1:\n",
    "                in_channels = 1\n",
    "            else:\n",
    "                in_channels = conv_filters[i - 2]\n",
    "            out_channels = conv_filters[i - 1]\n",
    "            width = conv_kernel_width[i - 1]\n",
    "            k = max(1, int((1 - pow(i / l, l - i)) * n)) if i < l else 3\n",
    "            module_list.append(Conv2dSame(in_channels=in_channels, out_channels=out_channels, kernel_size=(width, 1),\n",
    "                                          stride=1).to(self.device))\n",
    "            module_list.append(torch.nn.Tanh().to(self.device))\n",
    "\n",
    "            # KMaxPooling, extract top_k, returns tensors values\n",
    "            module_list.append(KMaxPooling(k=min(k, filed_shape), axis=2, device=self.device).to(self.device))\n",
    "            filed_shape = min(k, filed_shape)\n",
    "        self.conv_layer = nn.Sequential(*module_list)\n",
    "        self.to(device)\n",
    "        self.filed_shape = filed_shape\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.conv_layer(inputs)\n",
    "\n",
    "# DeepFM\n",
    "# -----------------------------------------------------------------------------------------------------------------\n",
    "class DeepFM(BaseModel):\n",
    "    \"\"\"Instantiates the DeepFM Network architecture.\n",
    "\n",
    "    :param linear_feature_columns: An iterable containing all the features used by linear part of the model.\n",
    "    :param dnn_feature_columns: An iterable containing all the features used by deep part of the model.\n",
    "    :param use_fm: bool,use FM part or not\n",
    "    :param dnn_hidden_units: list,list of positive integer or empty list, the layer number and units in each layer of DNN\n",
    "    :param l2_reg_linear: float. L2 regularizer strength applied to linear part\n",
    "    :param l2_reg_embedding: float. L2 regularizer strength applied to embedding vector\n",
    "    :param l2_reg_dnn: float. L2 regularizer strength applied to DNN\n",
    "    :param init_std: float,to use as the initialize std of embedding vector\n",
    "    :param seed: integer ,to use as random seed.\n",
    "    :param dnn_dropout: float in [0,1), the probability we will drop out a given DNN coordinate.\n",
    "    :param dnn_activation: Activation function to use in DNN\n",
    "    :param dnn_use_bn: bool. Whether use BatchNormalization before activation or not in DNN\n",
    "    :param task: str, ``\"binary\"`` for  binary logloss or  ``\"regression\"`` for regression loss\n",
    "    :param device: str, ``\"cpu\"`` or ``\"cuda:0\"``\n",
    "    :return: A PyTorch model instance.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 linear_feature_columns, dnn_feature_columns, use_fm=True,\n",
    "                 dnn_hidden_units=(256, 128),\n",
    "                 l2_reg_linear=0.00001, l2_reg_embedding=0.00001, l2_reg_dnn=0, init_std=0.0001, seed=1024,\n",
    "                 dnn_dropout=0,\n",
    "                 dnn_activation='relu', dnn_use_bn=False, task='binary', device='cpu'):\n",
    "\n",
    "        super(DeepFM, self).__init__(linear_feature_columns, dnn_feature_columns, l2_reg_linear=l2_reg_linear,\n",
    "                                     l2_reg_embedding=l2_reg_embedding, init_std=init_std, seed=seed, task=task,\n",
    "                                     device=device)\n",
    "\n",
    "        self.use_fm = use_fm\n",
    "        self.use_dnn = len(dnn_feature_columns) > 0 and len(\n",
    "            dnn_hidden_units) > 0\n",
    "        if use_fm:\n",
    "            self.fm = FM()\n",
    "\n",
    "        if self.use_dnn:\n",
    "            self.dnn = DNN(self.compute_input_dim(dnn_feature_columns), dnn_hidden_units,\n",
    "                           activation=dnn_activation, l2_reg=l2_reg_dnn, dropout_rate=dnn_dropout, use_bn=dnn_use_bn,\n",
    "                           init_std=init_std, device=device)\n",
    "            self.dnn_linear = nn.Linear(\n",
    "                dnn_hidden_units[-1], 1, bias=False).to(device)\n",
    "\n",
    "            self.add_regularization_weight(\n",
    "                filter(lambda x: 'weight' in x[0] and 'bn' not in x[0], self.dnn.named_parameters()), l2_reg_dnn)\n",
    "            self.add_regularization_weight(self.dnn_linear.weight, l2_reg_dnn)\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        sparse_embedding_list, dense_value_list = self.input_from_feature_columns(X, self.dnn_feature_columns,\n",
    "                                                                                  self.embedding_dict)\n",
    "        logit = self.linear_model(X)\n",
    "\n",
    "        if self.use_fm and len(sparse_embedding_list) > 0:\n",
    "            fm_input = torch.cat(sparse_embedding_list, dim=1)\n",
    "            logit += self.fm(fm_input)\n",
    "\n",
    "        if self.use_dnn:\n",
    "            dnn_input = combined_dnn_input(\n",
    "                sparse_embedding_list, dense_value_list)\n",
    "            dnn_output = self.dnn(dnn_input)\n",
    "            dnn_logit = self.dnn_linear(dnn_output)\n",
    "            logit += dnn_logit\n",
    "\n",
    "        y_pred = self.out(logit)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# xDeepFm\n",
    "class xDeepFM(BaseModel):\n",
    "    \"\"\"Instantiates the xDeepFM architecture.\n",
    "\n",
    "    :param linear_feature_columns: An iterable containing all the features used by linear part of the model.\n",
    "    :param dnn_feature_columns: An iterable containing all the features used by deep part of the model.\n",
    "    :param dnn_hidden_units: list,list of positive integer or empty list, the layer number and units in each layer of deep net\n",
    "    :param cin_layer_size: list,list of positive integer or empty list, the feature maps  in each hidden layer of Compressed Interaction Network\n",
    "    :param cin_split_half: bool.if set to True, half of the feature maps in each hidden will connect to output unit\n",
    "    :param cin_activation: activation function used on feature maps\n",
    "    :param l2_reg_linear: float. L2 regularizer strength applied to linear part\n",
    "    :param l2_reg_embedding: L2 regularizer strength applied to embedding vector\n",
    "    :param l2_reg_dnn: L2 regularizer strength applied to deep net\n",
    "    :param l2_reg_cin: L2 regularizer strength applied to CIN.\n",
    "    :param init_std: float,to use as the initialize std of embedding vector\n",
    "    :param seed: integer ,to use as random seed.\n",
    "    :param dnn_dropout: float in [0,1), the probability we will drop out a given DNN coordinate.\n",
    "    :param dnn_activation: Activation function to use in DNN\n",
    "    :param dnn_use_bn: bool. Whether use BatchNormalization before activation or not in DNN\n",
    "    :param task: str, ``\"binary\"`` for  binary logloss or  ``\"regression\"`` for regression loss\n",
    "    :param device: str, ``\"cpu\"`` or ``\"cuda:0\"``\n",
    "    :return: A PyTorch model instance.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, linear_feature_columns, dnn_feature_columns, dnn_hidden_units=(256, 256),\n",
    "                 cin_layer_size=(256, 128,), cin_split_half=True, cin_activation='relu', l2_reg_linear=0.00001,\n",
    "                 l2_reg_embedding=0.00001, l2_reg_dnn=0, l2_reg_cin=0, init_std=0.0001, seed=1024, dnn_dropout=0,\n",
    "                 dnn_activation='relu', dnn_use_bn=False, task='binary', device='cpu'):\n",
    "\n",
    "        super(xDeepFM, self).__init__(linear_feature_columns, dnn_feature_columns, l2_reg_linear=l2_reg_linear,\n",
    "                                      l2_reg_embedding=l2_reg_embedding, init_std=init_std, seed=seed, task=task,\n",
    "                                      device=device)\n",
    "        self.dnn_hidden_units = dnn_hidden_units\n",
    "        self.use_dnn = len(dnn_feature_columns) > 0 and len(dnn_hidden_units) > 0\n",
    "        if self.use_dnn:\n",
    "            self.dnn = DNN(self.compute_input_dim(dnn_feature_columns), dnn_hidden_units,\n",
    "                           activation=dnn_activation, l2_reg=l2_reg_dnn, dropout_rate=dnn_dropout, use_bn=dnn_use_bn,\n",
    "                           init_std=init_std, device=device)\n",
    "            self.dnn_linear = nn.Linear(dnn_hidden_units[-1], 1, bias=False).to(device)\n",
    "            self.add_regularization_weight(\n",
    "                filter(lambda x: 'weight' in x[0] and 'bn' not in x[0], self.dnn.named_parameters()), l2_reg_dnn)\n",
    "\n",
    "            self.add_regularization_weight(self.dnn_linear.weight, l2_reg_dnn)\n",
    "\n",
    "        self.cin_layer_size = cin_layer_size\n",
    "        self.use_cin = len(self.cin_layer_size) > 0 and len(dnn_feature_columns) > 0\n",
    "        if self.use_cin:\n",
    "            field_num = len(self.embedding_dict)\n",
    "            if cin_split_half == True:\n",
    "                self.featuremap_num = sum(\n",
    "                    cin_layer_size[:-1]) // 2 + cin_layer_size[-1]\n",
    "            else:\n",
    "                self.featuremap_num = sum(cin_layer_size)\n",
    "            self.cin = CIN(field_num, cin_layer_size,\n",
    "                           cin_activation, cin_split_half, l2_reg_cin, seed, device=device)\n",
    "            self.cin_linear = nn.Linear(self.featuremap_num, 1, bias=False).to(device)\n",
    "            self.add_regularization_weight(\n",
    "                filter(lambda x: 'weight' in x[0], self.cin.named_parameters()), l2_reg_cin)\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        sparse_embedding_list, dense_value_list = self.input_from_feature_columns(X, self.dnn_feature_columns,\n",
    "                                                                                  self.embedding_dict)\n",
    "\n",
    "        linear_logit = self.linear_model(X)\n",
    "        if self.use_cin:\n",
    "            cin_input = torch.cat(sparse_embedding_list, dim=1)\n",
    "            cin_output = self.cin(cin_input)\n",
    "            cin_logit = self.cin_linear(cin_output)\n",
    "        if self.use_dnn:\n",
    "            dnn_input = combined_dnn_input(sparse_embedding_list, dense_value_list)\n",
    "            dnn_output = self.dnn(dnn_input)\n",
    "            dnn_logit = self.dnn_linear(dnn_output)\n",
    "\n",
    "        if len(self.dnn_hidden_units) == 0 and len(self.cin_layer_size) == 0:  # only linear\n",
    "            final_logit = linear_logit\n",
    "        elif len(self.dnn_hidden_units) == 0 and len(self.cin_layer_size) > 0:  # linear + CIN\n",
    "            final_logit = linear_logit + cin_logit\n",
    "        elif len(self.dnn_hidden_units) > 0 and len(self.cin_layer_size) == 0:  # linear +　Deep\n",
    "            final_logit = linear_logit + dnn_logit\n",
    "        elif len(self.dnn_hidden_units) > 0 and len(self.cin_layer_size) > 0:  # linear + CIN + Deep\n",
    "            final_logit = linear_logit + dnn_logit + cin_logit\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        y_pred = self.out(final_logit)\n",
    "\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "cat_columns = ['prior_question_had_explanation','bundle_id','user_id', 'content_id', 'task_container_id']\n",
    "#cat_columns = ['bundle_id','user_id', 'content_id', 'task_container_id']\n",
    "\n",
    "cont_columns = ['answered_correctly_user', 'explanation_mean_user', 'quest_pct', 'avg_questions_seen','prior_question_elapsed_time', 'part',\n",
    "                'part_1', 'part_2', 'part_3', 'part_4', 'part_5', 'part_6', 'part_7',\n",
    "               'type_of_concept', 'type_of_intention', 'type_of_solving_question', 'type_of_starter',\n",
    "               'part_1_boolean', 'part_2_boolean', 'part_3_boolean', 'part_4_boolean', 'part_5_boolean', 'part_6_boolean', 'part_7_boolean',\n",
    "               'type_of_concept_boolean', 'type_of_intention_boolean', 'type_of_solving_question_boolean', 'type_of_starter_boolean']\n",
    "\n",
    "#cont_columns = ['answered_correctly_user', 'explanation_mean_user', 'quest_pct', 'avg_questions_seen','prior_question_elapsed_time', 'part']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda ready...\n",
      "cuda:0\n",
      "Train on 6667130 samples, validate on 1666783 samples, 204 steps per epoch\n",
      "Epoch 1/30\n",
      "78s - loss:  0.5566 - binary_crossentropy:  0.5566 - auc:  0.7395 - val_binary_crossentropy:  0.5435 - val_auc:  0.7575\n",
      "Epoch 2/30\n",
      "75s - loss:  0.5601 - binary_crossentropy:  0.5601 - auc:  0.7554 - val_binary_crossentropy:  0.5423 - val_auc:  0.7587\n",
      "Epoch 3/30\n",
      "76s - loss:  0.5373 - binary_crossentropy:  0.5373 - auc:  0.7646 - val_binary_crossentropy:  0.5409 - val_auc:  0.7607\n",
      "Epoch 4/30\n",
      "75s - loss:  0.5342 - binary_crossentropy:  0.5342 - auc:  0.7679 - val_binary_crossentropy:  0.5398 - val_auc:  0.7616\n",
      "Epoch 5/30\n",
      "75s - loss:  0.5317 - binary_crossentropy:  0.5317 - auc:  0.7706 - val_binary_crossentropy:  0.5395 - val_auc:  0.7619\n",
      "Epoch 6/30\n",
      "76s - loss:  0.5295 - binary_crossentropy:  0.5295 - auc:  0.7730 - val_binary_crossentropy:  0.5401 - val_auc:  0.7624\n",
      "Epoch 7/30\n",
      "76s - loss:  0.5276 - binary_crossentropy:  0.5276 - auc:  0.7750 - val_binary_crossentropy:  0.5403 - val_auc:  0.7620\n",
      "Epoch 8/30\n",
      "76s - loss:  0.5259 - binary_crossentropy:  0.5259 - auc:  0.7768 - val_binary_crossentropy:  0.5405 - val_auc:  0.7621\n",
      "Epoch 9/30\n",
      "75s - loss:  0.5245 - binary_crossentropy:  0.5245 - auc:  0.7783 - val_binary_crossentropy:  0.5410 - val_auc:  0.7616\n",
      "Epoch 10/30\n",
      "75s - loss:  0.5231 - binary_crossentropy:  0.5232 - auc:  0.7796 - val_binary_crossentropy:  0.5417 - val_auc:  0.7613\n",
      "Epoch 11/30\n",
      "75s - loss:  0.5221 - binary_crossentropy:  0.5221 - auc:  0.7807 - val_binary_crossentropy:  0.5419 - val_auc:  0.7609\n",
      "Epoch 12/30\n",
      "75s - loss:  0.5210 - binary_crossentropy:  0.5210 - auc:  0.7817 - val_binary_crossentropy:  0.5431 - val_auc:  0.7608\n",
      "Epoch 13/30\n",
      "75s - loss:  0.5202 - binary_crossentropy:  0.5203 - auc:  0.7825 - val_binary_crossentropy:  0.5428 - val_auc:  0.7599\n",
      "Epoch 14/30\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-05.\n",
      "76s - loss:  0.5195 - binary_crossentropy:  0.5195 - auc:  0.7833 - val_binary_crossentropy:  0.5432 - val_auc:  0.7599\n",
      "Epoch 15/30\n",
      "75s - loss:  0.5125 - binary_crossentropy:  0.5124 - auc:  0.7907 - val_binary_crossentropy:  0.5439 - val_auc:  0.7598\n",
      "Epoch 16/30\n",
      "75s - loss:  0.5122 - binary_crossentropy:  0.5122 - auc:  0.7909 - val_binary_crossentropy:  0.5442 - val_auc:  0.7597\n",
      "Epoch 17/30\n",
      "75s - loss:  0.5120 - binary_crossentropy:  0.5120 - auc:  0.7911 - val_binary_crossentropy:  0.5445 - val_auc:  0.7595\n",
      "Epoch 18/30\n",
      "75s - loss:  0.5118 - binary_crossentropy:  0.5118 - auc:  0.7912 - val_binary_crossentropy:  0.5447 - val_auc:  0.7594\n",
      "Epoch 19/30\n",
      "75s - loss:  0.5117 - binary_crossentropy:  0.5117 - auc:  0.7914 - val_binary_crossentropy:  0.5449 - val_auc:  0.7593\n",
      "Epoch 20/30\n",
      "75s - loss:  0.5115 - binary_crossentropy:  0.5115 - auc:  0.7915 - val_binary_crossentropy:  0.5451 - val_auc:  0.7592\n",
      "Epoch 21/30\n",
      "75s - loss:  0.5114 - binary_crossentropy:  0.5114 - auc:  0.7916 - val_binary_crossentropy:  0.5452 - val_auc:  0.7591\n",
      "Epoch 22/30\n",
      "76s - loss:  0.5113 - binary_crossentropy:  0.5113 - auc:  0.7917 - val_binary_crossentropy:  0.5454 - val_auc:  0.7590\n",
      "Epoch 23/30\n",
      "75s - loss:  0.5112 - binary_crossentropy:  0.5112 - auc:  0.7918 - val_binary_crossentropy:  0.5456 - val_auc:  0.7589\n",
      "Epoch 24/30\n",
      "76s - loss:  0.5111 - binary_crossentropy:  0.5111 - auc:  0.7919 - val_binary_crossentropy:  0.5457 - val_auc:  0.7589\n",
      "Epoch 25/30\n",
      "76s - loss:  0.5110 - binary_crossentropy:  0.5110 - auc:  0.7920 - val_binary_crossentropy:  0.5458 - val_auc:  0.7588\n",
      "Epoch 26/30\n",
      "75s - loss:  0.5109 - binary_crossentropy:  0.5109 - auc:  0.7921 - val_binary_crossentropy:  0.5459 - val_auc:  0.7586\n",
      "Epoch 27/30\n",
      "76s - loss:  0.5108 - binary_crossentropy:  0.5108 - auc:  0.7922 - val_binary_crossentropy:  0.5461 - val_auc:  0.7586\n",
      "Epoch 28/30\n",
      "75s - loss:  0.5107 - binary_crossentropy:  0.5107 - auc:  0.7923 - val_binary_crossentropy:  0.5463 - val_auc:  0.7585\n",
      "Epoch 29/30\n",
      "75s - loss:  0.5106 - binary_crossentropy:  0.5107 - auc:  0.7923 - val_binary_crossentropy:  0.5463 - val_auc:  0.7584\n",
      "Epoch 30/30\n",
      "75s - loss:  0.5106 - binary_crossentropy:  0.5106 - auc:  0.7924 - val_binary_crossentropy:  0.5464 - val_auc:  0.7584\n",
      "\n",
      "test LogLoss 0.5467\n",
      "test AUC 0.7583\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "fixlen_feature_columns = [SparseFeat(feat, X[feat].nunique())\n",
    "                          for feat in cat_columns] + [DenseFeat(feat, 1, )\n",
    "                                                      for feat in cont_columns]\n",
    "'''\n",
    "fixlen_feature_columns = [SparseFeat(feat, X[feat].nunique()) for feat in cat_columns]\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "fixlen_feature_columns =  [DenseFeat(feat, 1, ) for feat in cont_columns]\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "\n",
    "# 3.generate input data for model\n",
    "\n",
    "X_train,X_valid,y_train,y_valid = train_test_split(X[features],y,test_size=0.15)\n",
    "train_model_input = {name: X_train[name] for name in feature_names}\n",
    "test_model_input = {name: X_valid[name] for name in feature_names}\n",
    "\n",
    "device = 'cpu'\n",
    "use_cuda = True\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    print('cuda ready...')\n",
    "    device = 'cuda:0'\n",
    "\n",
    "'''\n",
    "model = DeepFM(linear_feature_columns=linear_feature_columns, dnn_feature_columns=dnn_feature_columns,\n",
    "               task='binary',dnn_dropout=0.2, dnn_use_bn=True, \n",
    "               l2_reg_embedding=1e-5, device=device)'''\n",
    "model = xDeepFM(linear_feature_columns, dnn_feature_columns, dnn_use_bn=True, dnn_dropout=0.5, device='cuda:0')\n",
    "\n",
    "model.compile(\"adam\", \"binary_crossentropy\",\n",
    "              metrics=[\"binary_crossentropy\", \"auc\"], )\n",
    "\n",
    "model.fit(train_model_input, y_train.values, batch_size=2**15, epochs=30, verbose=2, validation_split=0.2)\n",
    "\n",
    "pred_ans = model.predict(test_model_input, 256)\n",
    "print(\"\")\n",
    "print(\"test LogLoss\", round(log_loss(y_valid.values, pred_ans), 4))\n",
    "print(\"test AUC\", round(roc_auc_score(y_valid.values, pred_ans), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc  ###计算roc和auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def acu_curve(y,prob):\n",
    "    fpr,tpr,threshold = roc_curve(y,prob) ###计算真正率和假正率\n",
    "    roc_auc = auc(fpr,tpr) ###计算auc的值\n",
    " \n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.3f)' % roc_auc) ###假正率为横坐标，真正率为纵坐标做曲线\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    " \n",
    "    plt.show()\n",
    "acu_curve(y_valid.values, pred_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "iter_test = env.iter_test()\n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    test_df = test_df.iloc[:,:]\n",
    "    \n",
    "    #test_df['task_container_id'] = test_df.task_container_id.mask(test_df.task_container_id > 9999, 9999)\n",
    "    \n",
    "    test_df = pd.merge(test_df, group3, left_on=['task_container_id'], right_index= True, how=\"left\")\n",
    "    test_df = pd.merge(test_df, question2, left_on = 'content_id', right_on = 'question_id', how = 'left')\n",
    "    test_df = pd.merge(test_df, results_u_final, on=['user_id'],  how=\"left\")\n",
    "    test_df = pd.merge(test_df, results_u2_final, on=['user_id'],  how=\"left\")\n",
    "    test_df = pd.merge(test_df, user_lecture_stats_part, on=['user_id'], how=\"left\")\n",
    "    \n",
    "    test_df['part_1'].fillna(0, inplace = True)\n",
    "    test_df['part_2'].fillna(0, inplace = True)\n",
    "    test_df['part_3'].fillna(0, inplace = True)\n",
    "    test_df['part_4'].fillna(0, inplace = True)\n",
    "    test_df['part_5'].fillna(0, inplace = True)\n",
    "    test_df['part_6'].fillna(0, inplace = True)\n",
    "    test_df['part_7'].fillna(0, inplace = True)\n",
    "    test_df['type_of_concept'].fillna(0, inplace = True)\n",
    "    test_df['type_of_intention'].fillna(0, inplace = True)\n",
    "    test_df['type_of_solving_question'].fillna(0, inplace = True)\n",
    "    test_df['type_of_starter'].fillna(0, inplace = True)\n",
    "    test_df['part_1_boolean'].fillna(0, inplace = True)\n",
    "    test_df['part_2_boolean'].fillna(0, inplace = True)\n",
    "    test_df['part_3_boolean'].fillna(0, inplace = True)\n",
    "    test_df['part_4_boolean'].fillna(0, inplace = True)\n",
    "    test_df['part_5_boolean'].fillna(0, inplace = True)\n",
    "    test_df['part_6_boolean'].fillna(0, inplace = True)\n",
    "    test_df['part_7_boolean'].fillna(0, inplace = True)\n",
    "    test_df['type_of_concept_boolean'].fillna(0, inplace = True)\n",
    "    test_df['type_of_intention_boolean'].fillna(0, inplace = True)\n",
    "    test_df['type_of_solving_question_boolean'].fillna(0, inplace = True)\n",
    "    test_df['type_of_starter_boolean'].fillna(0, inplace = True)\n",
    "    \n",
    "    test_df['answered_correctly_user'].fillna(0.65,  inplace=True)\n",
    "    test_df['explanation_mean_user'].fillna(prior_mean_user,  inplace=True)\n",
    "    test_df['quest_pct'].fillna(content_mean,  inplace=True)\n",
    "    test_df['part'] = test_df.part - 1\n",
    "\n",
    "    test_df['part'].fillna(4, inplace = True)\n",
    "    test_df['avg_questions_seen'].fillna(1, inplace = True)\n",
    "    test_df['prior_question_elapsed_time'].fillna(elapsed_mean, inplace = True)\n",
    "    test_df['prior_question_had_explanation'].fillna(False, inplace=True)\n",
    "    \n",
    "    test_df['task_container_id'] = test_df['task_container_id'].astype(np.int64)\n",
    "    test_df['content_id'] = test_df['content_id'].astype(np.int64)\n",
    "    test_df['user_id'] = test_df['user_id'].astype(np.int64)\n",
    "    test_df['bundle_id'] = test_df['bundle_id'].astype(np.int64)\n",
    "    test_df['prior_question_had_explanation'] = test_df['prior_question_had_explanation'].astype(np.int64)\n",
    "    test_df['type_of_starter_boolean'] = test_df['type_of_starter_boolean'].astype(np.float64)\n",
    "    test_df['type_of_solving_question_boolean'] = test_df['type_of_solving_question_boolean'].astype(np.float64)\n",
    "    test_df['type_of_intention_boolean'] = test_df['type_of_intention_boolean'].astype(np.float64)\n",
    "    test_df['type_of_concept_boolean'] = test_df['type_of_concept_boolean'].astype(np.float64)\n",
    "    test_df['part_7_boolean'] = test_df['part_7_boolean'].astype(np.float64)\n",
    "    test_df['part_6_boolean'] = test_df['part_6_boolean'].astype(np.float64)\n",
    "    test_df['part_5_boolean'] = test_df['part_5_boolean'].astype(np.float64)\n",
    "    test_df['part_4_boolean'] = test_df['part_4_boolean'].astype(np.float64)\n",
    "    test_df['part_3_boolean'] = test_df['part_3_boolean'].astype(np.float64)\n",
    "    test_df['part_2_boolean'] = test_df['part_2_boolean'].astype(np.float64)\n",
    "    test_df['part_1_boolean'] = test_df['part_1_boolean'].astype(np.float64)\n",
    "    test_df['type_of_starter'] = test_df['type_of_starter'].astype(np.float64)\n",
    "    test_df['type_of_solving_question'] = test_df['type_of_solving_question'].astype(np.float64)\n",
    "    test_df['type_of_intention'] = test_df['type_of_intention'].astype(np.float64)\n",
    "    test_df['type_of_concept'] = test_df['type_of_concept'].astype(np.float64)\n",
    "    test_df['part_6'] = test_df['part_6'].astype(np.float64)\n",
    "    test_df['part_5'] = test_df['part_5'].astype(np.float64)\n",
    "    test_df['part_4'] = test_df['part_4'].astype(np.float64)\n",
    "    test_df['part_3'] = test_df['part_3'].astype(np.float64)\n",
    "    test_df['part_2'] = test_df['part_2'].astype(np.float64)\n",
    "    test_df['part_1'] = test_df['part_1'].astype(np.float64)\n",
    "    test_df['part'] = test_df['part'].astype(np.float64)\n",
    "    test_df['prior_question_elapsed_time'] = test_df['prior_question_elapsed_time'].astype(np.float32)\n",
    "    test_df['avg_questions_seen'] = test_df['avg_questions_seen'].astype(np.float64)\n",
    "    test_df['quest_pct'] = test_df['quest_pct'].astype(np.float64)\n",
    "    test_df['explanation_mean_user'] = test_df['explanation_mean_user'].astype(np.float64)\n",
    "    test_df['answered_correctly_user'] = test_df['answered_correctly_user'].astype(np.float64)\n",
    "    #X['prior_question_had_explanation_enc'].fillna(0, inplace = True)\n",
    "    \n",
    "    test_df, enc_dict = encode(test_df,cat_columns)\n",
    "\n",
    "    scale_dict={}\n",
    "    fix_missing={}\n",
    "\n",
    "    for col in cont_columns:\n",
    "        scaler = RobustScaler()\n",
    "        scale_dict[col]=scaler.fit(test_df[col].values.reshape(-1,1))\n",
    "        test_df[col] = scale_dict[col].transform(test_df[col].values.reshape(-1,1))\n",
    "        fix_missing[col] = test_df[col].mode()\n",
    "    \n",
    "    fixlen_feature_columns = [SparseFeat(feat, X[feat].nunique()) for feat in cat_columns]\n",
    "    dnn_feature_columns = fixlen_feature_columns\n",
    "    \n",
    "    fixlen_feature_columns =  [DenseFeat(feat, 1, ) for feat in cont_columns]\n",
    "    linear_feature_columns = fixlen_feature_columns\n",
    "    \n",
    "    feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "    \n",
    "    test_model_input = {name: test_df[name] for name in feature_names}\n",
    "    #print(test_model_input)\n",
    "    \n",
    "    #print()\n",
    "    test_df['answered_correctly'] = model.predict(test_model_input, 256)\n",
    "    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-15",
   "language": "python",
   "name": "torch-15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

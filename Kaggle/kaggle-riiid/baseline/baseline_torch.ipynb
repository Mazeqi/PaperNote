{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import riiideducation\n",
    "#import dask.dataframe as dd\n",
    "import  pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import warnings\n",
    "import gc\n",
    "warnings.filterwarnings('ignore')\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = 'riiid_data/'\n",
    "file_train = 'train.csv'\n",
    "file_questions = 'questions.csv'\n",
    "file_lecture = 'lectures.csv'\n",
    "nrows =  100*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\n",
    "                    dir_path + file_train, \n",
    "                    nrows=nrows, \n",
    "                    usecols=['row_id', 'timestamp', 'user_id', 'content_id', \n",
    "                             'content_type_id', 'task_container_id', 'answered_correctly',\n",
    "                            'prior_question_elapsed_time','prior_question_had_explanation'],\n",
    "                    dtype={\n",
    "                            'row_id': 'int64',\n",
    "                            'timestamp': 'int64',\n",
    "                            'user_id': 'int32',\n",
    "                            'content_id': 'int16',\n",
    "                            'content_type_id': 'int8',\n",
    "                            'task_container_id': 'int8',\n",
    "                            'answered_correctly': 'int8',\n",
    "                            'prior_question_elapsed_time': 'float32',\n",
    "                            'prior_question_had_explanation': 'str'\n",
    "                        }\n",
    "                   )\n",
    "#train = train[train.content_type_id == False]\n",
    "train_df = train_df.sort_values(['timestamp'], ascending=True)\n",
    "#train_df.drop(['timestamp'], axis=1,   inplace=True)\n",
    "\n",
    "\n",
    "questions_df = pd.read_csv(\n",
    "                        dir_path + file_questions, \n",
    "                        nrows=nrows,\n",
    "                        usecols=['question_id','bundle_id','part'], \n",
    "                        dtype={\n",
    "                            'question_id': 'int16',\n",
    "                            'bundle_id': 'int8',\n",
    "                            'part': 'int8',\n",
    "                       }\n",
    "                    )\n",
    "\n",
    "lectures_df = pd.read_csv(dir_path + file_lecture)\n",
    "train_df['prior_question_had_explanation'] = train_df['prior_question_had_explanation'].fillna('False').map({\"True\":True,\"False\":False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract lecture\n",
    "\n",
    "lectures_df['type_of'] = lectures_df['type_of'].replace('solving question', 'solving_question')\n",
    "\n",
    "lectures_df = pd.get_dummies(lectures_df, columns=['part', 'type_of'])\n",
    "\n",
    "part_lectures_columns = [column for column in lectures_df.columns if column.startswith('part')]\n",
    "\n",
    "types_of_lectures_columns = [column for column in lectures_df.columns if column.startswith('type_of_')]\n",
    "\n",
    "train_lectures = train_df[train_df.content_type_id == True].merge(lectures_df, left_on='content_id', right_on='lecture_id', how='left')\n",
    "\n",
    "user_lecture_stats_part = train_lectures.groupby('user_id')[part_lectures_columns + types_of_lectures_columns].sum()\n",
    "\n",
    "# add boolean features\n",
    "for column in user_lecture_stats_part.columns:\n",
    "    bool_column = column + '_boolean'\n",
    "    user_lecture_stats_part[bool_column] = (user_lecture_stats_part[column] > 0).astype(int)\n",
    "    \n",
    "del(train_lectures)\n",
    "train_df = train_df[train_df.content_type_id == False].sort_values('timestamp').reset_index(drop = True)\n",
    "elapsed_mean = train_df.prior_question_elapsed_time.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract train\n",
    "\n",
    "group1 = train_df.loc[(train_df.content_type_id == False), ['task_container_id', 'user_id']].groupby(['task_container_id']).agg(['count'])\n",
    "group1.columns = ['avg_questions']\n",
    "\n",
    "group2 = train_df.loc[(train_df.content_type_id == False), ['task_container_id', 'user_id']].groupby(['task_container_id']).agg(['nunique'])\n",
    "group2.columns = ['avg_questions']\n",
    "\n",
    "group3 = group1 / group2\n",
    "group3['avg_questions_seen'] = group3.avg_questions.cumsum()\n",
    "\n",
    "results_u_final = train_df.loc[train_df.content_type_id == False, ['user_id','answered_correctly']].groupby(['user_id']).agg(['mean'])\n",
    "results_u_final.columns = ['answered_correctly_user']\n",
    "\n",
    "results_u2_final = train_df.loc[train_df.content_type_id == False, ['user_id','prior_question_had_explanation']].groupby(['user_id']).agg(['mean'])\n",
    "results_u2_final.columns = ['explanation_mean_user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract question\n",
    "train_df = pd.merge(train_df, questions_df, left_on = 'content_id', right_on = 'question_id', how = 'left')\n",
    "\n",
    "results_q_final = train_df.loc[train_df.content_type_id == False, ['question_id','answered_correctly']].groupby(['question_id']).agg(['mean'])\n",
    "results_q_final.columns = ['quest_pct']\n",
    "\n",
    "results_q2_final = train_df.loc[train_df.content_type_id == False, ['question_id','part']].groupby(['question_id']).agg(['count'])\n",
    "results_q2_final.columns = ['count']\n",
    "\n",
    "question2 = pd.merge(questions_df, results_q_final, left_on = 'question_id', right_on = 'question_id', how = 'left')\n",
    "\n",
    "question2 = pd.merge(question2, results_q2_final, left_on = 'question_id', right_on = 'question_id', how = 'left')\n",
    "\n",
    "question2.quest_pct = round(question2.quest_pct,5)\n",
    "\n",
    "prior_mean_user = results_u2_final.explanation_mean_user.mean()\n",
    "\n",
    "train_df.drop(['timestamp', 'part', 'question_id', 'part', 'bundle_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nvalidation = train_df.groupby(\\'user_id\\').tail(5)\\ntrain = train_df[~train_df.index.isin(validation.index)]\\n\\n\\nresults_u_val = train_df[[\\'user_id\\',\\'answered_correctly\\']].groupby([\\'user_id\\']).agg([\\'mean\\'])\\nresults_u_val.columns = [\\'answered_correctly_user\\']\\n\\nresults_u2_val = train_df[[\\'user_id\\',\\'prior_question_had_explanation\\']].groupby([\\'user_id\\']).agg([\\'mean\\'])\\nresults_u2_val.columns = [\\'explanation_mean_user\\']\\n\\nvalidation = pd.merge(validation, group3, left_on=[\\'task_container_id\\'], right_index= True, how=\"left\")\\nvalidation = pd.merge(validation, results_u_val, on=[\\'user_id\\'], how=\"left\")\\nvalidation = pd.merge(validation, results_u2_val, on=[\\'user_id\\'], how=\"left\")\\n\\nvalidation = pd.merge(validation, user_lecture_stats_part, on=[\\'user_id\\'], how=\"left\")\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract valid\n",
    "'''\n",
    "validation = train_df.groupby('user_id').tail(5)\n",
    "train = train_df[~train_df.index.isin(validation.index)]\n",
    "\n",
    "\n",
    "results_u_val = train_df[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean'])\n",
    "results_u_val.columns = ['answered_correctly_user']\n",
    "\n",
    "results_u2_val = train_df[['user_id','prior_question_had_explanation']].groupby(['user_id']).agg(['mean'])\n",
    "results_u2_val.columns = ['explanation_mean_user']\n",
    "\n",
    "validation = pd.merge(validation, group3, left_on=['task_container_id'], right_index= True, how=\"left\")\n",
    "validation = pd.merge(validation, results_u_val, on=['user_id'], how=\"left\")\n",
    "validation = pd.merge(validation, results_u2_val, on=['user_id'], how=\"left\")\n",
    "\n",
    "validation = pd.merge(validation, user_lecture_stats_part, on=['user_id'], how=\"left\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract train\n",
    "X = train_df.iloc[:,:]\n",
    "#train_df = train_df[~train_df.index.isin(X.index)]\n",
    "\n",
    "results_u_X = train_df[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean'])\n",
    "results_u_X.columns = ['answered_correctly_user']\n",
    "\n",
    "results_u2_X = train_df[['user_id','prior_question_had_explanation']].groupby(['user_id']).agg(['mean'])\n",
    "results_u2_X.columns = ['explanation_mean_user']\n",
    "\n",
    "X = pd.merge(X, group3, left_on=['task_container_id'], right_index= True, how=\"left\")\n",
    "X = pd.merge(X, results_u_X, on=['user_id'], how=\"left\")\n",
    "X = pd.merge(X, results_u2_X, on=['user_id'], how=\"left\")\n",
    "X = pd.merge(X, user_lecture_stats_part, on=['user_id'], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_mean = question2.quest_pct.mean()\n",
    "question2.quest_pct.mean()\n",
    "#there are a lot of high percentage questions, should use median instead?\n",
    "\n",
    "#filling questions with no info with a new value\n",
    "question2.quest_pct = question2.quest_pct.mask((question2['count'] < 3), .65)\n",
    "\n",
    "\n",
    "#filling very hard new questions with a more reasonable value\n",
    "question2.quest_pct = question2.quest_pct.mask((question2.quest_pct < .2) & (question2['count'] < 21), .2)\n",
    "\n",
    "#filling very easy new questions with a more reasonable value\n",
    "question2.quest_pct = question2.quest_pct.mask((question2.quest_pct > .95) & (question2['count'] < 21), .95)\n",
    "\n",
    "X = pd.merge(X, question2, left_on = 'content_id', right_on = 'question_id', how = 'left')\n",
    "\n",
    "# validation = pd.merge(validation, question2, left_on = 'content_id', right_on = 'question_id', how = 'left')\n",
    "X.part = X.part - 1\n",
    "# validation.part = validation.part - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['answered_correctly']\n",
    "X = X.drop(['answered_correctly'], axis=1)\n",
    "#y_val = validation['answered_correctly']\n",
    "#X_val = validation.drop(['answered_correctly'], axis=1)\n",
    "\n",
    "# Filling with 0.5 for simplicity; there could likely be a better value\n",
    "X['answered_correctly_user'].fillna(0.65,  inplace=True)\n",
    "X['explanation_mean_user'].fillna(prior_mean_user,  inplace=True)\n",
    "X['quest_pct'].fillna(content_mean, inplace=True)\n",
    "\n",
    "X['part'].fillna(4, inplace = True)\n",
    "X['avg_questions_seen'].fillna(1, inplace = True)\n",
    "X['prior_question_elapsed_time'].fillna(elapsed_mean, inplace = True)\n",
    "#X['prior_question_had_explanation_enc'].fillna(0, inplace = True)\n",
    "\n",
    "X['part_1'].fillna(0, inplace = True)\n",
    "X['part_2'].fillna(0, inplace = True)\n",
    "X['part_3'].fillna(0, inplace = True)\n",
    "X['part_4'].fillna(0, inplace = True)\n",
    "X['part_5'].fillna(0, inplace = True)\n",
    "X['part_6'].fillna(0, inplace = True)\n",
    "X['part_7'].fillna(0, inplace = True)\n",
    "X['type_of_concept'].fillna(0, inplace = True)\n",
    "X['type_of_intention'].fillna(0, inplace = True)\n",
    "X['type_of_solving_question'].fillna(0, inplace = True)\n",
    "X['type_of_starter'].fillna(0, inplace = True)\n",
    "X['part_1_boolean'].fillna(0, inplace = True)\n",
    "X['part_2_boolean'].fillna(0, inplace = True)\n",
    "X['part_3_boolean'].fillna(0, inplace = True)\n",
    "X['part_4_boolean'].fillna(0, inplace = True)\n",
    "X['part_5_boolean'].fillna(0, inplace = True)\n",
    "X['part_6_boolean'].fillna(0, inplace = True)\n",
    "X['part_7_boolean'].fillna(0, inplace = True)\n",
    "X['type_of_concept_boolean'].fillna(0, inplace = True)\n",
    "X['type_of_intention_boolean'].fillna(0, inplace = True)\n",
    "X['type_of_solving_question_boolean'].fillna(0, inplace = True)\n",
    "X['type_of_starter_boolean'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 98182 entries, 0 to 98181\n",
      "Data columns (total 38 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   row_id                            98182 non-null  int64  \n",
      " 1   user_id                           98182 non-null  int32  \n",
      " 2   content_id                        98182 non-null  int16  \n",
      " 3   content_type_id                   98182 non-null  int8   \n",
      " 4   task_container_id                 98182 non-null  int8   \n",
      " 5   prior_question_elapsed_time       98182 non-null  float32\n",
      " 6   prior_question_had_explanation    98182 non-null  bool   \n",
      " 7   avg_questions                     98182 non-null  float64\n",
      " 8   avg_questions_seen                98182 non-null  float64\n",
      " 9   answered_correctly_user           98182 non-null  float64\n",
      " 10  explanation_mean_user             98182 non-null  float64\n",
      " 11  part_1                            98182 non-null  float64\n",
      " 12  part_2                            98182 non-null  float64\n",
      " 13  part_3                            98182 non-null  float64\n",
      " 14  part_4                            98182 non-null  float64\n",
      " 15  part_5                            98182 non-null  float64\n",
      " 16  part_6                            98182 non-null  float64\n",
      " 17  part_7                            98182 non-null  float64\n",
      " 18  type_of_concept                   98182 non-null  float64\n",
      " 19  type_of_intention                 98182 non-null  float64\n",
      " 20  type_of_solving_question          98182 non-null  float64\n",
      " 21  type_of_starter                   98182 non-null  float64\n",
      " 22  part_1_boolean                    98182 non-null  float64\n",
      " 23  part_2_boolean                    98182 non-null  float64\n",
      " 24  part_3_boolean                    98182 non-null  float64\n",
      " 25  part_4_boolean                    98182 non-null  float64\n",
      " 26  part_5_boolean                    98182 non-null  float64\n",
      " 27  part_6_boolean                    98182 non-null  float64\n",
      " 28  part_7_boolean                    98182 non-null  float64\n",
      " 29  type_of_concept_boolean           98182 non-null  float64\n",
      " 30  type_of_intention_boolean         98182 non-null  float64\n",
      " 31  type_of_solving_question_boolean  98182 non-null  float64\n",
      " 32  type_of_starter_boolean           98182 non-null  float64\n",
      " 33  question_id                       98182 non-null  int16  \n",
      " 34  bundle_id                         98182 non-null  int8   \n",
      " 35  part                              98182 non-null  int8   \n",
      " 36  quest_pct                         98182 non-null  float64\n",
      " 37  count                             98182 non-null  float64\n",
      "dtypes: bool(1), float32(1), float64(28), int16(2), int32(1), int64(1), int8(4)\n",
      "memory usage: 24.1 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['prior_question_had_explanation','bundle_id','user_id', 'content_id', 'task_container_id']\n",
    "\n",
    "cont_columns = ['answered_correctly_user', 'explanation_mean_user', 'quest_pct', 'avg_questions_seen','prior_question_elapsed_time', 'part',\n",
    "                'part_1', 'part_2', 'part_3', 'part_4', 'part_5', 'part_6', 'part_7',\n",
    "               'type_of_concept', 'type_of_intention', 'type_of_solving_question', 'type_of_starter',\n",
    "               'part_1_boolean', 'part_2_boolean', 'part_3_boolean', 'part_4_boolean', 'part_5_boolean', 'part_6_boolean', 'part_7_boolean',\n",
    "               'type_of_concept_boolean', 'type_of_intention_boolean', 'type_of_solving_question_boolean', 'type_of_starter_boolean']\n",
    "\n",
    "#cont_columns = ['answered_correctly_user', 'explanation_mean_user', 'quest_pct', 'avg_questions_seen','prior_question_elapsed_time', ]\n",
    "\n",
    "features=cat_columns+cont_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior_question_had_explanation\n",
      "bundle_id\n",
      "user_id\n",
      "content_id\n",
      "task_container_id\n"
     ]
    }
   ],
   "source": [
    "def encode(df,cols):\n",
    "    enc =  {}\n",
    "    for col in cols:\n",
    "        print(col)\n",
    "        lbencoder = LabelEncoder()\n",
    "        lb = lbencoder.fit(df[col].values)\n",
    "        df[col]=lb.transform(df[col].values)\n",
    "        enc[col]=lb\n",
    "        \n",
    "    return df,enc\n",
    "\n",
    "X,enc_dict = encode(X,cat_columns)\n",
    "\n",
    "scale_dict={}\n",
    "fix_missing={}\n",
    "\n",
    "\n",
    "for col in cont_columns:\n",
    "    scaler = RobustScaler()\n",
    "    scale_dict[col]=scaler.fit(X[col].values.reshape(-1,1))\n",
    "    X[col] = scale_dict[col].transform(X[col].values.reshape(-1,1))\n",
    "    fix_missing[col] = X[col].mode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 1), (256, 50), (349, 50), (11321, 50), (256, 50)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dims = [X[col].nunique() for col in cat_columns]\n",
    "cat_embs = [(dim, min(50,(dim+1)//2)) for dim in cat_dims]\n",
    "cat_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidDataset(Dataset):\n",
    "    def __init__(self, df,targets,cat_features,cont_features,mode='train'):\n",
    "        self.mode = mode\n",
    "        self.data_cont = df[cont_features].values\n",
    "        self.data_cat = df[cat_features].values\n",
    "        if mode=='train':\n",
    "            self.targets = targets.values \n",
    "        print(self.data_cont.shape)\n",
    "        print(self.data_cat.shape)\n",
    "        print(self.targets.shape)\n",
    "    def __len__(self):\n",
    "        return len(self.data_cont)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "            sample = {'data_cont': self.data_cont[idx], 'data_cat':self.data_cat[idx], 'target' : self.targets[idx]}\n",
    "            return sample\n",
    "        elif self.mode == 'test':\n",
    "            sample = {'data_cont': self.data_cont[idx], 'data_cat':self.data_cat[idx], 'target' : 0}\n",
    "            #return torch.FloatTensor(self.data_cont[idx]), torch.LongTensor(self.data_cat[idx]), 0\n",
    "            return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collater(data):\n",
    "    data_conts = [d_i['data_cont'] for d_i in data]\n",
    "    \n",
    "    data_cats = [d_i['data_cat'] for d_i in data]\n",
    "    \n",
    "    targets = [d_i['target'] for d_i in data]\n",
    "    \n",
    "    data_conts = np.stack(data_conts, axis=0)\n",
    "    \n",
    "    data_cats  =np.stack(data_cats, axis=0)\n",
    "    \n",
    "    targets  = np.stack(targets, axis=0)\n",
    "    \n",
    "    return {'data_cont' : torch.FloatTensor(data_conts), 'data_cat' : torch.LongTensor(data_cats), 'target' :  torch.FloatTensor(targets)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass RidModel(nn.Module):\\n    def __init__(self,emb_dims,no_of_cont):\\n        super(RidModel, self).__init__()\\n        \\n        self.emb = nn.ModuleList([nn.Embedding(x,y) for x,y in emb_dims])\\n        \\n        no_of_embs = sum([y for x, y in emb_dims])\\n        self.no_of_embs = no_of_embs\\n        self.no_of_cont = no_of_cont\\n        \\n        \\n        self.batch_norm1 = nn.BatchNorm1d(self.no_of_cont)\\n        self.dropout1 = nn.Dropout(0.2)\\n        self.dense1 = nn.utils.weight_norm(nn.Linear(no_of_cont, 128))\\n        \\n        self.batch_norm2 = nn.BatchNorm1d(128+no_of_embs)\\n        self.dense2 = nn.utils.weight_norm(nn.Linear(128+no_of_embs, 32))\\n         \\n        self.batch_norm3 = nn.BatchNorm1d(32)\\n        self.dense3 = nn.utils.weight_norm(nn.Linear(32, 16))\\n        \\n        self.batch_norm4 = nn.BatchNorm1d(16)\\n        self.dense4 = nn.utils.weight_norm(nn.Linear(16, 1))\\n        \\n       \\n    def forward(self,cont,cat):\\n         \\n        ## cat data part\\n        x_cat = [emb_layer(cat[:,i]) for i,emb_layer in enumerate(self.emb)]\\n        x_cat = torch.cat(x_cat,1)\\n        x_cat = self.dropout1(x_cat)\\n        ##cont data\\n        x = self.batch_norm1(cont)\\n        x = self.dropout1(x)\\n        x = F.relu(self.dense1(x))\\n        \\n        ##concat\\n        x = torch.cat([x,x_cat],1)\\n        \\n        ##rest of NN\\n        x = self.batch_norm2(x)\\n        x = F.relu(self.dense2(x))\\n        \\n        x = self.batch_norm3(x)\\n        x = F.relu(self.dense3(x))\\n        \\n        \\n        x = self.batch_norm4(x)\\n        x = F.sigmoid(self.dense4(x))\\n        \\n        return x\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "'''\n",
    "class RidModel(nn.Module):\n",
    "    def __init__(self,emb_dims,no_of_cont):\n",
    "        super(RidModel, self).__init__()\n",
    "        \n",
    "        self.emb = nn.ModuleList([nn.Embedding(x,y) for x,y in emb_dims])\n",
    "        \n",
    "        no_of_embs = sum([y for x, y in emb_dims])\n",
    "        self.no_of_embs = no_of_embs\n",
    "        self.no_of_cont = no_of_cont\n",
    "        \n",
    "        \n",
    "        self.batch_norm1 = nn.BatchNorm1d(self.no_of_cont)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(no_of_cont, 128))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(128+no_of_embs)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(128+no_of_embs, 32))\n",
    "         \n",
    "        self.batch_norm3 = nn.BatchNorm1d(32)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(32, 16))\n",
    "        \n",
    "        self.batch_norm4 = nn.BatchNorm1d(16)\n",
    "        self.dense4 = nn.utils.weight_norm(nn.Linear(16, 1))\n",
    "        \n",
    "       \n",
    "    def forward(self,cont,cat):\n",
    "         \n",
    "        ## cat data part\n",
    "        x_cat = [emb_layer(cat[:,i]) for i,emb_layer in enumerate(self.emb)]\n",
    "        x_cat = torch.cat(x_cat,1)\n",
    "        x_cat = self.dropout1(x_cat)\n",
    "        ##cont data\n",
    "        x = self.batch_norm1(cont)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        \n",
    "        ##concat\n",
    "        x = torch.cat([x,x_cat],1)\n",
    "        \n",
    "        ##rest of NN\n",
    "        x = self.batch_norm2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = F.relu(self.dense3(x))\n",
    "        \n",
    "        \n",
    "        x = self.batch_norm4(x)\n",
    "        x = F.sigmoid(self.dense4(x))\n",
    "        \n",
    "        return x\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train,X_valid,y_train,y_valid = train_test_split(X[features],y,test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del X,y,train_df\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnepochs=50\\ntrain_set = RidDataset(X_train,y_train,cat_columns,cont_columns,mode=\"train\")\\nvalid_set = RidDataset(X_valid,y_valid,cat_columns,cont_columns,mode=\"train\")\\nval_auc=[]\\ndataloaders = {\\'train\\':DataLoader(train_set,batch_size=2**10,shuffle=True,drop_last = True, collate_fn = collater),\\n              \"val\":DataLoader(valid_set,batch_size=2**10,shuffle=True, drop_last = True, collate_fn = collater)}\\n\\nmodel = RidModel(cat_embs,len(cont_columns)).to(DEVICE)\\ncheckpoint_path = \\'rid_model.pt\\'\\noptimizer = optim.Adam(model.parameters())\\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\\'min\\', factor=0.1, patience=5, eps=1e-4, verbose=True)\\ncriterion = nn.BCELoss()\\nbest_loss = {\\'train\\':np.inf,\\'val\\':np.inf}\\nauc_score = {\\'train\\':0,\\'val\\':0.0}\\n\\nfor epoch in range(nepochs):\\n    epoch_loss = {\\'train\\': 0.0, \\'val\\': 0.0}\\n\\n    for phase in [\\'train\\', \\'val\\']:\\n        if phase == \\'train\\':\\n            model.train()\\n        else:\\n            model.eval()\\n\\n        running_loss = 0.0\\n        auc=0.0\\n\\n        for i,data in enumerate(dataloaders[phase]):\\n            x, y, z = data[\\'data_cont\\'].to(DEVICE), data[\\'data_cat\\'].to(DEVICE),data[\\'target\\'].to(DEVICE)\\n            optimizer.zero_grad()\\n            with torch.set_grad_enabled(phase==\\'train\\'):\\n                preds = model(x,y)\\n                loss = criterion(preds, z)\\n                try:\\n                    auc = roc_auc_score(z.detach().cpu().numpy(),preds.detach().cpu().numpy())\\n                except ValueError:\\n                    pass\\n                \\n\\n                if phase==\\'train\\':\\n                    loss.backward()\\n                    optimizer.step()\\n                #print(auc)\\n\\n            running_loss += loss.item() / len(dataloaders[phase])\\n            auc += auc/len(dataloaders[phase])\\n\\n        epoch_loss[phase] = running_loss\\n        auc_score[phase]=auc\\n\\n    print(\"Epoch {}/{}   - loss: {:5.5f}   - val_loss: {:5.5f} -- AUC {:5.4f} --val AUC {:5.4f}\".format(epoch+1,\\n            nepochs, epoch_loss[\\'train\\'], epoch_loss[\\'val\\'],auc_score[\\'train\\'],auc_score[\\'val\\']))\\n    val_auc.append(auc_score[\\'val\\'])\\n    scheduler.step(epoch_loss[\\'val\\'])\\n\\n    if epoch_loss[\\'val\\'] < best_loss[\\'val\\']:\\n        best_loss = epoch_loss\\n        torch.save(model.state_dict(), checkpoint_path)\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "'''\n",
    "nepochs=50\n",
    "train_set = RidDataset(X_train,y_train,cat_columns,cont_columns,mode=\"train\")\n",
    "valid_set = RidDataset(X_valid,y_valid,cat_columns,cont_columns,mode=\"train\")\n",
    "val_auc=[]\n",
    "dataloaders = {'train':DataLoader(train_set,batch_size=2**10,shuffle=True,drop_last = True, collate_fn = collater),\n",
    "              \"val\":DataLoader(valid_set,batch_size=2**10,shuffle=True, drop_last = True, collate_fn = collater)}\n",
    "\n",
    "model = RidModel(cat_embs,len(cont_columns)).to(DEVICE)\n",
    "checkpoint_path = 'rid_model.pt'\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, eps=1e-4, verbose=True)\n",
    "criterion = nn.BCELoss()\n",
    "best_loss = {'train':np.inf,'val':np.inf}\n",
    "auc_score = {'train':0,'val':0.0}\n",
    "\n",
    "for epoch in range(nepochs):\n",
    "    epoch_loss = {'train': 0.0, 'val': 0.0}\n",
    "\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        auc=0.0\n",
    "\n",
    "        for i,data in enumerate(dataloaders[phase]):\n",
    "            x, y, z = data['data_cont'].to(DEVICE), data['data_cat'].to(DEVICE),data['target'].to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.set_grad_enabled(phase=='train'):\n",
    "                preds = model(x,y)\n",
    "                loss = criterion(preds, z)\n",
    "                try:\n",
    "                    auc = roc_auc_score(z.detach().cpu().numpy(),preds.detach().cpu().numpy())\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                \n",
    "\n",
    "                if phase=='train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                #print(auc)\n",
    "\n",
    "            running_loss += loss.item() / len(dataloaders[phase])\n",
    "            auc += auc/len(dataloaders[phase])\n",
    "\n",
    "        epoch_loss[phase] = running_loss\n",
    "        auc_score[phase]=auc\n",
    "\n",
    "    print(\"Epoch {}/{}   - loss: {:5.5f}   - val_loss: {:5.5f} -- AUC {:5.4f} --val AUC {:5.4f}\".format(epoch+1,\n",
    "            nepochs, epoch_loss['train'], epoch_loss['val'],auc_score['train'],auc_score['val']))\n",
    "    val_auc.append(auc_score['val'])\n",
    "    scheduler.step(epoch_loss['val'])\n",
    "\n",
    "    if epoch_loss['val'] < best_loss['val']:\n",
    "        best_loss = epoch_loss\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names\n",
    "from deepctr_torch.models import *\n",
    "cat_columns = ['prior_question_had_explanation','bundle_id','user_id', 'content_id', 'task_container_id']\n",
    "\n",
    "cont_columns = ['answered_correctly_user', 'explanation_mean_user', 'quest_pct', 'avg_questions_seen','prior_question_elapsed_time', 'part',\n",
    "                'part_1', 'part_2', 'part_3', 'part_4', 'part_5', 'part_6', 'part_7',\n",
    "               'type_of_concept', 'type_of_intention', 'type_of_solving_question', 'type_of_starter',\n",
    "               'part_1_boolean', 'part_2_boolean', 'part_3_boolean', 'part_4_boolean', 'part_5_boolean', 'part_6_boolean', 'part_7_boolean',\n",
    "               'type_of_concept_boolean', 'type_of_intention_boolean', 'type_of_solving_question_boolean', 'type_of_starter_boolean']\n",
    "#cont_columns = ['answered_correctly_user', 'explanation_mean_user', 'quest_pct', 'avg_questions_seen','prior_question_elapsed_time', ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef get_xy_fd():\\n    feature_columns = [SparseFeat(\\'prior_question_had_explanation\\', X_train[\\'prior_question_had_explanation\\'].nunique(), embedding_dim=8), \\n                       SparseFeat(\\'bundle_id\\', X_train[\\'bundle_id\\'].nunique(), embedding_dim=8),\\n                       SparseFeat(\\'user_id\\',  X_train[\\'user_id\\'].nunique(), embedding_dim=8), \\n                       SparseFeat(\\'content_id\\', X_train[\\'content_id\\'].nunique(), embedding_dim=8),\\n                       SparseFeat(\\'task_container_id\\', X_train[\\'task_container_id\\'].nunique(), embedding_dim=8),\\n                       DenseFeat(\\'answered_correctly_user\\', 1),\\n                       DenseFeat(\\'explanation_mean_user\\', 1),\\n                       DenseFeat(\\'quest_pct\\', 1),\\n                       DenseFeat(\\'avg_questions_seen\\', 1),\\n                       DenseFeat(\\'prior_question_elapsed_time\\', 1),\\n                      ]\\n    behavior_feature_list = [ \"bundle_id\", \\'user_id\\'] \\n    #print(X_train[\\'prior_question_had_explanation\\'].values)\\n    feature_dict = {\\'prior_question_had_explanation\\': X_train[\\'prior_question_had_explanation\\'], \\n                    \\'bundle_id\\': X_train[\\'bundle_id\\'],\\n                    \\'user_id\\':  X_train[\\'user_id\\'],\\n                    \\'content_id\\': X_train[\\'content_id\\'],\\n                    \\'task_container_id\\': X_train[\\'task_container_id\\'],\\n                    \\'answered_correctly_user\\': X_train[\\'answered_correctly_user\\'],\\n                    \\'explanation_mean_user\\': X_train[\\'explanation_mean_user\\'],\\n                    \\'quest_pct\\':X_train[\\'quest_pct\\'],\\n                    \\'avg_questions_seen\\':X_train[\\'avg_questions_seen\\'],\\n                     \\'prior_question_elapsed_time\\':X_train[\\'prior_question_elapsed_time\\'],\\n                   }\\n    x = {name: feature_dict[name] for name in get_feature_names(feature_columns)}\\n    y = y_train.values\\n    return x, y, feature_columns,behavior_feature_list\\nx, y, feature_columns,behavior_feature_list = get_xy_fd()\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def get_xy_fd():\n",
    "    feature_columns = [SparseFeat('prior_question_had_explanation', X_train['prior_question_had_explanation'].nunique(), embedding_dim=8), \n",
    "                       SparseFeat('bundle_id', X_train['bundle_id'].nunique(), embedding_dim=8),\n",
    "                       SparseFeat('user_id',  X_train['user_id'].nunique(), embedding_dim=8), \n",
    "                       SparseFeat('content_id', X_train['content_id'].nunique(), embedding_dim=8),\n",
    "                       SparseFeat('task_container_id', X_train['task_container_id'].nunique(), embedding_dim=8),\n",
    "                       DenseFeat('answered_correctly_user', 1),\n",
    "                       DenseFeat('explanation_mean_user', 1),\n",
    "                       DenseFeat('quest_pct', 1),\n",
    "                       DenseFeat('avg_questions_seen', 1),\n",
    "                       DenseFeat('prior_question_elapsed_time', 1),\n",
    "                      ]\n",
    "    behavior_feature_list = [ \"bundle_id\", 'user_id'] \n",
    "    #print(X_train['prior_question_had_explanation'].values)\n",
    "    feature_dict = {'prior_question_had_explanation': X_train['prior_question_had_explanation'], \n",
    "                    'bundle_id': X_train['bundle_id'],\n",
    "                    'user_id':  X_train['user_id'],\n",
    "                    'content_id': X_train['content_id'],\n",
    "                    'task_container_id': X_train['task_container_id'],\n",
    "                    'answered_correctly_user': X_train['answered_correctly_user'],\n",
    "                    'explanation_mean_user': X_train['explanation_mean_user'],\n",
    "                    'quest_pct':X_train['quest_pct'],\n",
    "                    'avg_questions_seen':X_train['avg_questions_seen'],\n",
    "                     'prior_question_elapsed_time':X_train['prior_question_elapsed_time'],\n",
    "                   }\n",
    "    x = {name: feature_dict[name] for name in get_feature_names(feature_columns)}\n",
    "    y = y_train.values\n",
    "    return x, y, feature_columns,behavior_feature_list\n",
    "x, y, feature_columns,behavior_feature_list = get_xy_fd()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda ready...\n",
      "cuda:0\n",
      "Train on 66763 samples, validate on 16691 samples, 2087 steps per epoch\n",
      "Epoch 1/10\n",
      "10s - loss:  0.4961 - binary_crossentropy:  0.4961 - auc:  0.7958 - val_binary_crossentropy:  0.4907 - val_auc:  0.7986\n",
      "Epoch 2/10\n",
      "10s - loss:  0.4853 - binary_crossentropy:  0.4853 - auc:  0.8039 - val_binary_crossentropy:  0.4896 - val_auc:  0.7983\n",
      "Epoch 3/10\n",
      "10s - loss:  0.4813 - binary_crossentropy:  0.4813 - auc:  0.8080 - val_binary_crossentropy:  0.4928 - val_auc:  0.7951\n",
      "Epoch 4/10\n",
      "10s - loss:  0.4757 - binary_crossentropy:  0.4758 - auc:  0.8103 - val_binary_crossentropy:  0.5029 - val_auc:  0.7872\n",
      "Epoch 5/10\n",
      "10s - loss:  0.4665 - binary_crossentropy:  0.4666 - auc:  0.8179 - val_binary_crossentropy:  0.5239 - val_auc:  0.7733\n",
      "Epoch 6/10\n",
      "10s - loss:  0.4546 - binary_crossentropy:  0.4545 - auc:  0.8271 - val_binary_crossentropy:  0.5505 - val_auc:  0.7602\n",
      "Epoch 7/10\n",
      "10s - loss:  0.4422 - binary_crossentropy:  0.4422 - auc:  0.8365 - val_binary_crossentropy:  0.5779 - val_auc:  0.7492\n",
      "Epoch 8/10\n",
      "10s - loss:  0.4310 - binary_crossentropy:  0.4309 - auc:  0.8473 - val_binary_crossentropy:  0.6058 - val_auc:  0.7413\n",
      "Epoch 9/10\n",
      "10s - loss:  0.4206 - binary_crossentropy:  0.4206 - auc:  0.8570 - val_binary_crossentropy:  0.6384 - val_auc:  0.7330\n"
     ]
    }
   ],
   "source": [
    "fixlen_feature_columns = [SparseFeat(feat, X[feat].nunique())\n",
    "                          for feat in cat_columns] + [DenseFeat(feat, 1, )\n",
    "                                                          for feat in cont_columns]\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "\n",
    "# 3.generate input data for model\n",
    "\n",
    "X_train,X_valid,y_train,y_valid = train_test_split(X[features],y,test_size=0.15)\n",
    "#train, test = train_test_split(X[features], test_size=0.2, random_state=2020)\n",
    "train_model_input = {name: X_train[name] for name in feature_names}\n",
    "test_model_input = {name: X_valid[name] for name in feature_names}\n",
    "\n",
    "device = 'cpu'\n",
    "use_cuda = True\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    print('cuda ready...')\n",
    "    device = 'cuda:0'\n",
    "\n",
    "model = DeepFM(linear_feature_columns=linear_feature_columns, dnn_feature_columns=dnn_feature_columns,\n",
    "               task='binary',\n",
    "               l2_reg_embedding=1e-5, device=device)\n",
    "\n",
    "model.compile(\"adagrad\", \"binary_crossentropy\",\n",
    "              metrics=[\"binary_crossentropy\", \"auc\"], )\n",
    "\n",
    "model.fit(train_model_input, y_train.values, batch_size=32, epochs=10, verbose=2, validation_split=0.2)\n",
    "\n",
    "pred_ans = model.predict(test_model_input, 256)\n",
    "print(\"\")\n",
    "print(\"test LogLoss\", round(log_loss(y_valid.values, pred_ans), 4))\n",
    "print(\"test AUC\", round(roc_auc_score(y_valid.values, pred_ans), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-15",
   "language": "python",
   "name": "torch-15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
